[
  {
    "objectID": "ggplot_examples.html",
    "href": "ggplot_examples.html",
    "title": "2  Building plots using the package ggplot2",
    "section": "",
    "text": "2.1 Load packages\nIn this exercise we are going to produce and improve a variety of useful and widely used plots using the package ggplot2 which is part of the larger tidyverse package.\nYou will see that the code to do each plot is very similar, whatever the type of plot, and that plots can be built up from very basic forms to become really attractive, informative versions with very little additional effort.\nYou need to read the examples in this worksheet and then fill in the missing code or alter what is provided already in the empty code chunks of the accompanying template script. Instructions for getting that are given below.\nAs you complete each code chunk, try it out by pressing the green arrow at the top right of the chunk. Sometimes you might want to try out an individual line. You can do that by placing the cursor anywhere in the line and pressing Controll-Entr (windows) or Command-Enter (Mac)\nRemember that the template is a markdown document, so you can add extra text between the code chunks to explain to yourself what is going on. You can format this test, if you wish, according to the very basic markdown rules for doing this. See Help/Markdown Quick Reference. This formatting is only useful if you ‘knit’ the script, by pressing the knit button at the top of the script pane. Try this! I suggest you knit to html. This is how the worksheet you are working from was produced.\n# install.packages(\"name of package\") # run this line once, if you need to, for any of the packages that need to be installed\nlibrary(tidyverse)\nlibrary(here)\nlibrary(palmerpenguins)\nlibrary(devtools)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_examples.html#get-the-template-script",
    "href": "ggplot_examples.html#get-the-template-script",
    "title": "2  Building plots using the package ggplot2",
    "section": "2.2 Get the template script",
    "text": "2.2 Get the template script\nThis next chunk will download the template file that you need to fill in as you work through this worksheet, and put it in the scripts subfolder within your project folder. For it to work, you need to be ‘working in your Project’ - in which case the name of the project will appear in the top right of the main RStudio window, and if you have a subfolder within the project folder called ‘scripts’. If any of that is not true, it needs to be sorted now!\n\nfile_url &lt;- \"https://raw.githubusercontent.com/mbh038/r-workshop/gh-pages/scripts/ggplot_examples_template.Rmd\"\nfile_dest &lt;- here(\"scripts\",\"my_ggplot_examples.rmd\")\ndownload.file(file_url,file_dest)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_examples.html#load-the-palmer-penguin-data",
    "href": "ggplot_examples.html#load-the-palmer-penguin-data",
    "title": "2  Building plots using the package ggplot2",
    "section": "2.3 Load the Palmer penguin data",
    "text": "2.3 Load the Palmer penguin data\nFor this exercise we use the Palmer penguins data set which comes with the package palmerpenguins\nThe palmerpenguin package contains two built-in data sets. One is called penguins:\nHere we load the data into this R session (you will now see it in the Environment pane) and we inspect it using the function glimpse().\n\ndata(penguins)\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nHow many rows are there and how many columns?\nFor more detailed meta-information on the data we just type the name of the data set with a question mark before it:\n\n?penguins",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_examples.html#summary-stats-on-all-the-numeric-columns",
    "href": "ggplot_examples.html#summary-stats-on-all-the-numeric-columns",
    "title": "2  Building plots using the package ggplot2",
    "section": "2.4 Summary stats on all the numeric columns",
    "text": "2.4 Summary stats on all the numeric columns\nThis is in general useful to get, at least for the columns that contain numerical data, since it shows which columns contains NAs,which is R-speak for missing data. They are how R represents what would be empty cells in an Excel spreadsheet.\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nWe see that there are some rows with NAs in for a few of the columns. We need to be aware of this when doing calculations with the data, such as taking means.\nHere, we will remove those rows:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_examples.html#remove-the-rows-with-nas",
    "href": "ggplot_examples.html#remove-the-rows-with-nas",
    "title": "2  Building plots using the package ggplot2",
    "section": "2.5 Remove the rows with NAs",
    "text": "2.5 Remove the rows with NAs\n\npenguins &lt;- penguins |&gt;\n  drop_na()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_examples.html#how-many-observations-are-there-for-each-species",
    "href": "ggplot_examples.html#how-many-observations-are-there-for-each-species",
    "title": "2  Building plots using the package ggplot2",
    "section": "2.6 How many observations are there for each species?",
    "text": "2.6 How many observations are there for each species?\nNote the use of the pipe operator |&gt;, here and throughout. Think of it as meaning and then. It feeds the output of one line into the function of the next line, where it is used as that function’s first argument.\n\npenguins |&gt;\n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      146\n2 Chinstrap    68\n3 Gentoo      119",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "ggplot_examples.html#mean-value-for-each-numerical-variable-for-each-species",
    "href": "ggplot_examples.html#mean-value-for-each-numerical-variable-for-each-species",
    "title": "2  Building plots using the package ggplot2",
    "section": "2.7 Mean value for each numerical variable, for each species",
    "text": "2.7 Mean value for each numerical variable, for each species\nHere is an example of the use of the group_by() then summarise() combination, whereby data is first grouped, here by species, then summary statistics (of your choice) are calculated for each group.\nIn this example the data are grouped by species, then the mean value of all the columns that contain numerical data are calculated, not just an overall value for the whole column, but for each species\n\npenguins |&gt;\n  group_by(species) |&gt;\n  summarize(across(where(is.numeric), mean, na.rm = TRUE)) |&gt;\n  ungroup() # good practice to include this at the end.\n\n# A tibble: 3 × 6\n  species   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g  year\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie              38.8          18.3              190.       3706. 2008.\n2 Chinstrap           48.8          18.4              196.       3733. 2008.\n3 Gentoo              47.6          15.0              217.       5092. 2008.\n\n\n\n2.7.1 Scatter plots\nIs flipper length correlated with body mass?\nWe could a do correlation test to find this out, but let us first plot the data. We will show here how an elegant plot can be built up, starting from a very basic one, so that you see what each line of code for the finished version actually does. In the chunks below, run each one in turn to see the effect of each successive change that you make.\nFirst we feed the penguin data to the function ggplot(), and use its aes() argument to tell it which variables are to be ‘mapped’ to which aesthetic (which means, roughly speaking, ‘visible’) features of the plot, such as the x-axis, the y-axis, point and line colours, fill colours, symbol types and size etc:\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g))\n\n\n\n\n\n\n\n\nThis produces the first layer of the eventual finished plot, an empty plot, ready to display data. Before it can do this, ggplot() needs to be told how you want to do so - what type of plot do you want? For that, we add a geom.....() line, to specify the type of plot.\nThere are lots of geom types, but for a scatter plot we use geom_point():\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThis gives us a recognisable scatter plot, but it is deficient in a number of ways. For starters, we know that there are three species of penguin. It would be better if each were plotted using symbols of a different colour, shape or size. We can do this by adding in an extra argument to the aesthetic in the first line. Here we include colour = species.\n\npenguins |&gt;\n  ggplot(aes(x = flipper_length_mm,y = body_mass_g, colour = species)) +\n  geom_point()\n\n\n\n\n\n\n\n\nCan you guess what you should have do if you wanted not the symbol colour, but its shape or size to depend on species? Clue: change one word!\nNow we add labels, titles and so on, using the line labs(...). Note how we can actually write the arguments of this over several lines on the page, for clarity.\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) +\n  geom_point() +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       colour= \"Species\", # this changes the title of the legend.\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins\",\n       caption = \"Alternative place to put the information in the subtitle\")\n\n\n\n\n\n\n\n\nIt can be useful to include some combination of titles, subtitles and captions if the figure is to be used as part of a presentation or poster, but if it is to go in a report, you would normally only include a caption, and let the word-processing software do it, and if just for exploratory analysis, not even that. I normally do include axis labels, however.\nNow we use a theme to alter the overall look of the figure. There are several built-in themes you can choose from, and others from packages that you can use. I usually use theme_cowplot() from the cowplot package. Try typing ?theme at the command prompt in the console window to see what is available. Here, we use the built-in theme_bw():\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) +\n  geom_point() +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       colour= \"Species\",\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins\") +\n  theme_bw()\n\n\n\n\n\n\n\n\nNow we reposition the legend. We don’t have to, but we might not like the default position of the legend. If not, we can move or even remove it using another theme() line. The position argument of this can be “none” if you want to remove it, top”, “bottom”, “left”, “right” or a numerical vector in relative coordinates, where c(0,0) means bottom left within the plot, and c(1,1) means top-right. This is what we use here. Play around with different values.\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) +\n  geom_point() +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       colour= \"Species\",\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins\") +\n  theme_bw() +\n  theme(legend.position = c(0.2,0.8)) # try \"top\", \"left\" etc\n\n\n\n\n\n\n\n\nNicer colours. If you don’t like the default colours offered by R, there are several other palettes available, for example the Brewer palettes, borrowed from the world of maps. See https://colorbrewer2.org ,and for a list of the available palettes, type &gt;?scale_colour_brewer into the console pane then look at the help that appears in the Help pane (bottom right), and scroll down to the palettes section. Note that we dont have to alter the colours. But doing so can make your plots not only look nicer, but serve some other purpose, such as to be colour-blind friendly, or have colours that are appropriate for the variables being plotted (eg red points for red things, blue points for blue things). For an assignment or dissertation report, it is a good idea to pick a palette that you like and that works, and stick with it, so that all your plots have the same general look. Here we choose the qualitative palette \"Set2\" and use it by by adding the line scale_colour_brewer(palette=\"Set2\"). Try a few other palettes.\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) +\n  geom_point() +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       colour= \"Species\",\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins\") +\n  scale_colour_brewer(palette=\"Set2\") + # try other palettes eg \"Set3\"\n  theme_bw() +\n  theme(legend.position = c(0.2,0.8)) # try \"top\", \"left\" etc\n\n\n\n\n\n\n\n\nIf we like, we can add best fit lines to each subset of the data, using geom_smooth(). To produce straight line fits, geom_smooth() needs to be told to use a linear model, using the method = \"lm\" argument. By default, you will get lines with a grey 95% confidence band around them. This can be useful, but if you don’t want it, add the argument se = FALSE, as we have done below. We have also altered the linewidth.\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=body_mass_g,colour=species)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", linewidth=0.5,se=FALSE) + # try leaving out the se argument\n  labs(x = \"Flipper length (mm)\",\n       y = \"Body mass (g)\",\n       colour= \"Species\",\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and body mass for Adelie, Chinstrap, and Gentoo Penguins\") +\n   scale_colour_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = c(0.2,0.8)) # also try legend.position = \"top\", \"left\" etc\n\n\n\n\n\n\n\n\n\n\n2.7.2 Repeat for bill length and flipper length\nModify the code of the previous plot so that you now plot bill length vs flipper length. Adjust any labels and titles as necessary. This time, put the legend in the bottom right of the plot.\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=bill_length_mm,colour=species)) +\n  geom_point() +\n  geom_smooth(method=\"lm\", linewidth=0.5,se=FALSE) + # try leaving out the se argument\n  labs(x = \"Flipper length (mm)\",\n       y = \"Bill length (mm)\",\n       colour= \"Species\",\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and bill length for Adelie, Chinstrap, and Gentoo Penguins\") +\n   scale_colour_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = c(0.9,0.2)) # play with the values to get it where you want it\n\n\n\n\n\n\n\n\nDo you see how straightforwrd it is to adapt the code that produces one plot to get the code you need for another, similar plot?\n\n\n2.7.3 Add yet more informtion to the plot\nLet us include the information of which island the penguins come from by making the shape of the plotted points be dependent on that:\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,y=bill_length_mm,colour=species,shape=island)) +\n  geom_point() +\n  #geom_smooth(method=\"lm\", linewidth=0.5,se=FALSE) + # try leaving out the se argument\n  labs(x = \"Flipper length (mm)\",\n       y = \"Bill length (mm)\",\n       colour= \"Species\",\n       shape=\"Island\",\n       title=\"Penguin size, Palmer Station LTER\",\n       subtitle=\"Flipper length and bill length for Adelie, Chinstrap, and Gentoo Penguins\") +\n   scale_colour_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = \"right\") # play with the position to get it where you want it. Try \"top\" etc.\n\n\n\n\n\n\n\n\n\n\n2.7.4 Distribution of penguin flipper lengths\nThe distribution of a data set is often a useful thing to know. Around which value are the data grouped, how widely spread are they and are the values symmetrically or asymmetrically distributed around the central value? A number of plot types can show this for us. Here we illustrate histograms, density plots, box plots, violin plots and ridge plots.\n\n2.7.4.1 Histogram\nFirst, let’s do a basic histogram. For this we use geom_histogram(). In the ggplot line, in the aes() argument, we need only specify the variable that maps to x, since the software will count how many observations lie within specific narrow ranges of the variable, called bins. Those bin counts will be the y variable of the histogram. To find the distribution of flipper length, we use flipper_length_mmm as the x variable. So we could try\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm)) +  # why is y not specified?\n  geom_histogram()\n\n\n\n\n\n\n\n\nBut this isn’t useful. The histograms for the three species overlap each other, so we need to give each one a different colour, and we need to reduce the opacity of the bars so that the histograms behind are not obscured by the ones in front, where they overlap. Further, we need to stop ggplot from stacking the different histogram bars on top of each other where those for different species are in the same bin. Annoyingly, that is what it does by default, which makes seeing the individual distributions clearly much more difficult.\nAnother thing with histograms, something that can make them a fiddle to use, is that their usefulness in revealing a distrivution is affect by how wide the bins are. By default, ggplot chooses the bin width such that you get 30 bins altogether. This may not be optimal. Here, let’s try specifying the bin width to 4 mm (but see what happens when you try other values, especially very large and very small values).\nThis we can achieve by:\n\nincuding fill = species in the aes() argument of ggplot.\nsepcifying position = identity as an argument of geom_histogram(), to stop the stacking.\nspecifying the opacity argument alpha to be a value less than 1. Here we try alpha = 0.4` - but try other values in the range 0 (transparent) - 1 (opaque), to reduce the opacity.\nspecifying binwidth = 4 - try other values\n\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm, fill = species)) +  # why is y not specified?\n  geom_histogram(position = \"identity\", alpha = 0.4, binwidth = 4)\n\n\n\n\n\n\n\n\nSo, a lot going on, but still only three lines of code!\nNow add good axis labels, an overall theme, and choose a colour scheme you like, and the legend position, just as you have done before:\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,fill=species)) +\n  geom_histogram(position=\"identity\",alpha = 0.4, binwidth = 4) +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Count\",\n       fill= \"Species\", # specifies the legend title. See what happens if you omit this line.\n       title=\"Penguin flipper lengths\") + # we wouldn't use this for a figure going in a report.\n  scale_fill_brewer(palette=\"Set2\") + \n  theme_bw() +\n  theme(legend.position = c(0.9,0.8)) # play with the position to get it where you want it\n\n\n\n\n\n\n\n\nIn the scatter plot and the histogram, we have used colour to distinguish the different species. We can do this because our data set is tidy: there is just one column that species the species, and the same for every other variable. That same feature of the data enables to use another way to represent the different species: facet_wrap(~species). This gives us three separate plots, side by side or one above the other. See it used here:\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,fill=species)) +\n  geom_histogram(position=\"identity\",alpha = 0.4, binwidth = 4) +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Count\",\n       fill= \"Species\", \n       title=\"Penguin flipper lengths\") + \n  facet_wrap(~species) + #try adding the argument ncol = 1.\n  scale_fill_brewer(palette=\"Set2\") + # try other palettes, eg \"Set1\".\n  theme_bw() +\n  theme(legend.position=\"none\") # we don't need a legend!\n\n\n\n\n\n\n\n\nJust a thought, but do the colours here serve any useful purpose? What extra information do they convey? If you ever think that a feature of a graph conveys no additional information, consider omitting it. Here is the figue before without colours, but going for white brs with grey outlines:\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm)) +\n  geom_histogram(position=\"identity\",alpha = 0.4, binwidth = 4, fill=\"white\",colour=\"grey50\") +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Count\",\n       fill= \"Species\", # specifies the legend title. See what happens if you omit this line.\n       title=\"Penguin flipper lengths\") + # we wouldn't use this for a figure going in a report.\n  facet_wrap(~species) + #try adding the argument ncol = 1.\n  theme_bw() +\n  theme(legend.position=\"none\") # we don't need a legend!\n\n\n\n\n\n\n\n\nArguably, this is a better plot than the previous one because it excludes the potentially confusing redundancy of using different colours each species, when we already know which species is the subject of each plot.\nIf you don’t like white as the fill colour, try another one, for exampe this one that I found on Cynthia Brewer’s very useful map colour site: https://colorbrewer2.org\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm)) +\n  geom_histogram(position=\"identity\",alpha = 0.4, binwidth = 4, fill=\"#a6bddb\",colour=\"grey50\") +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Count\",\n       fill= \"Species\", # specifies the legend title. See what happens if you omit this line.\n       title=\"Penguin flipper lengths\") + # we wouldn't use this for a figure going in a report.\n  facet_grid(island~species) + #try adding the argument ncol = 1.\n  theme_bw() +\n  theme(legend.position=\"none\") # we don't need a legend!\n\n\n\n\n\n\n\n\nDifferent fill colours would be useful if the different penguin species had distinctive dominant colours, but that isn’t the case!\n\n\n2.7.4.2 Density plot\nAn alternative to a histogram, the density plot, gives us a smoothed version of the histogram. The vertical axis on these is not a count, but a measure of the concentration of the data.\nHere is one with overlapping density plots\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm,fill=species)) +\n  geom_density(alpha=0.2) +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Density\",\n       fill= \"Species\",\n       title=\"Penguin flipper lengths\") +\n  scale_fill_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = \"right\") # play with the position to get it where you want it\n\n\n\n\n\n\n\n\nWe can also adapt this and do what was done for the histograms and do a set of three, one for each species, using facet_wrap():\n\npenguins |&gt;\n  ggplot(aes(x=flipper_length_mm)) +\n  geom_density(alpha = 0.2, fill=\"#a6bddb\",colour=\"grey50\") +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Count\",\n       fill= \"Species\", # specifies the legend title. See what happens if you omit this line.\n       title=\"Penguin flipper lengths\") + # we wouldn't use this for a figure going in a report.\n  facet_wrap(~species) + #try adding the argument ncol = 1.\n  theme_bw() +\n  theme(legend.position=\"none\") # we don't need a legend!\n\n\n\n\n\n\n\n\nWhich is more useful in this case: the overlapping plots on one chart, or the separate charts done using facet_wrap()? Whatever you think here, the answer in other cases will sometimes be one, sometimes the other. Now you have the tools to enable you to try both and make the best choice.\n\n\n2.7.4.3 Box plots\nBox plots are a really useful way to summarize the distribution of numerical response data such as flipper_length_mm across different categorical variables, such as species. We use geom_boxplot() to produce them.\nLet’s do a basic box plot of flipper lengths for each penguin species:\n\npenguins |&gt;\n  ggplot(aes(x=species,y=flipper_length_mm,fill=species)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nNow let’s use what we have done before to add code lines that\n\ninclude suitable axis labels and a title\ngive the same ‘theme’ ie overall look as the previous graphs\nfill the boxes with the same colour for each species.\nremove the legend that you now have, because you don’t need it (Why?). Use theme(legend.position=\"none\") to do this.\n\n\npenguins |&gt;\n  ggplot(aes(x=species,y=flipper_length_mm,fill=species)) +\n  geom_boxplot() +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\",\n       title=\"Penguin flipper lengths\") +\n  scale_fill_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = \"none\") # no legend needed\n\n\n\n\n\n\n\n\n\n\n2.7.4.4 Violin Plot using geom_violin()\nThis is a variant on the box plot. Each ‘violin’ is a sideways density plot of the distribution of the data for each species, with its own mirror image to make it look a bit like a violin. The code for these is exactly as for box plots except we use geom_violin().\n\npenguins |&gt;\n  ggplot(aes(x=species,y=flipper_length_mm,fill=species)) +\n  geom_violin() \n\n\n\n\n\n\n\n\nNow we write code to improve this, just as you did the box plot. The final code is the same as for that apart from one line!\n\npenguins |&gt;\n  ggplot(aes(x=species,y=flipper_length_mm,fill=species)) +\n  geom_violin() +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\",\n       title=\"Penguin flipper lengths\") +\n  scale_fill_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = \"none\") # no legend needed\n\n\n\n\n\n\n\n\n\n\n2.7.4.5 Ridge plot\nThis is a variant on the density plot, that is most useful when you have lots of categorical variables. We have only three here, the three penguin species, but let’s try it anyway.\nFor this, we need the ggridges package. This is one of many packages that extend the power of ggplot, and so work in much the same way:\n\n# library\n#install.packages(\"ggridges\") # use this once, if you have to, then comment it out.\nlibrary(ggridges) \n \n# basic example\npenguins |&gt;\nggplot(aes(x = flipper_length_mm, y = species, fill = species)) +\n  geom_density_ridges() +\n  labs(x = \"Flipper length (mm)\",\n       y = \"Species\",\n       title=\"Penguin flipper lengths\") +\n  theme_ridges() + \n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nNow try producing graphs like the ones above, but for body mass rather than flipper length.\n\n\n\n2.7.5 Bar chart with error bar\nThere are different ways to produce this commonly used way to summarise data. For example we might use one to compare the mean flipper lengths of the different penguin species. For a bar chart of these to be of any use at all, it needs to include error bars that show standard deviations of the samples, standard errors of the means, or confidence intervals (Why?). Which you use depends on the story you are trying to tell.\nFirst, we will add error bars that are ± one standard deviation of the samples.\nI usually first create a summary of the data, in which we calculate the means and appropriate error for each species for whichever variable I am interested in, then feed this summary table to ggplot and use geom_col() to plot the bars, with geom_errorbar() on top of that to plot the error bars.\nLet’s do that first:\n\nflipper_summary &lt;- penguins |&gt;\n  drop_na() |&gt;\n  # these two lines produce a summary table\n  group_by(species) |&gt;\n  summarise(fl.mean = mean(flipper_length_mm), fl.sd = sd(flipper_length_mm))\nflipper_summary\n\n# A tibble: 3 × 3\n  species   fl.mean fl.sd\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie       190.  6.52\n2 Chinstrap    196.  7.13\n3 Gentoo       217.  6.59\n\n\n\nflipper_summary |&gt;\n  ggplot(aes(x = species, y = fl.mean)) +\n  geom_col() +\n  geom_errorbar(aes(ymin = fl.mean-fl.sd, ymax = fl.mean + fl.sd), width = 0.1) +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\") +\n  theme_bw() \n\n\n\n\n\n\n\n\n\n2.7.5.1 Standard deviation or standard error?\nThe error bars in the plot above are ± one standard deviation. A standard deviation gives us an idea of the spread of values within a sample or population. Remember that if a population is normally distributed about its mean, there is a roughly 95% probability that a random chosen individual will lie within two standard deviations of the mean.\nSo standard deviations of samples are useful. They are a useful way to summarise the variability of the sample, they tell us about the likely variability of the next sample, and they are our best estimate of the variability of the population from which the sample was drawn.\nSometimes, though, we want to know more than that. We might want to know how closely a sample mean is likely o be to the true mean of the population from which the sample was drawn, and perhaps to get an idea as to whether two or more populations are different, given the means of samples drawn from those populations. For this, we need not the standard deviation but the standard error. These are the error bars that are most commonly displayed on bar charts when you see them in papers.\nTo calculate standard deviation error bar lengths we use a formula \\(\\text{SE} = \\frac{\\text{SD}}{\\sqrt{n}}\\) where \\(n\\) is the number of observations, SD is the standard deviation of the sample and SE is the standard error of the means of the sample. We can use the summary functions sd() to calculate the standard deviation, and n() to calculate \\(n\\).\n\nflipper_summary2 &lt;- penguins |&gt;\n  drop_na() |&gt;\n  # these two lines produce a summary table\n  group_by(species) |&gt;\n  summarise(fl.mean = mean(flipper_length_mm), fl.se = sd(flipper_length_mm)/sqrt(n()))\nflipper_summary\n\n# A tibble: 3 × 3\n  species   fl.mean fl.sd\n  &lt;fct&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie       190.  6.52\n2 Chinstrap    196.  7.13\n3 Gentoo       217.  6.59\n\n\n\nflipper_summary2 |&gt;\n  ggplot(aes(x = species, y = fl.mean)) +\n  geom_col() +\n  geom_errorbar(aes(ymin=fl.mean-fl.se, ymax = fl.mean + fl.se),width=0.1) +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\") +\n  theme_bw() \n\n\n\n\n\n\n\n\nThese standard error bars are always smaller than the standard deviation error bars (by a factor equal to the square root of the sample size). Here they are so small as to be barely visible. They ar useful in bar charts like this one since they give us a rough and ready way of assessing whether the differences between the samples (the heights of the bars) are likely to indicate real differences between the populations. If the bar-height differences are much greater than the size of the standard error bars, then they probably indicate significant differences between the popultions. If not, then they probably don’t.\nNow let’s alter this code so that each bar has a different fill colour, and remove the legend that then appears, since it is unnecessary?\n\nflipper_summary |&gt;\n  # we add an argument to colour each bar according to species\n  ggplot(aes(x = species, y = fl.mean, fill = species)) +\n  geom_col() +\n  geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd),width=0.1) +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\") +\n  theme_bw() +\n  # include an arument to remove the legend\n  theme()\n\n\n\n\n\n\n\n\nNow let us replace this colour scheme with nicer ones (not just nice, but also colour-blind friendly, perhaps) offered by the Brewer palettes.\nTo do this we can add the line scale_fill_brewer(palette = \"Set2\"). Note: we use scale_colour_brewer() to alter the colours of points, like we did above, or the outline colour of bars, and use scale_fill_brewer() to alter the fill colour of bars. This is what we want to do here.\n\nflipper_summary |&gt;\n  ggplot(aes(x = species, y = fl.mean, fill = species)) +\n  geom_col() +\n  geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd), width=0.1) +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\") +\n  scale_fill_brewer(palette=\"Set2\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nIf you don’t like the colours of the palette “Set2” you can try another one. To find out what palettes are available, remember, you can type ?scale_fill_brewer() into the console pane then look at the help that appears in the Help pane (bottom right), and scroll down to the Palettes section.\nIf you agree that having different fill colours for the bars is actually confusing and brings no information to the plot that we do not already know, you can modify the previous plot in the manner that you did for the separate histograms:\n\nflipper_summary |&gt;\n  ggplot(aes(x = species, y = fl.mean)) + \n  # add arguments here that give fill colour \"#a6bddb\" and outline colour \"grey50\".\n  geom_col(fill = \"#a6bddb\", colour = \"grey50\") +\n  geom_errorbar(aes(ymin=fl.mean-fl.sd, ymax = fl.mean + fl.sd), width=0.1) +\n  labs(x = \"Species\",\n       y = \"Flipper length (mm)\") +\n  theme_bw() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Building plots using the package `ggplot2`</span>"
    ]
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "8  Correlation",
    "section": "",
    "text": "8.1 Correlation\nThis guide to correlation draws heavily on the very helpful chapter in Statistics, by David Freedman, Robert Pisani, Roger Purves and Ani Adhikari, 2nd ed., Norton.\nThe notable statistician Karl Pearson (1857 - 1936) carried out a study to investigate the resemblance between children and their parents. As part of the study, Pearson measured the heights of 1078 parents and of their children at maturity. The heights of the children are plotted against the heights of the parents in the plots below, where we distinguish between father-son and mother-daughter pairs.\nThe taller a father, the taller his sons tend to be. It is the same with mothers and daughters.\nThere is a positive association between a father’s height and the height of his sons.\nBut there is a lot variation - the association is weak.\nIf you know the height of a father, how much does that tell you about the height of his sons?\nConsider fathers who are about about 67 inches tall, and look at the wide variation in the heights of their sons - - all the points between the two vertical dotted lines. The same is true for the daughters of mother who are about 63 inches tall.\nIf there is a strong association between two variables, then knowing one helps a lot in predicting the other. But when there is a weak association, information about one variable does not help much in guessing the other. When there is no association, it does not help at all.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#correlation",
    "href": "correlation.html#correlation",
    "title": "8  Correlation",
    "section": "",
    "text": "8.1.1 The correlation coefficient\nSuppose we are looking at the relationship between two variables and have already plotted the scatter plot. The graph looks like a cloud of points.\nHow can we summarise it numerically?\nThe first thing we can do is to mark a point that shows the average of the x-values and the average of the y-values. This is the point of averages. It marks the centre of the cloud.\nThe next step is to measure the width of the cloud from side to side, in both the x and the y directions. This can be done using the standard deviations (SD) of the x and y values. Remember that if both x and y are normally distributed, then 95% of the data will lie within about 2 (1.96 if we want to be pernickety) standard deviations of the mean, in each direction.\n\n\n\n\n\n\n\n\n\nSo far, our summary statistics are:\n\nmean of the x values, SD of the x values.\nmean of the y values, SD of the y values.\n\nThese statistics tell us where the centre of the cloud is and how far spread out it is both vertically and horizontally, but they do not tell the whole story.\nConsider the following two sets of data plotted below. Both have the same centre and the same spread.\n\n\n\n\n\n\n\n\n\nHowever the points in the first cloud are tightly clustered around a line - there is a strong linear association between the two variables. In the second cloud, the clustering is much looser. The strength of the association is different in the two diagrams. To measure the association, one more summary statistic is needed - the correlation coefficient.\nThis coefficient is usually abbreviated as r, for no good reason.\n\nThe correlation coefficient is a measure of linear association or clustering around a line. The relationship between two variables can be summarized by:\n\nthe average of the x-values, the SD of the x-values.\nthe average of the y-values, the SD of the y-values.\nthe correlation coefficient r\n\n\n\n\n8.1.2 Different values of r.\nLet us see how this looks graphically. In the Figure below we show six scatter plots for hypothetical data. In all six pictures the average is 3 and the standard deviation is 1 for both x and y. The correlation coefficient is printed in each case.\n\n\n\n\n\n\n\n\n\nThe one top left shows a correlation of 0 and the cloud is completely formless. As x increases, y shows no tendency to increase or decrease. It just straggles around.\nThe next diagram has r = 0.4 and a linear pattern is just starting to emerge. The next has r = 0.6 with a stronger linear pattern, and so on. The closer r is to 1 the stronger is the linear association and the more tightly clustered are the points around a line.\nA correlation of 1, which does not appear in the Figure is often referred to as a perfect correlation. It means that all the points lie exactly on a line so there is a perfect linear correlation between the two variables. Correlation coefficients are always between -1 and 1.\nThe correlation between the heights of identical twins is around 0.95. A scatter diagram for the heights of twins would thus look like the bottom right diagram in the Figure. We see that even with a coefficient this big there is a still a fair degree of scatter. The heights of identical twins are far from being equal all the time.\nReal data in the life sciences never shows perfect correlation and rarely does it even show strong correlation. It is more common for it to look like Pearson’s father-son data, with weak associations and r values in the range 0.3 to 0.7. This is even more true for data from the social sciences which concern human behaviour.\nWe can also have negative associations between variables. For example women with more education tend to have fewer children. Animals with higher body weight tend to have lower metabolic rates. As one variable increases, the other decreases. When there is negative association, the correlation coefficient has a negative sign.\nBelow we show six examples of negative correlation. As in the previous figure, all the data sets have a mean of 3 and a standard deviation of 1.\n\n\n\n\n\n\n\n\n\n\nCorrelations are always between -1 and 1, but can take any value in between. A positive correlation means that the cloud slopes up: as one variable increases, so does the other. A negative correlation means that the cloud slopes down. As one variable increases, the other decreases.\n\n\n\n8.1.3 Using R to find the correlation coefficient.\nFirst, let us try to find the correlation between two sets of data where we know what the correlation coefficient is, because we created the data ourselves. We will take the x and y data used above for which the correlation coefficient was fixed to be 0.8\n\ncor.test(x,y,method=\"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  x and y\nt = 9.1069, df = 48, p-value = 4.94e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6647907 0.8794036\nsample estimates:\n      cor \n0.7958685 \n\n\nThere are different ways to calculate the correlation coefficient. Which of them is appropriate depends mainly on the type of data, and if they are numeric, whether they are normally distributed. If they are, then we use the Pearson method. If they are not, for example because they are ordinal data, then we use the Spearman’s Rank method and write method=“spearman” instead. In this case we can relax the requirement that there is a linear association between the data sets, but there does still need to be a monotonic relationship.\nIt is important to be able to interpret and report the output.\nFirst, understand that R is carrying out a test, the null hypothesis of which is that there is no correlation between the values of x and the values of y among the populations from which the x and y data were drawn, so that the correlation coefficient between x and y within those populations is zero. It then reports a p-value: how likely it is that you would have got the data you got for this sample of data if that null hypothesis were true. As with most tests, to do this it uses the data to calculate a so-called test-statistic. How it does this need not concern us here. The details will differ from test to test, and the name given will differ. Here it is called t. It also reports the number of independent pieces of information used to calculate that statistic. This is called the degrees of freedom, here denoted df. This usually (but not necessarily) has a value that is 1,2 or 3 less than the number of data points.\nThen it reports the p-value. A tiny (close to zero) value here means that it thinks it very unlikely that the samples would be as they are if the x and y variables were not correlated in the populations from which the samples were drawn. A high (by which we usually mean greater than 0.05) value means that there is a reasonable chance that the actual non-zero correlation coefficient could have been found between x and y in the samples, even though those values were not correlated in the wider populations from which the samples were drawn. In that case we would have found no evidence that the x and y data within the population were correlated. This doesn’t mean that they aren’t, just that we have insufficient evidence to reject the null hypothesis that they are not.\nThe p-value reported here is 4.3e-12. That is R’s way of saying what in standard form would be written 4.3 x 10-12. This is a really tiny value. It is 0.0000000000043, which is a very inconvenient way to write such a small number. Hence R’s way of doing it or the standard form way of doing it. In the context of a statistical test and when p is is that small we don’t care about its exact value, we simply note that it is very, very small. We thus can confidently reject the null hypothesis and assert that the data provide evidence that x and y are correlated, in this case positively.\nFurther, it reports the actual correlation coefficient. Here it finds r = 0.797, which we happen to know to be correct because we created this data set ourselves, and a 95% confidence interval for the coefficient. The precise meaning of the confidence interval is subtle, but it is a kind of error bar for the correlation coefficient r. It means that if we drew sample after sample from the population and calculated the confidence interval for r for each sample, then 95% of the time that interval would capture the true value of r. Thus, you can reasonably think of the confidence interval as being the range of values within which the true population correlation coefficient plausibly lies, given the value that was found for the sample.\nIf the p-value is small enough that we reject the null-hypothesis, then this confidence interval should not encompass zero. Why? Because any value inside the confidence interval is a plausible value for the population correlation coefficient andif we are going to reject the null hypothesis, then zero should not be a plausible value for the population correlation coefficient, given the data.\nIf the p-value is large enough that we do not reject the null hypothesis then this confidence interval will encompass zero. Why? Becuase if the confidence interval encompasses zero, then zero is a plausible value for the correlation coefficient and so we should not reject the null.\nHere, the confidence interval is from 0.67 to 0.88. This does not encompass zero. In fact it is far from zero, so is consistent with our finding a really small p-value. On both groundss, we reject the null.\nTo report the result of this test we would say something like:\n\nWe find evidence for a strong positive correlation between x and y (Pearson r =0.80, t=9.1, df=48, p&lt;0.001)\n\nNote that when the p-value is much less than 0.05 as it is here we do not normally report its exact value, but simply write p&lt;0.01, or p&lt;0.001, and so on. The point is that these ways of reporting it tell the reader that p is way less than 0.05. This is all they need to know to see that we can confidently reject the null hypothesis.\n\n\n8.1.4 Correlations for real data\nLet us look at the Iris data set that is built into R. It contains values for the Sepal Width, Sepal Length, Petal Width and Petal Length for samples of 50 plants from each of three species of Iris, setosa, versicolor and virginica. Here are the first few rows:\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nWe will look to see if the data allow us to reject the idea that sepal width and sepal length are not correlated within the wider populations of each of these species:\nFirst, let’s plot the data\n\niris |&gt;\n  ggplot(aes(x=Sepal.Width,y=Sepal.Length,colour=Species)) +\n  geom_point() +\n  labs(x=\"Sepal Width (mm)\",\n       y=\"Sepal Length (mm)\") +\n  facet_wrap(~Species,nrow=1,scales=\"free\") +\n  theme_classic() +\n  theme(legend.position=\"none\") +\n  theme(strip.background=element_blank())\n\n\n\n\n\n\n\n\n\n8.1.4.1 What we can tell from plotting the data\nHaving seen the plots, do you think it plausible that there is a linear relationship between sepal width and length? Only in this case can you use a Pearson correlation test (see below). If not linear, do you think there is at least a monotonic relationship between petal width and length (ie no peaks or troughs)? That, at least, would enable you to use a Spearman’s Rank correlation test. If neither are true, then you can’t use either test.\n\n\n8.1.4.2 Test for normality\nIt does look as though there is a plausibly linear relationship between sepal width and length, so we might be able to use the Pearson method for calculating correlation coefficient. This is the ‘parametric’ method that is more powerful than the ‘non-parametric’ alternative, the Spearman’s rank method.\nIn principle, however, this method requires that each group of the data be approximately normally distributed around its repective mean (that is what the word parametric is getting at), so we ought to test for this. We can do this either graphically or using a normality test such as the Shapiro wilk test. Let us do the latter here:\n\n\n# A tibble: 3 × 3\n  Species    Sepal.Length_p.val Sepal.Width_p.val\n  &lt;fct&gt;                   &lt;dbl&gt;             &lt;dbl&gt;\n1 setosa                  0.460             0.272\n2 versicolor              0.465             0.338\n3 virginica               0.258             0.181\n\n\nAll the p-values for this test are comfortably greater than 0.05 so we can reasonably presume that our data are drawn from normally distributed populations. This, plus the plausibly linear realtionships we have seen in the graphs means that can go ahead and use the Pearson method to calculate the correlation coefficient between sepal length and width for each species!\n\n\n8.1.4.3 Calculate the correlation coefficients\nLooking at each graph, it appears that there is a positive correlation for each species, but that this is weaker for versicolar and virginica than it is for setosa. Knowing the sepal width for that species gives you a much better idea of the sepal length, and vice-versa, than is true for the other two species.\nLet us find out:\n\niris |&gt;\n  group_by(Species) |&gt;\n  summarise(r=cor.test(Sepal.Width,Sepal.Length)$estimate,\n            lower.bound95=cor.test(Sepal.Width,Sepal.Length)$conf.int[1],\n            upper.bound95=cor.test(Sepal.Width,Sepal.Length)$conf.int[2],\n            \"p value\"=cor.test(Sepal.Width,Sepal.Length)$p.value) |&gt;\n  kbl(digits=3) |&gt;\n  kable_styling(full_width=0.7)\n\n\n\n\nSpecies\nr\nlower.bound95\nupper.bound95\np value\n\n\n\n\nsetosa\n0.743\n0.585\n0.846\n0.000\n\n\nversicolor\n0.526\n0.290\n0.702\n0.000\n\n\nvirginica\n0.457\n0.205\n0.653\n0.001\n\n\n\n\n\n\n\nThe table gives the estimated value for the Pearson correlation coefficient in each case, the lower and upper bound of the 95% confidence interval for that coefficient and the p-value.\nDo these output provide evidence for a correlation between sepal length and sepal width in each case?\n\n\n\n8.1.5 The problem of missing variables\nSuppose in the above analysis we had not distinguished between the three species. If we had plotted the speal length and width data we would have seen this:\n\niris |&gt;\n  ggplot(aes(x=Sepal.Width,y=Sepal.Length)) +\n  geom_point() +\n  labs(x=\"Sepal Width (mm)\",\n       y=\"Sepal Length (mm)\") +\n  theme_classic() +\n  theme(legend.position=\"none\") +\n  theme(strip.background=element_blank())\n\n\n\n\n\n\n\n\nThis looks like a weak negative correlation, as is confirmed by calculating the Spearman’s (in this case) rank correlation coefficient.\nThe message here is that failure to spot importnat ‘missing’ variables, in the case species, can lead to grossly misleading ideas as to whether two variables are correlated, and if so, how.\n\n\n8.1.6 The correlation coefficient measures the degree of linear association.\n\n8.1.6.1 Pearson correlation coefficient\nSometimes the Pearson correlation coefficient r is a poor measure of the degree of association within a data set. Outliers and non-linearity are two problem cases.\nConsider first a data set where there is a very strong association between variables, but where the data sset contains an outlier, and then a data set where there is a strong but non-linear association between variables. Here we mean by ‘strong’ that knowing the value of one variable gives you a very good idea of the value of the other.\n\n\n\n\n\n\n\n\n\nThe outlier in the left-hand figure above brings the correlation coefficient down to 0.08, which is close to zero. The correlation coefficient in the right-hand figure is similarly small at 0.249, despite that there is a strong association between the x and y data. The reason is that the association is non-linear.\n\n\n8.1.6.2 Spearman’s rank correlation coefficient rSp\nThe Spearman’s rank correlation coefficient is a valid measure of the association between two variables providing their relationship is monotonic - that is, continuously rising or flat, or continuously falling or flat. Linear relationships are monotonic, so the Spearman’s rank correlation coefficient is always a useful (if not necessarily the most powerful - Pearson would trump it if it could be used) measure of association for such cases, but it will still be valid when the relationship is monotonic but non-linear, whereas the Pearson correlation coefficient would not be.\n\nSpearman’s rank correlation coefficient rSp can also be be used for ordinal data, whereas Pearson’s r coefficient cannot be. This makes it very useful in much of ecology, animal behaviour and environmental studies where ordinal scales are commonly used.\n\n\n\n8.1.7 When is it appropriate to calculate a correlation coefficient?\nSo, to sum up, we note that the Pearson correlation coefficient is a measure of linear association, not of association in general. At least, this is true if you are calculating the Pearson correlation coefficient. If your data are not suitable for that and you decide to calculate the Spearman’s Rank correlation coefficient, then the condition is relaxed somewhat: there might be but there no longer needs to be a linear relationship between the two variables, but there must be a monotonic one. That means that, as one variable increases, the other should either increase or remain constant, or decrease or remain constant - that is, there should be no peaks or troughs in the data.\n\n\n8.1.8 Association is not causation\nA very important and often-repeated point to note is that correlation measures association. But association is not the same as causation.\nSee Spurious Correlations for some amusing examples.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#examples",
    "href": "correlation.html#examples",
    "title": "8  Correlation",
    "section": "8.2 Examples",
    "text": "8.2 Examples\n\n8.2.1 Cyclones\nCyclones are areas of low atmospheric pressure around which steep gradients in air pressure can cause strong winds to develop, which in turn may create large waves if the cylone is over the oceans. Depending on where they occur, these storms are variously also known as hurricanes and typhoons. Here we consider whether the peak wind speeds are associated with the depth of the low pressure at the eye of the storm, and whether the peak wave sizes are associated with how wide the storm is. If the answer to either of these questions is yes, then an outcome of practical importance - wind speed, wave height - can be predicted at least in part by a variable that can be measured easily - pressure, distance.\n\n8.2.1.1 South West Indian Ocean intense tropical cyclones 1973 - 2024\nPressure gradients cause winds so it is reasoable to ask whether there a correlation between the peak wind speed and minimum pressure at the eye of cyclones. Here we look at data for for intense tropical cyclones in the south west Indian Ocean over the period 1973-2024. The data are taken (scraped using the R package rvest!) from: https://en.wikipedia.org/wiki/List_of_South-West_Indian_Ocean_intense_tropical_cyclones . The original data sources are available on that site.\n\n\n\n\n\n\n\n\n\nIn this figure we see that there is a weak but significant negative correlation between the peak recorded wind speed and the minimum recorded pressure at the centre of intense tropical cyclones that occurred in the south west Indian Ocean between 1973 and 2024. Neither wind speed nor pressure were normally distributed, so the Spearman’s rank correlation coefficient rSp has been calculated, and not the Pearson r coefficient.\n\n\n8.2.1.2 Significant wave height vs size of cyclone\nHere we look at results displayed in Figure 3f of\n\nOh, Y. et al. (2023) ‘Optimal tropical cyclone size parameter for determining storm-induced maximum significant wave height’, Frontiers in Marine Science, 10, p. 1134579. Available at: https://doi.org/10.3389/fmars.2023.1134579.\nThe authors seek to determine whether there is an association between the size of a cylone, measured by the ‘R50’ distance measured outward from the storm centre to where the wind speeds have subsided to 50 kph, and the maximum ‘significant wave height’ of the swell created by the storm. Significant wave height is a widely used measure that is the average height of the heighest 1/3 of the waves, these being the ones that impact most on practical matters like the fuel consumption of ships, the erosion of shores, and so on.\n\n\n\n\n\n\n\n\n\nThe plot shows that there is a monotonically rising relationship between the R50 radius of the cyclones included in the study and the maximum significant wave height of swell created by them. The relationship is not linear however, so the only appropriate measure of correlation coefficient is the Spearman’s rank, which gives \\(r_{sp} = 0.948, p&lt;0.001\\), indicating a very strong positive association between the size of a cyclone and the height of the waves it creates.\n\nWhy do you think this relationship flattens off for larger storm sizes?\n\n\n\n\n8.2.2 Lichen abundance\n\nJovan, S. (2008). Lichen Bioindication of Biodiversity, Air Quality, and Climate: Baseline Results From Monitoring in Washington, Oregon, and California. http://gis.nacse.org/lichenair/doc/Jovan2008.pdf\n\nIn this paper the authors investigate the utility of using lichen as bioindicators of air quality. is there an association between air quality and the abundance of this or that species of lichen?\n\n\n\n\n\n\n\n\n\n\nWe note that the relationship between air quality score and proportion of nitrophyte abundance is plausibly linear.\n\n\nThere is a strong negative correlation (rSp=-0.78, p&lt;0.001) between air quality score and proportion of nitrophyte lichen. This suggests that this proportion can be used as a bioindicator of air quality.\n\n\nA Spearman’s rank correlation coefficient was calculated in this case rather than a Pearson correlation coefficient, despite the fact that both the x and y variables are plausibly drawn from normally distributed populations of values, according to a Shapiro-Wilk test. The problem is that both the air quality score and the proportion of nitrophyte abundance are ordinal variables - something we learn from reading the paper in which this figure appears. This means that analysis using parametric tests such as the Pearson method for determining linear correlation are not appropriate. A non-parametric method such as Spearman’s rank method can be used instead.\n\n\n\n8.2.3 Soil bacteria\n\nLauber, C. L., Hamady, M., Knight, R., & Fierer, N. (2009). Pyrosequencing-based assessment of soil pH as a predictor of soil bacterial community structure at the continental scale. Applied and Environmental Microbiology, 75(15), 5111–5120. https://doi.org/10.1128/AEM.00335-09\n\n\n\n\n\n\n\n\n\n\nIn the Figure above, note that the Pearson r-values for C and E are close to zero, and the p-values are greater than 0.1, meaning that at this significance level there is no evidence from these data that there is any linear association between soil pH and the relative abundances of Alphaproteobacteria or Beta/Gammaproteobacteria. From the plots, it looks in C as if there no assocation at all, whereas in E it looks as though there might be, but if so then not a linear or even monotonic association, for which the correlation coefficient (Pearson r or Spearman rSp) would be a poor measure.\n\n\n8.2.4 Birds\n\nPain, D.J., Mateo, R. and Green, R.E. (2019) ‘Effects of lead from ammunition on birds and other wildlife: A review and update’, Ambio, 48(9), pp. 935–953. https://doi.org/10.1007/s13280-019-01159-0\n\n\n\n\n\n\n\n\n\n\nThis figure is from a study on the impact on bird populations of ingestion of lead from spent lead ammunition arising from hunting using rifles and shot guns. For several species of wetland birds, the population trend (as measured by a proxy scale) is plotted against the prevalence of carcasses found to contain lead shot.\nThere is a clear negative trend here that is plausibly linear, or at least monotonic. Shapiro-Wilk tests show that neither data set is plausibly drawn from a normally distributed population, so a Spearman’s rank correlation coefficient is calculated. The result is \\(r_{\\text{Sp}} = -0.697, p &lt; 0.01\\) so we can say that there is a evidence of a significant and strong negative correlation between lead shot ingestion of waterbird species and their population trends.\n\n\n8.2.5 Heart rate vs life expectancy\n\n\n\n\n\n\n\n\n\nHere we see a strong negative linear correlation between the life expectancy of different species and the log of the mean heart rate in beats per minute. On this plot, humans are almost an outlier. In this case, use of a Shapirro Wilk test showed that both life expectancy and log of the heart rate were found to be consistent with being drawn from normally distributed populations, so the Pearson method was used to calculate the correlation coefficient.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#exercise-1",
    "href": "correlation.html#exercise-1",
    "title": "8  Correlation",
    "section": "8.3 Exercise 1",
    "text": "8.3 Exercise 1\n\n\n\n\n\n\n\n\n\nPlots A to F above show scatter plots of different data sets Y against X.\n\nWhich of them show linear behaviour?\nWhich of them show monotonic behaviour?\nFor which of them might it be appropriate to calculate the following correlation coefficients between X and Y?\n\nPearson r\nSpearman rank rsp",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#exercise-2",
    "href": "correlation.html#exercise-2",
    "title": "8  Correlation",
    "section": "8.4 Exercise 2",
    "text": "8.4 Exercise 2\nMeasurements were made on female Adelie penguins on a series of islands in the Antarctic. The bill lengths and depths of 73 individuals were recorded and are shown in the plot below.\n\n\n\n\n\n\n\n\n\nFrom this information and plot, decide\n\nWhether it is plausible that there is a linear relationship between the bill depths and lengths within the data set\nWhether the correlation coefficient within the data set is likely to be positive or negative\nWhether the correlation is ‘strong’ or ‘weak’ ie is the absolute value of the correlation coefficient likely to be close to 1 or close to zero\nWhether there might be evidence from this data that there is any correlation between bill depth and bill length in the population from which this data set was drawn.\n\n\n8.4.0.1 Tests for normality\nShapiro-Wilk tests are carried out to check for normality of the two sets of data:\n\nshapiro.test(bill_depths)\n\n\n    Shapiro-Wilk normality test\n\ndata:  bill_depths\nW = 0.9831, p-value = 0.4364\n\n\n\nshapiro.test(bill_lengths)\n\n\n    Shapiro-Wilk normality test\n\ndata:  bill_lengths\nW = 0.99117, p-value = 0.8952\n\n\nOn this basis, we see that we can use the Pearson method to calculate the correlation coefficient between bill depth and bill length. What is telling us this?\n\n\n8.4.0.2 Calculate correlation coefficient\nFor these data, we calculate the correlation coefficient using the Pearson method.\n\n# Pearson\ncor.test(bill_depths,bill_lengths, method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  bill_depths and bill_lengths\nt = 1.3714, df = 71, p-value = 0.1746\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.07209557  0.37677877\nsample estimates:\n      cor \n0.1606361 \n\n\nWhich part(s) of this output tell us that:\n\nThere is a weak positive correlation between bill length and depth within the sample?\nThere is no evidence that this correlation exists in the wider population from which this data set was drawn?\n\nHow would you report this result?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "correlation.html#exercise-3",
    "href": "correlation.html#exercise-3",
    "title": "8  Correlation",
    "section": "8.5 Exercise 3",
    "text": "8.5 Exercise 3\nOpen a new R notebook\nIn the usual way, include to start with code chunks to\n\nLoad the packages needed tidyverse and here.\nRead the data set iris.csv (which should be in your data folder already) into an object called iris\n\nYou can do this with this code chunk:\n```{r}     \nfilepath&lt;-here(\"data\",\"iris.csv\")\niris&lt;-read_csv(filepath)\nglimpse(iris)\n```\n\nCreate a faceted plot of sepal length against sepal width for each species.\nCalculate the Pearson correlation coefficient between sepal length and sepal width for each species, and display this, plus the lower and upper bounds of the confidence interval and the p-value for each species in a table.\n\nFor (4) and (5) you can adapt code used on the main Correlation tab.\nNow:\n\nDoes it appear that the sepal length and sepal width are correlated for each species?\n\nIs the correlation positive or negative?\n\nFor which species is the correlation strongest?\n\nDo the correlation coefficients make sense, given the plots?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "r4nqy",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html",
    "href": "tests_for_difference_two_levels.html",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "",
    "text": "3.1 Test finder flow chart\nIn this document we consider tests for difference where there are two levels being compared.\nFirst, use this flowchart to see if a two-sample t-test or its non-parametric counterpart the Mann-Whitney-U test is appropriate for your question, your study design and your data:\nflowchart TD\n  A{Difference or Trend \\nQuestion?} --&gt; B[Trend]\n  B --&gt; B2{Are you testing for \\ndegree of association\\nor are you trying \\nto make predictions?}\n  B2 --&gt; B33[Association:\\n\\nTest for\\n correlation coefficient\\nPearson or \\n Spearman's Rank]\n  B2 --&gt; B44[Predictions:\\n\\nSimple linear regression]\n  A --&gt; C[Difference]\n  C --&gt; C22{Do you have replicates?}\n  C22 --&gt; C22Y[Yes]\n  C22 --&gt; C22N[No]\n  C22N --&gt; C23{Do you have count data?}\n  C23 --&gt; C23Y[Yes]\n  C23 --&gt; C23N[N0]\n  C23Y --&gt; C24(Chi square test:\\nGoodness of fit\\nor\\nTest of independence)\n  C23N --&gt; C25[These data cannot be analysed]\n  C22Y --&gt; D{How many factors?}\n  D --&gt; F[Two or more]\n  F --&gt; F2{Independent\\nsamples?}\n  F2 --&gt; F2Y[Yes]\n  F2 --&gt; F2N[No]\n  F2Y --&gt; F22Y(n-way ANOVA)\n  F2N --&gt; F22N(n-way\\nrepeated measures\\nANOVA)\n  D --&gt; E[One]\n  E --&gt; G{How many levels?}\n  G --&gt; H[Two]\n  G --&gt; I[More than two]\n  I --&gt; J{Independent\\n samples?}\n  J --&gt; K[No]\n  J --&gt; L[Yes]\n  K --&gt; S(Repeated measures one-way ANOVA\\nor\\nFriedman Test)\n  L --&gt; T(One way ANOVA\\nor\\nKruskal Wallis one-way test)\n  H --&gt; M{Independent\\n samples?}\n  M --&gt; N[No]\n  M --&gt; O[Yes]\n  N --&gt; P(paired t-test\\nor\\nSigned rank test)\n  O --&gt; Q(two sample t-test\\nor\\nMatt Whitney U test)\nIf this chart suggests you need something other than the two sample t-test or Mann-Whitney test, you need to go to the descriptions of that test.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html#two-sample-t-test-the-parametric-case",
    "href": "tests_for_difference_two_levels.html#two-sample-t-test-the-parametric-case",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "3.2 Two sample t-test: the parametric case",
    "text": "3.2 Two sample t-test: the parametric case\nIn this exercise we find out how to run a two-sample t-test, to determine whether there is evidence to reject the hypothesis that two samples are drawn from the same population.\n\n3.2.1 When to use the two-sample t-test\n\nIt can be used when we have two independent samples of numerical (not ordinal) response data, and our question is whether the data provide evidence that the samples are drawn from different populations. Even when this criterion is met and the data are numerical and independent, the normality criterion described below still needs to be met. That apart, two common examples where we have two sets of data but we should not use the two sample t-test are:\n\nIf the data in your two samples are not independent because you have measured the same individual replicate before and after some event or treatment, then you should probably be using a paired t-test instead. In this you don’t have two samples, each comprising a separate and independent set of replicates. Instead, you have multiple pairs of values, one pair per replicate. The replicates are still assumed to be independent of each other\nIf your response data are the answers to a Likert scale such as might be used in a survey then they are ordinal in nature and not numerical, and you should probably be using the non-parametric equivalent of the two sample t-test, which is variously known as the Wilcoxon Rank Sum test or as the Mann Whitney U test, or its paired sample version, if appropriate.\n\nIt can be used when the data set is small. But not so small that there are no replicates. You do need replicates.\nIt can still be used when the data set is large.\nIt assumes that the data are drawn from a normally distributed population. There are various ways to test if this is plausibly the case, and you should try at least one of them, but with small samples, just where the t-test is most useful, it can be difficult to tell. In the end we can also appeal to reason: is there good reason to suppose that the data would or would not be normally distributed?\nWhen comparing the means of two samples, both samples should in principle have the same variance, which is a measure of the spread of the data, so in principle you need to check that this is at least approximately the case, or have reason to suppose that it should be. However, in an actual t-test done using R, the Welch variant of the t-test is carried out by default. This works even when the variances of the two sets are different, so in practice it is possible to ignore this equal variance requirement.\nWe only use it when we are comparing two samples, one for each of the two levels of a single factor. When we have samples for more than two levels and we use the t-test to look for a difference between any two of them, it becomes increasingly likely, the more pairs of samples we compare, that we will decide that we have found a difference because we got a p-value that was less than some pre-determined threshold (which could be anything, but is most often chosen to be 0.05) even if in reality there is none. This is the problem of high false positive rates arising from multiple pairwise testing and is where ANOVA comes in. t-tests are only used to detect evidence for a difference between two groups, not more. ANOVAs (or their non-parametric equivalent) are used when we are looking for differences between more than two groups.\n\n\n\n3.2.2 Motivation and example\nIn our example we will consider the impact of pesticide use on the masses of shells of garden snails (Cornu aspersum), as measured in gardens around a city, ten from randomly selected gardens that have used a range of pesticides for at least two years and ten that are from randomly selected gardens that have not ever used pesticides. We leave aside here the issue of how those gardens were identified and how randomisation was ensured.\n\n\n3.2.3 Questions and hypotheses\nOur question is:\nIs there evidence for a difference between snail shell masses in the gardens where pesticides were used compared to those where they were not used?\nFrom which a suitable null hypothesis is:\nThere is no difference between shell masses in the gardens, whether or not pesticides were used.\nand a suitable alternate, two-sided hypothesis is:\nThere is a difference between shell masses.\n\n\n3.2.4 The data\nSuppose we had our data arranged in a spreadsheet in three columns, one giving the garden ID, G1 to G20, one telling us whether pesticides were used in the garden, yes or no, and one telling us the masses in grams of the snail shells from each garden. Afficioados of R will see that this is ‘tidy’ data. Each variable (ID, pesticide use, shell mass) occurs in only one column, rather than being spread across several. It turns out that this way of storing your data makes it much easier to analyse.\n\n# there should be a 'garden_snails.csv' file in your data folder\n\nfilepath&lt;-here(\"data\",\"garden_snails.csv\")\nsnails&lt;-read_csv(filepath)\n\n# if not, you should be able to get it from Mike's github repo\n\n# file_url &lt;- \"https://raw.githubusercontent.com/mbh038/r-workshop/refs/heads/gh-pages/data/garden_snails.csv\"\n# snails&lt;-read_csv(file_url)\nhead(snails,20)\n\n# A tibble: 20 × 3\n   garden.ID pesticide shell_mass_g\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;\n 1 S1        Yes               1.37\n 2 S2        Yes               1.15\n 3 S3        Yes               0.73\n 4 S4        Yes               0.65\n 5 S5        Yes               1.03\n 6 S6        Yes               1.8 \n 7 S7        Yes               1.21\n 8 S8        Yes               1.41\n 9 S9        Yes               1.27\n10 S10       Yes               1.08\n11 S11       No                2   \n12 S12       No                3.99\n13 S13       No                1.99\n14 S14       No                1.75\n15 S15       No                2.81\n16 S16       No                2.15\n17 S17       No                1.87\n18 S18       No                3.46\n19 S19       No                2.8 \n20 S20       No                2.89\n\n\n\nIs this a tidy data set?\nIs the data in the pesticide column categorical?\nIf so, how many levels does it have and what are they?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html#the-process",
    "href": "tests_for_difference_two_levels.html#the-process",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "3.3 The Process",
    "text": "3.3 The Process\n\n3.3.1 Step One: Summarise the data\nWith numerical data spread across more than one level of a categorical variable, we often want summary information such as mean values and standard errors of the mean for each level.\nHere we will calculate the number of replicates, the mean and the standard error of the mean for both levels of pesticide ie Yes and No:\n\nsnail.summary&lt;- snails |&gt;\ngroup_by(pesticide) |&gt;\nsummarise(n = n(),\n          mean.mass = mean(shell_mass_g),\n          se.mass = sd(shell_mass_g)/sqrt(n()))\nsnail.summary\n\n# A tibble: 2 × 4\n  pesticide     n mean.mass se.mass\n  &lt;chr&gt;     &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 No           10      2.57   0.236\n2 Yes          10      1.17   0.105\n\n\nFrom these data, does it look as though there is evidence for a difference between shell masses in the two types of garden? Clearly, the snails in the ten gardens that did not use pesticide had a higher mean shell mass than the ten from gardens that did use pesticide. But is this a fluke? How precisely do we think these sample means reflect the truth about the impact of the use of pesticides? That is what the standard error column tells us. You can think of the standard error as being an estimate of how far our sample means, drawn from just ten gardens of each type are likely to differ from the true shell masses for all gardens that did use pesticides and all gardens that did not.\nBottom line: the difference between the sample means is about ten times the size of the standard errors of each. It really does look as though snails shells in gardens where pesticides are not used are indeed heavier than in gardens where pesticides are used.\n\n\n3.3.2 Step Two: Plot the data\nRemember, before we do any statistical analysis, it is almost always a good idea to plot the data in some way. We can often get a very good idea as to the answer to our research question just from the plots we do.\nIn Figure 3.1, we will use ggplot() in R to plot a histogram of ozone levels, one for each side of the city. We will stack the histograms one above the other, all the better to help us spot any differences between east and west.\n\nsnails |&gt;\n  ggplot(aes(x=shell_mass_g)) +\n  geom_histogram(binwidth=0.2,fill=\"darkred\")+\n  facet_wrap(~pesticide,ncol=1) +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 3.1: Stacked histograms\n\n\n\n\n\nInstead of histograms, we could have drawn box plots, as in:\n\nsnails |&gt;\n  ggplot(aes(x=pesticide,y=shell_mass_g))+\n  geom_boxplot()+\n  labs(x=\"Pestice use?\",\n       y=\"Shell mass (g)\") +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 3.2: Side-byside box and whisker plots of the distribution of values in each snail sample. The lower and upper edges of each box show the 25th and 75th percentiles of each sample, and the thick black line between them shows the median value ie the 50th percentile\n\n\n\n\n\nor as a dot plot of the means with standard errors of the mean included as error bars, as in Figure 3.3\n\n# for this chart we will use the summary table that we created above.\n\nsnail.summary |&gt; \n  ggplot(aes(x=pesticide,y=mean.mass))+\n  geom_point(size=3) +\n  geom_errorbar(aes(ymin=mean.mass-se.mass,ymax=mean.mass+se.mass),width=0.1)+\n  ylim(0,4) + # try leaving this line out. What happens? Which is better?\n  labs(x=\"Pesticide use?\",\n       y=\"Shell mass (g)\") +\n  theme_classic()\n\n\n\n\n\n\n\nFigure 3.3: The data points show mean values, the error bars show plus or minus one standard error of the mean\n\n\n\n\n\n\nDo the data look as though they are inconsistent with the null hypothesis ?\nIn addition, do the data look as though each group is drawn from a normally distributed population? One of the types of graphs gives you no indication of that while the other two do. Which is the odd one out? Even when looking at the other two figures, when there are so few data it’s kind of hard to tell, no?\n\nLet’s now do some stats.\n\n\n3.3.3 Step Three: Check the validity of the data - are the data normally distributed?\nWe can go about establishing this in three ways: using an analytical test of normality, using a graphical method and by thinking about what kind of data we have. Let’s consider these in turn.\n\n3.3.3.1 Normality test - analytical method\nThere are several analytical tests one can run on a set of data to determine if it is plausible that it has been drawn from a normally distributed population. One is the Shapiro-Wilk test.\nFor more information on the Shapiro-Wilk test in R, type ?shapiro.test into the console window. For kicks, try it out on the examples that appear in the help window (which is the bottom right pane, Help tab). One example is testing a sample of data that explicitly is drawn from a normal distribution, the other tests a sample of data that definitely is not. What p-value do you get in each case? How closely do the histograms of each sample resemble a normal distribution?\n\n#first we create a data frame containing the two example data sets\nexample1&lt;-rnorm(500, mean = 5, sd = 3) # first example from the help pane\nexample2&lt;-runif(500, min = 2, max = 4) # second example from the help pane\n\ndf&lt;-tibble(data=c(example1,example2), distribution=c(rep(\"example 1: normal\",500),rep(\"example 2: not at all normal\",500)))\n\n# then we plot a histogram of each data set\nggplot(df,aes(x=data)) +\n  geom_histogram(bins=20,fill=\"cornflowerblue\") +\n  facet_wrap(~distribution) +\n  theme_classic()\n\n\n\n\n\n\n\n# and finally we run a Shapiro-Wilk normality test on each data set\nshapiro.test(example1) # 100 samples drawn from a normally distributed population\n\n\n    Shapiro-Wilk normality test\n\ndata:  example1\nW = 0.99782, p-value = 0.7733\n\nshapiro.test(example2) # 100 samples drawn from a uniformly (ie NOT normally) distributed population\n\n\n    Shapiro-Wilk normality test\n\ndata:  example2\nW = 0.94548, p-value = 1.346e-12\n\n\nFor the examples above, we see that Shapiro-Wilk test gave a high p-value for the data that we knew were drawn from a normal distribution, and a very low p-value for the data that we knew were not.\nThe Shapiro-Wilk test tests your data against the null hypothesis that it is drawn from a normally distributed population. It gives a p-value which, as always, is the probably of you having data as far from normality, or further, as yours are if the null hypothesis were true. If the p-value is less than 0.05 then we reject the null hypothesis and cannot suppose our data is drawn froma normally distributed population. In that case we would have to ditch the t-test for a difference, and choose another difference test in its place that could cope with data that was not normally distributed. For a two-sample t-test such as we are hoping to use here, the so-called non-parametric alternative that we could use instead is the Wilcoxon Rank Sum test, often called the Mann-Whitney U test.\nWhy don’t we do that in the first place, I hear you ask? Why bother with this finicky t-test that requires that we go through the faff of testing the data for normality before we can use it? The answer is that it is more powerful than other, so-called non-parametric tests that can cope with non-normal data. It is more likely than they are to spot a difference if there really is a difference. So if we can use it, that is what we would rather do.\nSo, onwards, let’s do the Shapiro-Wilk test on our data\nWe want to test each garden group for normality, so we group the data by location as before and and then summarise, this time asking for the p-value returned by the Shapiro-Wilk test of normality.\n\nsnails |&gt;\n  group_by(pesticide) |&gt;\n  summarise('Shapiro-Wilk p-value'=shapiro.test(shell_mass_g)$p.value)\n\n# A tibble: 2 × 2\n  pesticide `Shapiro-Wilk p-value`\n  &lt;chr&gt;                      &lt;dbl&gt;\n1 No                         0.223\n2 Yes                        0.854\n\n\nFor both groups the p-value is more than 0.05, so at the 5% significance level we cannot reject the null hypothesis that the data are normally distributed, so we can go on and use the t-test. Yay!\n\n\n3.3.3.2 Graphical methods - the quantile-quantile or QQ plot.\nConfession: I don’t normally bother with numerical tests for normality such as Shapiro-Wilk. I usually use a graphical method instead.\nWe have already seen two ways of plotting the data that might help suggest whether it is plausible that the data are drawn from normally distributed populations. Histograms and box plots both indicate how data is distributed, and for normally distributed data both would be symmetrical. Well, they would be, more or less, if the data set was large enough but for small data sets it can be quite hard to tell from either type of plot whether the data are drawn from a normally distributed population.\nA better type of plot for making this judgement call is the quantile-quantile or ‘qq’ plot which basically compares the distribution of your data to that of a normal distribution. If your data are approximately normally distributed then a qq plot will give a straight(-ish) line. Even with small data sets, this is usually easy to spot.\n\nsnails |&gt;\n  ggplot(aes(sample=shell_mass_g)) +\n  stat_qq(colour=\"blue\") +\n  stat_qq_line() +\n  facet_wrap(~pesticide) +\n  theme_classic()\n\n\n\n\n\n\n\n\nNothing outrageously non-linear there, so that also suggests we can safely use the t-test.\nFor an overview of how normally distributed and non-normally distributed data looks when plotted in histograms, box plots and quantile-quantile plots, see this review\n\n\n3.3.3.3 The ‘thinking about the data’ normality test\nAs you might have guessed, this isn’t a test as such, but a suggestion that you think about what kind of data you have: is it likely to be normally distributed within its subgroups or not? If the data are numerical values of some physical quantity that is the result of many independent processes, and if the data are not bounded on either side (say by 0 and 100 as for exam scores) then it is quite likely that that they are. If they are count data, or ordinal data, then it is quite likely that they are not.\nThis way of thinking may be all you can do when data sets are very small and any of the more robust tests for normality presented here leave you not much the wiser.\n\n\n\n3.3.4 Do the actual two-sample t-test\nSo, it looks as though it is plausible that the data are drawn from normal distributions. That means we can go on to use a parametric test such as a two sample t-test and have confidence in its output.\nIf we were doing this in R we could use the t.test() function for this (other functions are available!). This needs to be given a formula and a data set as arguments. Look up t.test() in R’s help documentation, and see if you can get the t-test to tell you whether there is a significant difference between ozone levels in the east and in the west of the city.\n\nt.test(shell_mass_g~pesticide,data=snails)\n\n\n    Welch Two Sample t-test\n\ndata:  shell_mass_g by pesticide\nt = 5.4172, df = 12.442, p-value = 0.0001372\nalternative hypothesis: true difference in means between group No and group Yes is not equal to 0\n95 percent confidence interval:\n 0.8397234 1.9622766\nsample estimates:\n mean in group No mean in group Yes \n            2.571             1.170 \n\n\n\n\n3.3.5 Interpret the output of the t-test.\nStudy the output of the t-test. Here are some questions to ask yourself.\n\nWhat kind of test was carried out?\n\nA Welch two sample t-test\n\nWhat data was used for the test?\n\nThe snail shell mass in g (the output variable) and pesticide use (the explanatory variable)\n\nWhat is the test statistic of the data?\n\nThis is t = 5.4172.\n\nHow many degrees of freedom were there? This number is the number of independent pices of information that were used to calculate the final result. It is usually one, two, or three or so less than the number of data points. Don’t overthink it at this stage, especially not the fact that here it is not an integer.\n\ndf = 12.442\n\nWhat is the p-value?\n\np = 0.0001372. You would most likely report this as p &lt; 0.001\n\nWhat does the p value mean?\n\nIt is the likelihood of seeing a difference between sample means as large or larger than the one we found if in fact pesticides made no difference to snail shell mass.\n\nWhat is the confidence interval for the difference between shell masses in gardens that use pesticides and in gardens that do not? Does it encompass zero? Remember that the confidence interval gives the range of values within which the true difference between mean shell masses might reasonably lie, given the data. If that range includes zero then the test is telling is that zero is a plausible value for the difference, and hence that we cannot reject the null hypothesis.\n\nThe 95% confidence interval has lower bound 0.8397 and upper bound 1.962.\n\nIs there sufficient evidence to reject the null hypothesis?\n\nYes. We see this in two ways. First the p value is much less than 0.05 and second, the 95% confidence interval does not encompass zero. In a way, the confidence interval is giving us more information than the p-value, since not only can we deduce whether there is evidence for a significant difference, we can also see how big that difference is and how precisely we know it.\n\nWhat does the word ‘Welch’ tell you - Google it or look it up in the help for t.test().\n\nIt tells us that a variant of the t-test is being used in which it does not matter if the two. samples have difference variances (spreads).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html#other-examples-where-a-two-sample-t-test-might-be-used.",
    "href": "tests_for_difference_two_levels.html#other-examples-where-a-two-sample-t-test-might-be-used.",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "3.4 Other examples where a two sample t-test might be used.",
    "text": "3.4 Other examples where a two sample t-test might be used.\nRemember that t-tests in general are used when you have independent samples with multiple replicates drawn from populations corresponding to two levels of some factor (eg north coast, south coast; this beach, that beach; polluted place, clean place etc) and you have measured something numerical, like a length or a mass, temperature or concentration. You still have to do the tests for normality described above, but these are the basic criteria.\n\n3.4.1 Can you think of examples of where you might use a two-sample t-test?\nHere are a few suggestions:\n\nIs there a difference between the flight initiation distance of redstarts when confronted by dogs compared to when they are confronted by drones?\nIs the nitrate concentration of water in a river below a beaver dam different from the nitrate content above that dam?\n\nCan you think of another example?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html#what-if-i-cant-use-a-two-sample-t-test",
    "href": "tests_for_difference_two_levels.html#what-if-i-cant-use-a-two-sample-t-test",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "3.5 What if I can’t use a two sample t-test?",
    "text": "3.5 What if I can’t use a two sample t-test?\n\nAssuming you have two independent samples, this might be because one or both sets failed the normality criterion, or your data are ordinal. In that case the likely alternative is the non-parametric equivalent of the t-test, variously known as the Wilcoxon Rank Sum test or the Mann Whitney U test.\nIf your data are in fact sets of paired values, for example because you measured some attribute of the same individuals before and after some treatment, or at two points in time, then you need to use the paired t-test.\nIf you only have one sample of replicates and want to compare its mean value to a threshold, then you use a one sample t-test. You might do this, for example, if you had collected sediment samples from an estuary, measured the concentration in those samples of some pollutant such as pathogens from sewage, or phosphates from farm runoff, and then wanted to see if the water was compliant with water quality thresholds as dictated by, say, the Water Framework Directive.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html#the-non-parametric-case",
    "href": "tests_for_difference_two_levels.html#the-non-parametric-case",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "3.6 The non-parametric case",
    "text": "3.6 The non-parametric case\nA common scenario is that we have two sets of measurements, and we want to see if there is evidence that they are drawn from different populations. For some data types we can use a t-test to do this, but for others we cannot.\nA t-test requires in particular that the two sets of data are normally distributed around their respective means. With ordinal data this makes no sense. The mean is undefined as a concept for such data.\nTo see this , reflect that for a collection \\(X\\) of numerical data, say, 5, 3, 3, 4, and 5 we would calculate the mean as:\n\\[\n\\bar{X} = \\frac{5+3+3+4+5}{5} = \\frac{20}{5}=4\n\\]\nBut trying doing the same to five responses of a Likert scale survey. Say the responses you had to five Likert items (individual questions) were “strongly disagree”, “strongly agree”, “mildly disagree”, “strongly disagree” and “don’t care either way”. If you tried to calculate a ‘mean’ response you would be attempting to add up all these responses and to divide the ‘sum’ by five, like this:\n\\[\\text{mean response}=\\frac{\\text{stongly disagree}+\\text{strongly agree}+\\text{mildly disagree}+\\text{stongly disagree}+\\text{don't care either way}}{5} = ?\n\\] This sum makes no sense, I hope you will agree. It makes no sense, not because we are using words to describe our responses, but because, as these are ordinal data, we do not know the size of the gaps between the different points on the scale. Is the difference in agreement between the lowest two, “strongly disagree” and “midly disagree” the same as the gap between the highest two, “mildly agree” and “strongly agree”? We don’t know, mainly because ‘agreement’ is not something that can be measured easily using something like a weighing machine. And if we don’t know, then we shouldn’t really be adding these responses up or dividing them by anything.\nNevertheless, ordinal data are very common, since they are typically what is generated by survey data, where for example repondents may answer a series of questions (‘items’), each with typically five possible responses, but maybe more or fewer, these responses being ordinal in the sense that there is a definite order to them. They might encompass responses like those above, say, or something similar like “very unhappy” to “very happy”. They are also common in clinical and veterinary practice where ordinal pain scores are widely used - patients being asked (if they are human) or assessed as to their level of pain on a scale of 1-10, for example. Note that even if the pain value is recorded as a number it is actually a label, that could just as well have been recorded as one of a series of letters, A, B, C etc or emojis, or any symbol you like. You can’t take the average of a set of faces!\nThus, formally, we need another kind of test for a difference. Broadly, we need to use some form of non-parametric test where we do not assume that the data has any form of distribution, and where, often, we do not use the actual values of the measurements in our dataset but instead use only their ranks. The smallest value would be given rank 1, the next rank 2 and so on.\nThere are many non-parametric tests out there. Here we will look at only one - the Wilcoxon Rank Sum Test, often referred to as a Mann-Whitney U test for a difference. We can use this for the scenario we have painted above, where we have two sets of data and we wish to know if these provide evidence that the populations from which the samples have been drawn are in fact different.\n\n3.6.1 Example\nThis example uses actual data gathered by a student at Newquay University Centre.\nThe student wished to assess peoples’ sense of wellbeing using two different sets of questions designed to assess this. The scales chosen were the Warwick–Edinburgh Mental Well-being Scale (WEMWBS) and the New Ecological Paradigm (NEP) Scale. The student wished in particular to determine whether this sense of well-being was affected by whether a person often and actively frequented the coast and made it and the sea a substantive part of their life in one way or another. ie to find out whether there was evidence to support the notion that it could be good for your mental wellbeing to be by the sea and to make it part of your life.\nEach scale used consists of 15 questions or ‘Likert items’, each of which is answered on a 5 point ordinal scale, where a score of 1 indicates lowest wellbeing and a score of 5 indicates highest wellbeing. Thus each respondent could score anything from 15 to 75.\nThe student got responses from 374 people, 86 of whom were not “marine” users, while the other 288 say that they were marine users. The total scores from each respondent were recorded for each type of survey and stored in the file wellness.csv which you should find on the module Moodle site / Teams page. Please put this file in the data folder of your R project.\n\n\n3.6.2 Script\nCode chunks for a script to carry out the analysis of this data are provided below. To use them you should create a new Quarto document using File/New File/Quarto document, from which you delete all the exemplar material below the yaml section at the top. The first few chunks of this script carry out the same old-same old that we see in script after script: load packages, load data, summarise data , plot data. Copy and paste any chunks you want to use into your own script then adapt them as necessary.\nYou can run your script by running each chunk in sequence, which you do by clicking the green arrow in the top-right corner of each chunk.\nTry also to ‘Render’ the script by clicking on the Render button at the top of the script pane.\n\n3.6.2.1 Load packages\n\nlibrary(tidyverse)\nlibrary(here)\n\n\n\n3.6.2.2 Load data\nOur data set is in a .csv file which we have placed in the data folder within our project folder.\nNote that this data set has been stored in ‘tidy’ form: each variable appears in only column, and each observation appears in only one row.\n\nfilepath&lt;-here(\"data\",\"wellness.csv\")\nwellness&lt;-read_csv(filepath)\nglimpse(wellness)\n\nRows: 748\nColumns: 4\n$ id          &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ scale       &lt;chr&gt; \"WEMWBS\", \"WEMWBS\", \"WEMWBS\", \"WEMWBS\", \"WEMWBS\", \"WEMWBS\"…\n$ marine      &lt;chr&gt; \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\",…\n$ total_score &lt;dbl&gt; 48, 51, 37, 39, 38, 40, 54, 39, 54, 39, 51, 50, 49, 51, 54…\n\n\n\n\n3.6.2.3 Summarise the data\nWe’ll calculate the median score (50th percentile) and the 25th and 75th percentile scores. For ordinal data, these summary statistics are well defined, whereas means and standard deviations are not.\n\nwellness |&gt;\n  group_by(scale,marine) |&gt;\n  summarise(median.score=median(total_score),iqr_25=quantile(total_score,0.25),iqr_75=quantile(total_score,0.75))\n\n# A tibble: 4 × 5\n# Groups:   scale [2]\n  scale  marine median.score iqr_25 iqr_75\n  &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 WEMWBS No             42.5   36       49\n2 WEMWBS Yes            47     41       51\n3 nep    No             51     48.2     53\n4 nep    Yes            50     48       53\n\n\n\n\n3.6.2.4 Plot the data\nBox plots are particularly suitable for ordinal data since they show the 25th and 75th percentiles of the data (the bottom and top of the box) plus the 50th percentile aka the median, which is the thick line across each box. All of these percentiles are well defined quantities for ordinal data.\n\nwellness |&gt;\n  ggplot(aes(x = scale,y = total_score,fill = marine)) +\n  geom_boxplot() +\n  labs(x = \"Likert Scale\",\n       y = \"Wellbeing Score\") +\n  theme_classic()\n\n\n\n\n\n\n\n\nLooking at the plot, what do you think each scale suggests about whether proximity to the sea makes a difference to wellbeing?\n\n\n3.6.2.5 Wilcoxon-Mann-Whitney U test\nFirst let’s pull out the scores as measured by the WEMWBS scale and do a test for a difference between the scores of marine users and those of non-marine users. We can use the filter() function to do this.\n\nWEMWBS&lt;-wellness |&gt; filter(scale==\"WEMWBS\") # save the WEMWBS data into a data frame called WEMWBS\nglimpse(WEMWBS)\n\nRows: 374\nColumns: 4\n$ id          &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ scale       &lt;chr&gt; \"WEMWBS\", \"WEMWBS\", \"WEMWBS\", \"WEMWBS\", \"WEMWBS\", \"WEMWBS\"…\n$ marine      &lt;chr&gt; \"Yes\", \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\",…\n$ total_score &lt;dbl&gt; 48, 51, 37, 39, 38, 40, 54, 39, 54, 39, 51, 50, 49, 51, 54…\n\n\nNow let’s do the actual Wilcoxon-Mann-Whitney U test:\n\nwilcox.test(total_score~marine,data=WEMWBS)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  total_score by marine\nW = 9077.5, p-value = 0.0001687\nalternative hypothesis: true location shift is not equal to 0\n\n\nThe null hypothesis of this test is that there is no evidence that the data are drawn from different populations. In this case, the p-value is very small, so we can confidently reject that null hypothesis and assert that there is evidence, according to the WEMWBS scale that marine use makes a difference to peoples’ sense of wellbeing.\nDoes it make it worse or better? - we can see from the summary table and from the box plot that higher scores are associated with those people who were exposed to a marine environment.\nWe might report this results as follows, first using a plain English statement of the main finding, and then reporting the type of test use, the value of the test statistic that it calculated and the p value. In this case, because the p value is so small, we would not report its exact value, but simply give an indication of how small it is:\nWe find evidence, according to the WEMWBS scale, that the wellbeing score is 4.5 or about 10% higher for people exposed to a marine environment (Mann-Whitney U, W = 9077.5, p &lt; 0.001).\n\n\n\n3.6.3 Exercise\nAdapt the code of the last chunk so that you can do the same test but for data as recorded by the nep scale\n\n\n3.6.4 When should I use this Wilcoxon-Mann-Whitney U test?\nThe test we have used here is an example of a non-parametric test. This means that it does not assume that the data follow a known mathematical distribution and, further, that it can be used with ordinal data.\nWe used the Mann-Whitney U test in particular because we were testing for a difference, and because the factor of interest - marine exposure - had just two levels - Yes or No. This test is only suitable when there are just two levels, so you can think of it as as a non-parametric alternative to a t-test.\nIn another setting where we still had just one factor (eg zone of a rocky shore) but there were more than two levels (eg low, mid and high zones of the shore) and we decided that we wanted to do a non-parametric test for a difference, then we would probably use the Kruskal-Wallis test, which you can think of as the non-parametric alternative to a one-way ANOVA.\nIn this example we used the Mann-Whitney U test because the data were ordinal and thus not suitable to use with a parametric test (but see below!). Where we can, we usually try to use a parametric test as they are more powerful than their non-parametric equivalents, meaning, if there is a trend or a difference in the data, they are better able to detect it. However those parametric tests (t-test, ANOVA, pearson correlation, PCA, GLM to name but a few) typically require not only that the data are numerical but also a host of other things, including that they follow a particular distribution, usually (but not always) the normal distribution, and this is often not the case with real biological data. Often, especially with count data, there are lots of zeros, or the data distribution is heavily skewed, usually to the right. In these cases, providing the data are independent of each other, we can usually still use a non-parametric test such as we have here. it might not be the most powerful test we can use (GLMs are typically way better if you can use them), but it will work.\n\n\n3.6.5 Hang on!\nThe eagle eyed among you may have spotted a massive flaw in the line of argument presented above. We said that ordinal data can’t be added up, can’t be used to calculate averages and so on. Thus we can’t run parametric tests on them and have to look for alternatives, namely, non-parametric tests.\nAnd yet, these non-parametric tests are usually run on the output of Likert scales such as we have considered here, where for each person we have a number of Likert Items (ie individual questions) that together constitute the scale, that each generate a score 1-5, then we add up the scores to get a total score. But that means we are adding up ordinal data!!!\nIt turns out that you actually get much the same results with Likert scale data if you analyse them using supposedly inappropriate parametric tests such as a 2-sample t-test as you do if you use a non-parametric test such as the one we considered here, the Mann-Whitney test.\nA study by De Winter and Dodou (2010) shows this convincingly.\nde Winter, J. F. C., & Dodou, D. (2010). Five-Point Likert Items: t test versus Mann-Whitney-Wilcoxon (Addendum added October 2012). Practical Assessment, Research, and Evaluation,15, 1–16. https://doi.org/10.7275/bj1p-ts64\nFor an enlightening discussion of this paper, see this blog by Jim Frost",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  },
  {
    "objectID": "tests_for_difference_two_levels.html#paired-data",
    "href": "tests_for_difference_two_levels.html#paired-data",
    "title": "3  Tests for difference: one factor, two levels",
    "section": "3.7 Paired data",
    "text": "3.7 Paired data\nOften one has a sample of replicated data where each element has a counterpart in another matched sample - paired data. A common scenario for this is when there are data for the same individual at two different points in time, for example before and after some event such as the application of a treatment.\nIn order to determine whether there is a difference between the two sets, one should take the paired aspect into account and not simply match the whole before-set against the whole after-set without doing this. That would be to throw away the information whereby there is likely to be a greater degree of correlation between the responses of an individual before and after the event than there is between any randomly chosen pairs of individuals before and after the event.\n\n3.7.1 Which test: paired t-test or Wilcoxon signed rank test?\nThere is a choice between at least two tests: the parametric paired t-test and the non-parametric Wilcoxon signed rank test. Ideally one would use the t-test since it is more powerful than the Wilcoxon test. This means several things, but in particular it means that, all else being equal, it can detect a small difference with higher probability than the Wilcoxon test can.\n\n\n3.7.2 The paired t-test\nWhere the data are numerical (ie not ordinal) and where the before and after data are both normally distributed around their respective mean values one would use the paired t-test in this scenario. One can test for normality using either a test such as the Shapiro-Wilk test, or graphically using either a histogram, a box plot, or (best), a quantile-quantile plot.\n\n\n3.7.3 The Wilcoxon Signed Rank test\nThe t-test, an example of a so-called parametric test, is actually pretty robust against departures from normality, but where one doubts its validity due to extreme non-normality or for other reasons such as the ordinal nature of the data, the Wilcoxon signed rank test is a useful non-parametric alternative. It is called non-parametric because it does not make any assumption about the distribution of the data values. It only uses their ranks, where the smallest value gets rank 1, the next smallest gets rank 2, and so on.\nSo, you typically use this test when you would like to use the paired t-test, but you cannot because one or both of the data sets is way off being normally distributed or is ordinal.\n\n3.7.3.1 Null Hypotheses\nIn both the t-test and the Wilcoxon signed rank tests, the null hypothesis is the usual ‘nothing going on’, ‘there is no difference’ scenario, but there is a subtle difference between them that reflects the different information that they use. In the Wilcoxon signed rank test the null is that the difference between the medians of pairs of observations is zero. This is different from the null hypothesis of the paired t–test, which is that the difference between the means of pairs is zero.\n\n\n3.7.3.2 Test output\nBoth tests will give a p value. This is the probability that the mean (t-test) or median (Wilcoxon signed rank) paired differences between the corresponding before and after sample elements would be equal to or greater than it actually is for the data if the null hypothesis were true. If the p value is less than some pre-decided ‘significance level’, usually taken to be 0.05, then we reject the null hypothesis. If it is not, then we fail to reject the null hypothesis.\n\n\n\n3.7.4 Example\nWe will use as an example a data set from Laureysens et al. (2004) that has measurements of metal content in the wood of 13 poplar clones growing in a polluted area, once from each clone in August and once again from each of them in November. The idea was to investigate the extent to which poplars could absorb metals from the soil and thus be useful in cleaning that up. Under a null hypothesis, there would be no change in the metal concentrations in the plant tissue of each clone between August and November. Under an alternate hypothesis, there would be.\nLaureysens, I. et al. (2004) ‘Clonal variation in heavy metal accumulation and biomass production in a poplar coppice culture: I. Seasonal variation in leaf, wood and bark concentrations’, Environmental Pollution, 131(3), pp. 485–494. Available at: https://doi.org/10.1016/j.envpol.2004.02.009.\nConcentrations of aluminum (in micrograms of Al per gram of wood) are shown below.\nLoad packages\n\nlibrary (tidyverse)\nlibrary(here)\nlibrary(cowplot) # to make the plots look nice\n\nLoad data\n\nfilepath &lt;- here(\"data\",\"poplars-paired_np.csv\")\npoplars &lt;- read_csv(filepath,show_col_types = FALSE)\nhead(poplars,20)\n\n# A tibble: 13 × 4\n      ID Clone          August November\n   &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n 1     1 Balsam_Spire      8.1     11.2\n 2     2 Beaupre          10       16.3\n 3     3 Hazendans        16.5     15.3\n 4     4 Hoogvorst        13.6     15.6\n 5     5 Raspalje          9.5     10.5\n 6     6 Unal              8.3     15.5\n 7     7 Columbia_River   18.3     12.7\n 8     8 Fritzi_Pauley    13.3     11.1\n 9     9 Trichobel         7.9     19.9\n10    10 Gaver             8.1     20.4\n11    11 Gibecq            8.9     14.2\n12    12 Primo            12.6     12.7\n13    13 Wolterson        13.4     36.8\n\n\nPlot the data\nBefore we do any test on some data to find evidence for a difference or a trend, it is a good idea to plot the data. This will reveal whatever patterns there are in the data and how likely they are to reveal a truth about the population from which they have been drawn.\nTidy the data\nIn this case there is work to do before we can plot the data. The problem is that the data is ‘untidy’. The two levels of the factor month are spread across two columns, August and November. For plotting purposes it will be useful to ‘tidy’ the data so that there is only one column containing both levels of month and another containing the aluminium concentrations. The function pivot_longer() can do this for us:\n\npoplars_tidy &lt;- poplars |&gt;\n  pivot_longer (August:November,names_to=\"month\",values_to=\"Al_conc\")\nhead(poplars_tidy,8)\n\n# A tibble: 8 × 4\n     ID Clone        month    Al_conc\n  &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt;\n1     1 Balsam_Spire August       8.1\n2     1 Balsam_Spire November    11.2\n3     2 Beaupre      August      10  \n4     2 Beaupre      November    16.3\n5     3 Hazendans    August      16.5\n6     3 Hazendans    November    15.3\n7     4 Hoogvorst    August      13.6\n8     4 Hoogvorst    November    15.6\n\n\nNow we can plot the data as a box plot, with one box for August and one for November ie one for each level of the factor month. Had we not first tidied the data, we could not have done this.\n\npoplars_tidy |&gt;\n  ggplot(aes(x = month, y = Al_conc, fill = month, colour = month)) + \n  # alpa (= opacity) &lt; 1 in case any points are on top of each other\n  geom_boxplot(outlier.size=0,alpha=0.5) +\n  geom_point(alpha = 0.5) +\n  # group = ID makes the lines join elements of each pair\n  geom_line(aes(group=ID),colour = \"grey60\") +\n  labs(x = \"Month\",\n       y = \"Al conc.(mu g Al / g wood)\") +\n  theme_cowplot() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nDoes it look as though the difference between the medians could plausibly be zero for the population from which these samples were drawn? Or, put another way, if it was zero, how big a fluke would this sample be? That is what the p value actually tells us.\n\n\n3.7.5 Two sample paired t-test\nCheck for normality of differences\nBefore we use the t-test, we need to check that it is OK to do so. This means checking whether the paired differences are plausibly drawn from a normal distribution centred on zero.\nThe null hypothesis of the Shapiro-Wilk test is that the data set given to it is plausibly drawn from a normally distributed population. So let us give our sample of paired differences:\n\nshapiro.test(poplars$August-poplars$November)\n\n\n    Shapiro-Wilk normality test\n\ndata:  poplars$August - poplars$November\nW = 0.92667, p-value = 0.3081\n\n\nThe p value is very high. Thus we do not reject the null hypothesis and we can reasonably assume that the differences between the August and November aluminium concentrations in the sample could plausibly have been drawn from a normally distributed population, despite the outlier value in the November sample. Thus we can reasonably test for difference using a paired t-test.\nThe actual t-test\nWe can do this in R using the function t.test(), where we give to the function both the August and the November data, knowing that each August value has a counterpart November value, and we set the argument paired to TRUE.\n\nt.test(poplars$August, poplars$November, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  poplars$August and poplars$November\nt = -2.3089, df = 12, p-value = 0.03956\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -9.5239348 -0.2760652\nsample estimates:\nmean difference \n           -4.9 \n\n\nAll parts of the output have meaning and are useful, but here we will focus on just two:\n\nthe p value is equal to 0.040. Hence, if we have chosen the usual significance value of 0.05, we can take this to mean that there is evidence of a significant difference between the August and November values.\nthe lower and upper bounds of the 95% confidence interval are (-9.52, -0.28). YOu can think of this interval as the range of values within which the difference can plausibly lie, at the 95% confidence level. The key thing is that this range does not encompass zero. This means that we can be confident at the 95% level that there is a non-zero change on going from August to November, and, in particular, that the August value is lower than the November value.\n\n\n\n3.7.6 The non-parametric alternative: The Wilcoxon signed rank test\nTo be safe, because of that outlier, let us test for difference using the Wilcoxon signed rank test. In R this is done using the function wilcox.test(), with the argument paired set to TRUE.\n\nwilcox.test(poplars$August, poplars$November, paired = TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  poplars$August and poplars$November\nV = 16, p-value = 0.03979\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe see that the conclusion (in this case) is the same.\n\n\n3.7.7 Relation to one-sample paired test\nThe two-sample paired tests as we have done above are the same as doing a one-sample test to see if the differences between the August and November paired values is different from zero. This is true whether we do a t-test or a Wilcoxon signed rank test.\nIn either case, the first argument is the vector of differences, and the second mu is the threshold value against which we want to compare those differences, in this case zero.\n\nt.test(poplars$August - poplars$November, mu = 0, data = poplars)\n\n\n    One Sample t-test\n\ndata:  poplars$August - poplars$November\nt = -2.3089, df = 12, p-value = 0.03956\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -9.5239348 -0.2760652\nsample estimates:\nmean of x \n     -4.9 \n\n\n\nwilcox.test(poplars$August - poplars$November, mu = 0, data = poplars)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  poplars$August - poplars$November\nV = 16, p-value = 0.03979\nalternative hypothesis: true location is not equal to 0\n\n\nNote that the output from both these one-sample tests, where the one sample is the vector of differences and the threshold with which it is compared is zero, is exactly the same as the output of the two-sample tests where the two samples were the vectors between which we were interested in detecting a difference, ie the August and November values. This is not surprising since the two cases are just two ways of doing exactly the same thing, which is to ask if there is evidence from the sample for a difference in the population between the August and November concentrations of aluminium.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Tests for difference: one factor, two levels</span>"
    ]
  }
]