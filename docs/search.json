[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "r4nqy",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "ANOVA_how_it_works.html",
    "href": "ANOVA_how_it_works.html",
    "title": "3  ANOVA principles",
    "section": "",
    "text": "3.1 What is ANOVA?\nMaterial used from Chapter One of Grafen and Hails: Modern Statistics for the Life Sciences",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA principles</span>"
    ]
  },
  {
    "objectID": "ANOVA_how_it_works.html#what-is-anova",
    "href": "ANOVA_how_it_works.html#what-is-anova",
    "title": "3  ANOVA principles",
    "section": "",
    "text": "3.1.1 The basic principles of ANOVA\nIn a simple case we consider the comparison of three means. This is done by the analysis of variance (ANOVA). In this case we will go through an example in detail and work out all the mechanics, but once we have done that and seen how the output is derived from the input we will not need to do it again. We will use R to do the heavy lifting. We will just need to know when it is appropriate to use ANOVA, how to get R to do it and how to interpret the output that R produces.\n\n\n3.1.2 The Scenario\nSuppose we have three fertilizers and wish to compare their efficacy. This has been done in a field experiment where each fertilizer is applied to 10 plots and the 30 plots are later harvested, with the crop yields being calculated. We end up with three groups of 10 figures and we wish to know if there are any differences between these groups.\nWhen we plot the data we see that the fertilizers do differ in the amount of yield produced but that there is also a lot of variation between the plots that were given the same fertilizer.\n\n\n\n\n\n\n\n\n\n\n\n3.1.3 What does an ANOVA do?\nAn ANOVA (ANalysis Of VAriance) analysis attempts to determine whether the differences between the effect of the fertilizers is significant by investigating the variability in the data. We investigate how the variability between groups compares to the variability within groups.\n\n\n3.1.4 Grand Mean\nFirst we calculate the ‘grand mean’, the mean of the yields across all 30 plots:\n\n\n[1] 4.643667\n\n\n\n3.1.4.1 Deviations from the grand mean\n\n\n\n\n\n\n\n\n\n\n\n3.1.4.2 Mean value of yield for each fertilizer\n\n\n# A tibble: 3 × 2\n  FERTIL fmean\n  &lt;fct&gt;  &lt;dbl&gt;\n1 1       5.44\n2 2       4.00\n3 3       4.49\n\n\n\n\n\n3.1.5 Measures of variability\n\n3.1.5.1 SST - Total sum of squares\n\n\n[1] 36.4449\n\n\nSST is the total sum of squares. It is the sum of squares of the deviations of the data around the grand mean. This is a measure of the total variability of the data set.\n\n\n3.1.5.2 SSE - Error sum of squares\nSSE is the error sum of squares. It is the sum of the squares of the deviations of the data around the three separate group means. This is a measure of the variation between plots that have been given the same fertilizer.\n\n\n3.1.5.3 SSF - Fertilizer sum of squares\nSSF is the fertilizer sum of squares. This is the sum of the squares of the deviations of the group means from the grand mean. This is a measure of the variation between plots given different fertilizers.\n\n\n\n\n\n\n\n\n\nWhen the three group means are fitted, there is an obvious reduction in variability around the three means compared to that around the grand mean, but it is not obvious if the fertilizers have had an effect on yield.\nAt what point do we decide if the amount of variation explained by fitting the means is significant? By this, we mean, “When is the variability between the group means greater than we would expect by chance alone?\nFirst, we note that SSF and SSE partition between them the total variability in the data:\n\n\n\n3.1.6 SST = SSF + SSE\n\n\n[1] 36.4449\n\n\n[1] 10.82275\n\n\n[1] 25.62215\n\n\n[1] 36.4449\n\n\nSo the total variability has been divided into two components. That due to differences between plots given different treatments and that due to differences between plots given the same treatment. Variability must be due to one or other of these components. Separating the total SS into its component SS is known as partitioning the sums of squares.\nA comparison of SSF and SSE is going to indicate whether fitting the three fertilizer means accounts for a significant amount of variability.\nHowever, to make a proper comparison, we really need to compare the variability per degree of freedom ie the variance.\n\n\n3.1.7 Partitioning the degrees of freedom\nEvery sum of squares (SS) has been calculated using a number of independent pieces of information. In each, case, we call this number the number of degrees of freedom for the SS.\nFor SST this number is one less than the number of data points n. This is because when we calculate the deviations of each data point around a grand mean there are only n-1 of them that are independent, since by definition the sum of these deviations is zero, and so when n-1 of them have been calculated, the final one is pre-determined.\nSimilarly, when we calculate SSF, which measures the deviation of the group means from the grand mean, we have \\(k\\)-1 degrees of freedom, (where in the present example \\(k\\), the number of treatments, is equal to three) since the deviations must sum to zero, so when \\(k\\)-1 of them have been calculated, the last one is pre-determined.\nFinally, SSE, which measure deviation around the group means will have n-k degrees of freedom, since the sum of each of the deviations around one of the group means must sum to zero, and so when all but one of them have been calculated, the final one is pre-determined. There are \\(k\\) group means, so the total degrees of freedom for SSE is n-k.\nThe degrees of freedom are additive: \\[\ndf(\\text{SST}) = df(\\text{SSE}) + df(\\text{SSF})\n\\] Check:\n\\[\\begin{align*}\ndf(\\text{SST}) &= n-1\\\\\ndf(\\text{SSE}) &= k-1\\\\\ndf(\\text{SSF}) &= n-k\\\\\n\\therefore df(\\text{SSE}) + df(\\text{SSF}) &= k-1 + n-k\\\\\n&=n-1\\\\\n&=df(\\text{SST})\n\n\\end{align*}\\]\n\n\n3.1.8 Mean Squares\nNow we can calculate the variances which are a measure of the amount of variability per degree of freedom.\nIn this context, we call them mean squares. To find each one we divided each of the sums of squares (SS) by their corresponding degrees of freedom.\nFertiliser Mean Square (FMS) = SSF / k - 1. This is the variation per df between plots given different fertilisers.\nError Mean Square (EMS) = SSE / n - k. This is the variation per df between plots given the same fertiliser.\nTotal Mean Square (TMS) = SST / n - 1. This is the total variance per df of the dataset.\nUnlike the SS, the MS are not additive. That is, FMS + EMS \\(\\neq\\) TMS.\n\n\n3.1.9 F-ratios\nIf none of the fertilizers influenced yield, we would expect as much variation between the plots treated with the same fertilizer as between the plots treated with different fertilizers.\nWe can express this in terms of the mean squares: the mean square for fertilizer would be the same as the mean square for error:\n\\[\n\\frac{\\text{FMS}}{\\text{EMS}}=1\n\\] We call this ratio the F-ratio. It is the end result of ANOVA. F-ratios can never be negative since they are the ratio of two mean square values, both of which must be non-negative, but there is no limit to how large they can be.\nEven if the fertilizers were identical, the F-ratio is unlikely to be exactly 1 - it could by chance take a whole range of values. The F-distribution represents the range and likelihood of all possible F ratios under the null hypothesis. ie when the fertilizers were identical.\nThe shape of the F distribution depends on the degrees of freedom of FMS and EMS, and we normally specify it by giving the values of each. Below we show F distributions for 2 and 27 degrees of freedom (ie 3 plots, so k = 3, so the degrees of freedom of FMS = k-1 =2, and 10 plants per plot, so n = 3 x 10 =30, and hence the degrees of freedom of EMS = n-k = 30 - 3 = 27), and for 10 and 27 degrees of freedom.\n\n\n\n\n\n\n\n\n\nNote that, whatever the degrees of freedom, F-distributions are examples of so-called probability density functions. The area beneath them between any two values of F-ratio is equal to the probability of getting an F-ratio in that range. Hence the total area under the curves is equal to 1, since the F-ratio must take some value between zero and infinity, and the area under the tail to the right of any given F-ratio is the probability of getting an F-ratio bigger than that value.\nHence, the probability under the null hypothesis of getting an F-ratio as large or larger than the value we actually got is the area to the right of this F-ratio under the appropriate F distribution. We often call this probability the p-value. p for probability. p-values are the the probability of getting data as extreme (same F-ratio,) or more extreme (bigger F-ratio) as the data you got you got if the null hypothesis were true.\nIf the fertilizers were very different, then the FMS would be much greater than the EMS and the F-ratio would be greater than one. However it can be quite large even when there are no treatment differences. So how do we decide when the size of the F-ratio is due to treatment rather than to chance?\nTraditionally, we decide that it sufficiently larger than one to be due to treatment differences if it would be this large or larger under the null hypothesis only 5% or less of the time. If we had inside knowledge that the null hypothesis was in fact true then we would still get an F-ratio that large or larger 5% of the time.\nOur p-value ie the probability that the F-ratio would have been as large as it is or larger, under the null hypothesis, represents the strength of evidence against the null hypothesis. The smaller it is, the stronger the evidence, and only when it is less than 0.05 do we regard the evidence as strong enough to reject the null.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA principles</span>"
    ]
  },
  {
    "objectID": "ANOVA_how_it_works.html#anova-example-1",
    "href": "ANOVA_how_it_works.html#anova-example-1",
    "title": "3  ANOVA principles",
    "section": "3.2 ANOVA example 1",
    "text": "3.2 ANOVA example 1\nWe will carry out the ANOVA analysis of the fertilizer data discussed on the previous tab.\nOur question is whether yield depends on fertilizer.\nWhat is our null hypothesis?\nStart a new notebook with these two code chunks to begin with:\n```{r global-options, include=FALSE}\nknitr::opts_chunk$set(fig.width=12, fig.height=8, warning=FALSE, message=FALSE,echo=FALSE)\n```\n\n```{r load packages, message=FALSE,warning=FALSE,echo=FALSE}\nlibrary(tidyverse)\nlibrary(here)\nlibrary(cowplot)\nlibrary(gridExtra)\nlibrary(ggfortify)\n```\nLoad the fertilizer.csv data into an object call `fertilizer\nIs it tidy data? If not, tidy it.\nConvert the FERTIL column to a factor, using this code:\n```{r make_factor}\nfertilizer &lt;- fertilizer |&gt;\n  mutate(FERTIL=as.factor(FERTIL))\n```\nMake a box plot of yield vs fertilizer, like the one on the previous tab.\nNow use the lm() function to create the anova model (There are several ways to do this in R - this is just one)\n\nfertil.model&lt;-lm(YIELD~FERTIL,data=fertilizer)\n\nNow inspect the model:\n\nanova(fertil.model)\n\nAnalysis of Variance Table\n\nResponse: YIELD\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nFERTIL     2 10.823  5.4114  5.7024 0.008594 **\nResiduals 27 25.622  0.9490                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSo we find that we can reject the null hypothesis. There is thus evidence that fertilizer does affect yield (ANOVA, df = 2,27, F=5.7, p&lt; 0.01)\nWhat this test has not done so far is show us where the differences lie. An ANOVA is a holistic test that tells you whether or not there is evidence for a difference between at least one pair of groups being compared. To identify which gruopd, if any, are differeny, we need to do so-called post-hoc tests.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA principles</span>"
    ]
  },
  {
    "objectID": "ANOVA_how_it_works.html#anova-example-2",
    "href": "ANOVA_how_it_works.html#anova-example-2",
    "title": "3  ANOVA principles",
    "section": "3.3 ANOVA example 2",
    "text": "3.3 ANOVA example 2\nAn experiment was performed to compare four melon varieties. It was designed so that each variety was grown in six plots, but two plots growing variety 3 were accidentally destroyed.\nWe wish to find out if there is evidence for a difference in yield between the varieties.\n\n3.3.1 Null hypothesis\nWhat is the null hypothesis of this study?\nThe data are in the melons.csv dataset.\nWrite code chunks to\n\n\n3.3.2 Load data and inspect the data\n\n\nRows: 22\nColumns: 2\n$ YIELDM  &lt;dbl&gt; 25.12, 17.25, 26.42, 16.08, 22.15, 15.92, 40.25, 35.25, 31.98,…\n$ VARIETY &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4,…\n\n\n\n\n3.3.3 Prepare the data\nEnsure that the VARIETY column is a factor\n\n\n3.3.4 Plot the data\nCreate a scatter plot of the yield.\n\n\n\n\n\n\n\n\n\n\n\n3.3.5 Summarise the data\nCreate a summary table that shows the mean yield for each variety.\n\n\n# A tibble: 4 × 3\n  VARIETY     N  Mean\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;\n1 1           6  20.5\n2 2           6  37.4\n3 3           4  20.5\n4 4           6  29.9\n\n\n\n\n3.3.6 1-way ANOVA\n\n3.3.6.1 Create the model\n\nmelons.model&lt;-lm(YIELDM~VARIETY,data=melons)\n\n\n\n3.3.6.2 Check the validity of the model\n\nautoplot(melons.model,smooth.colour=NA) + theme_cowplot()\n\n\n\n\n\n\n\n\nDO the data look as though they meet the criteria for an ANOVA? - the variance of the residuals is roughly constant across all groups and the qq-plot is fairly straight. We could confirm with a normality test if we like. For example, we could use a Shapiro-Wilk test.\nWhat is the null hypothesis of this test?\n\nshapiro.test(melons.model$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  melons.model$residuals\nW = 0.94567, p-value = 0.2586\n\n\nWhat do we conclude from this test?\n\n\n3.3.6.3 Inspect the model\n\nanova(melons.model)\n\nAnalysis of Variance Table\n\nResponse: YIELDM\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nVARIETY    3 1115.28  371.76  23.798 1.735e-06 ***\nResiduals 18  281.19   15.62                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWhat conclusions would you draw from the output of this model and the table of mean yields for each variety?\n\n\n\n3.3.7 Confidence intervals of the means\nLet us find the 95% confidence intervals for each mean\nThese we calculate as\n\\[\n\\text{Mean}\\pm t_{\\text{crit}}\\text{SE}_{\\text{mean}}\n\\] For a 95% confidence interval and 18 degrees of freedom, \\(t_{\\text{crit}}\\) is 2.1, so we find that the intervals are:\n\n\n# A tibble: 4 × 4\n  VARIETY  Mean    LB    UB\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1        20.5  17.1  23.9\n2 2        37.4  34.0  40.8\n3 3        20.5  16.3  24.6\n4 4        29.9  26.5  33.3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA principles</span>"
    ]
  },
  {
    "objectID": "ANOVA_how_it_works.html#anova-example-2-solution",
    "href": "ANOVA_how_it_works.html#anova-example-2-solution",
    "title": "3  ANOVA principles",
    "section": "3.4 ANOVA example 2 solution",
    "text": "3.4 ANOVA example 2 solution\nAn experiment was performed to compare four melon varieties. It was designed so that each variety was grown in six plots, but two plots growing variety 3 were accidentally destroyed.\nWe wish to find out if there is evidence for a difference in yield between the varieties.\n\n3.4.1 Null hypothesis\nWhat is the null hypothesis of this study?\nThe data are in the melons.csv dataset.\nWrite code chunks to\n\n\n3.4.2 Load data and inspect the data\n\nfilepath&lt;-here(\"data\",\"melons.csv\")\nmelons&lt;-read_csv(filepath)\nglimpse(melons)\n\nRows: 22\nColumns: 2\n$ YIELDM  &lt;dbl&gt; 25.12, 17.25, 26.42, 16.08, 22.15, 15.92, 40.25, 35.25, 31.98,…\n$ VARIETY &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4,…\n\n\n\n\n3.4.3 Prepare the data\nEnsure that the VARIETY column is a factor\n\nmelons &lt;- melons |&gt;\n  mutate(VARIETY=as.factor(VARIETY))\n\n\n\n3.4.4 Plot the data\nCreate a scatter plot of the yield.\n\nmelons |&gt;\n  ggplot(aes(x=VARIETY,y=YIELDM)) +\n  geom_point() +\n  scale_y_continuous(limits=c(0,45),breaks=seq(0,45,5))+\n  labs(x = \"Melon variety\", y=\"Yield\") +\n  theme_cowplot()\n\n\n\n\n\n\n\n\n\n\n3.4.5 Summarise the data\nCreate a summary table that shows the mean yield for each variety.\n\nmelons |&gt;\n  group_by(VARIETY) |&gt;\n  summarise(\n    N=n(),\n    Mean=round(mean(YIELDM),2)\n  )\n\n# A tibble: 4 × 3\n  VARIETY     N  Mean\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;\n1 1           6  20.5\n2 2           6  37.4\n3 3           4  20.5\n4 4           6  29.9\n\n\n\n\n3.4.6 1-way ANOVA\n\n3.4.6.1 Create the model\n\nmelons.model&lt;-lm(YIELDM~VARIETY,data=melons)\n\n\n\n3.4.6.2 Check the validity of the model\n\nautoplot(melons.model,smooth.colour=NA) + theme_cowplot()\n\n\n\n\n\n\n\n\nThe data look as though they meet the criteria for an ANOVA - the variance of the residuals is roughly constant across all groups and the qq-plot is fairly straight. We could confirm with a normality test if we like. For example, we could use a Shapiro-Wilk test.\nThe null hypothesis of this test is that the residuals are drawn from a population that is normally distributed\n\nshapiro.test(melons.model$residuals)\n\n\n    Shapiro-Wilk normality test\n\ndata:  melons.model$residuals\nW = 0.94567, p-value = 0.2586\n\n\nSince p&gt;0.05 we conclude that there is no reason to reject the null hypothesis that the residuals are normally disributed.\n\n\n3.4.6.3 Inspect the model\n\nanova(melons.model)\n\nAnalysis of Variance Table\n\nResponse: YIELDM\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nVARIETY    3 1115.28  371.76  23.798 1.735e-06 ***\nResiduals 18  281.19   15.62                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nsummary(melons.model)\n\n\nCall:\nlm(formula = YIELDM ~ VARIETY, data = melons)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.4233 -2.2781 -0.5933  2.6694  5.9300 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  20.4900     1.6136  12.699 2.02e-10 ***\nVARIETY2     16.9133     2.2819   7.412 7.14e-07 ***\nVARIETY3     -0.0275     2.5513  -0.011  0.99152    \nVARIETY4      9.4067     2.2819   4.122  0.00064 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.952 on 18 degrees of freedom\nMultiple R-squared:  0.7986,    Adjusted R-squared:  0.7651 \nF-statistic:  23.8 on 3 and 18 DF,  p-value: 1.735e-06\n\n\nWhat conclusions would you draw from the output of this model and the table of mean yields for each variety?\nWe see that the null hypothesis is rejected with a p-value of less than 0.001. We conclude that there are significant differences in the mean yield of melons across the varieties. We estimate that variety 2 has the highest mean yield and varieties 1 and 3 have the lowest mean yields.\nThe unexplained variance ie the error s for each group is 15.6 with 18 degrees of freedom. So the standard error for each group is \\(\\frac{s}{\\sqrt{n}}\\) where s=\\(\\sqrt{15.6}\\) = 3.95 divided by the number of elements in each group, giving us standard errors of 1.97 for variety 3, and 1.61 for the other varieties.\n\n\n\n3.4.7 Confidence intervals of the means\nLet us find the 95% confidence intervals for each mean\nThese we calculate as\n\\[\n\\text{Mean}\\pm t_{\\text{crit}}\\text{SE}_{\\text{mean}}\n\\] For a 95% confidence interval and 18 degrees of freedom, \\(t_{\\text{crit}}\\) is 2.1, so we find that the intervals are:\n\n\n# A tibble: 4 × 4\n  VARIETY  Mean    LB    UB\n  &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1        20.5  17.1  23.9\n2 2        37.4  34.0  40.8\n3 3        20.5  16.3  24.6\n4 4        29.9  26.5  33.3",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>ANOVA principles</span>"
    ]
  },
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "2  A recommended analysis workflow",
    "section": "",
    "text": "This is intended as a rough outline of the sequence of steps one commonly goes through when working on scripts:\n\nBefore we start on the script: am I working in a Project?. If not, fix this!\nWhat is my question?\nLoad packages\nLoad data\nInspect Data\nClean up or tidy or manipulate the data in some way\nSummarise the data\nPlot the data\nDo statistical analysis\nDecide what all this has told you and report it in plain English.\n\nDetails will differ from script to script, but this sequence of steps is very common.\n\n2.0.1 Are you working within your Project?\nBefore we even think of the script, we need to make sure that we are working within our Project, or bad things will happen. If you are, the Project name will be at the top right of the RStudio window. If you are not, save the script you are working on, and go to File/Open Project and open your Project. If you haven’t even got a ‘Project’ or don’t know what that means then just make sure that everything you need for whatever you are working on is in one folder and then turn that folder into a Project. (So a ‘Project’ is just a regular folder that has been given superpowers.) You do that by going to File/New Project/Existing Directory. Then you navigate to your folder and click on Create Project. RStudio will then restart and you will see the name of your newly anointed Project folder at the top-right of the RStudio window, You know that a folder is a ‘Project’ because it will have a .Rproj file inside it.\nIf all this sounds complicated, don’t worry. It really isn’t. Just get someone to show you how to do it and you will be fine.\nNow, to the script itself:\n\n\n2.0.2 Statement of the question(s) to be investigated\nWithout thinking this through, you won’t know what your script is for…\nWhat is the analysis that will follow for? What question are you trying to answer? What hypotheses are you trying to test?\nSuppose we were trying to test the hypothesis that there is no difference between the petal widths of the setosa, versicolor and virginica species of iris. All we have to go on are the petal widths of the plants we happened to measure. From these measurements we want to make a statement about these three species in general.\n\n\n2.0.3 Open a notebook\nIn RStudio, go to File/New File/ R Notebook. Delete everything below the yaml section at the top. This strangeley named section is the bit between the two lines with three dashes in. For the most part, we will not need to worry about this section. We just should not delete it entirely. What is useful to do is to amend the title to something sensible, and to add author: \"your name\" and date: \"the date in any old format\" lines, so that your yaml will look something like this:\n---\ntitle: \"A typical workflow\"\nauthor: \"Who wrote this?\"\ndate: \"Today's date\"\noutput:\n  html_document:\n    df_print: paged\n---\nDelete everything beneath this yaml section. The big empty space that then leaves you with is where you write your code. Remember that in notebooks, the code goes in ‘chunks’ that are started and finished with by lines with three backticks. Any other text goes between the chunks and you can format this text using the simple rule of Markdown, available in the RStudio Help menu. Thus your script will end up looking something like this:\n---\ntitle: \"A typical workflow\"\nauthor: \"Who wrote this?\"\ndate: \"Today's date\"\noutput:\n  html_document:\n    df_print: paged\n---\n\n### First header \nAny text we want to add. Note that a code chunk starts with ```{r} and ends with ```\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) # some actual R code\n```\n:::\n\n### Second header \nAny text we want to add to explain what this next chunk does\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse) # some actual R code\n```\n:::\n\n\n2.0.4 Set-up chunk\nJust put this chunk in at the top. Worry about it later. Or don’t worry about it at all, if you prefer. It is there to suppress warnings and messages from appearing in the rendered version of your script.\n```{r, include=FALSE}\n# makes the rendered version look prettier\nknitr::opts_chunk$set(message=FALSE,warning=FALSE)\n```\n\n\n2.0.5 Load Packages\nYou will nearly always want the first five packages, and often you will appreciate the sixth, janitor. Others, such as vegan will be useful from time to time, depending on what you are doing. If any of these lines throw an error, it is most likely becuase you have not yet installed that package. Do so in the console pane (not in this script!) using the function install.packages(\"name of package\"). Then run this whole chunk again.\n\nlibrary(tidyverse)\nlibrary(here)\nlibrary(ggfortify)\nlibrary(readxl)\nlibrary(cowplot)\nlibrary(janitor)\nlibrary(vegan)\n\n\n\n2.0.6 Load data\nThere are several ways to do this, so details will differ depending on what file type your data is saved in and where it is stored.\nHere are two examples. In each case code here presumes that the data is stored in a subfolder called ‘data’ within the Project folder, and we use the function here() from the here package. In my experience this dramatically simplifies the business of finding your data, wherever your script is. It makes it easier for you to share your script with others and be confident that what worked for you will work for them. It does require that you are working within your project.\n\n2.0.6.1 (a) If from a csv file\nIf you have your data in a data subfolder within your project, this chunk will work. Just substitute the name of your data file\n\nfilepath&lt;-here(\"data\",\"iris.csv\")\niris&lt;-read_csv(filepath)\nglimpse(iris)\n\nRows: 150\nColumns: 5\n$ Sepal.Length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      &lt;chr&gt; \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa…\n\n\n\n\n2.0.6.2 (b) If from an Excel file\nYou will need to use read_excel() from the readxl package, and you have to specify the name of the worksheet that holds the data you want. You can, if you want, specify the exact range that is occupied by the data. However I suggest you avoid doing this unless it turns out that you need to do so. If your data is a nice, neat, rectangular block of rows and columns, you should find that you don’t need to specify the range.\n\nfilepath&lt;-here(\"data\",\"difference_data.xlsx\")\niris&lt;-read_excel(path = filepath,\n                 sheet = \"iris\", # delete the comma if you choose not to specify the range in the line below\n                 range= \"A1:F151\" # optional - try leaving it out first. Only include if necessary.\n                 ) |&gt;\n  clean_names()\nglimpse(iris)\n\nRows: 150\nColumns: 6\n$ id           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ sepal_width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ petal_length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ petal_width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ species      &lt;chr&gt; \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa…\n\n\n\n\n\n2.0.7 Clean / Manipulate the data\nOften we need to do some sort of data ‘wrangling’ to get the data into the form we want. For example we may wish to tidy it, to remove rows with missing values, to filter out rows from sites or time periods we don’t want to include in our analysis, to create new columns and so on.\nFor example, lets create a new data frame for just the setosa species of iris:\n\nsetosa &lt;- iris |&gt;\n  filter(species == \"setosa\") # filter picks out rows according to criteria being satisfied in some column\nglimpse(setosa)\n\nRows: 50\nColumns: 6\n$ id           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ sepal_width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ petal_length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ petal_width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ species      &lt;chr&gt; \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa…\n\n\nor maybe we just want the numeric columns:\n\niris_numeric &lt;- iris |&gt;\n  select(-species) # select() retains or leaves out particular columns. Here, we leave out the species column.\nglimpse(iris_numeric)\n\nRows: 150\nColumns: 5\n$ id           &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ sepal_length &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ sepal_width  &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ petal_length &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ petal_width  &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n\n\n\n\n2.0.8 Summarise the data\nWe nearly always want to do this. For example, let’s find the mean petal widths of the three species, the standard errors of those means and save the results to a data frame called petal_summary\n\npetal_summary&lt;-iris |&gt;\n  group_by(species) |&gt;\n  summarise(mean.Pwidth = mean(petal_width),\n            se.Pwidth = sd(petal_width/sqrt(n())))\npetal_summary\n\n# A tibble: 3 × 3\n  species    mean.Pwidth se.Pwidth\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;\n1 setosa           0.246    0.0149\n2 versicolor       1.33     0.0280\n3 virginica        2.03     0.0388\n\n\nWe can look at this table and already get an idea as to whether the petal widths are the same or are different for the three species.\n\n\n2.0.9 Plot the data\nThe next step is usually to plot the data in some way. We would typically use the ggplot2 package from tidyverse to do this.\n\n2.0.9.1 Bar plot with error bars\nWe could plot a bar plot with error bars, working from the summary data frame that we created:\n\npetal_summary |&gt;\n  ggplot(aes(x = species, y = mean.Pwidth)) +\n  geom_col(fill=\"#a6bddb\") + # this is the geom that gives us a bar plot when we have already done the calculations\n  geom_errorbar(aes(ymin = mean.Pwidth - se.Pwidth, ymax = mean.Pwidth + se.Pwidth), width = 0.15) +\n  labs( x = \"species\",\n        y = \"Mean petal width (mm)\",\n        caption = \"Error bars are ± one standard error of the mean\") + # important to say what these error bars denote\n  theme_cowplot()\n\n\n\n\n\n\n\n\nNote that we have given the bars a fill colour - we got this color from this site due to the cartographer Cynthia Brewer, who is behind the various incarnations of the Brewer package in R, which is great for getting colours that work well. We have used the same colour for each species since the x-axis labels already tell us which bar relates to which species. To use a different colour for each bar would imply there is some extra information encoded by colour. Since there is not, it serves no purpose to have different colours, and potentially confuses the reader. Remember always that a plot is intended to convey a message. Anything that detracts from that message should be avoided, however pretty you think it is.\nA couple of points could be made about this type of plot:\nFirst, what about those error bars? Three types of error bar are in common usage and there are arguments in favour and against the use of each of them: the standard deviation tells us about the spread of values in a sample, and is an estimate of the spread of values in a population, the standard error of the mean, as used here, is an estimate of the precision with which the sample means estimates the respective population means for each of the species, and a confidence interval, typically a 95% confidence interval, gives us the region within which we are (say) 95% confident that the true species mean petal width might plausibly lie. Which type of error bar you should use depends on which story you want to tell. Here, because we are interested in whether there is evidence of a difference in the mean petal width of different species, we have gone for the standard eror of the mean.\nRegardless of which error bar you use and why, you should always tell the reader which one you have gone for, as we have in the caption to the figure.\nA second point about this bar plot is that it doesn’t tell us very much, and indeed nothing that we didn’t already know. It only conveys the mean and standard error values for each species, which is information we already have, arguably more compactly and in more easily readable form, in the table we created. Further, it potentially obscures information that might come from knowing the distribution of the data.\nHere are three other plot types that do show the distribution of petal widths for each species and thus add extra information to what we already know from the summary table\n\n\n2.0.9.2 Box plot\n\niris |&gt;\n  ggplot(aes(x=species, y=petal_width)) + # what we want to plot\n  geom_boxplot(fill=\"#a6bddb\",notch=TRUE) + # what kind of plot we want\n  geom_jitter(width=0.1, colour = \"#f03b20\",alpha=0.5) +\n  labs (x = \"species\",\n        y = \"Petal Width (mm)\") +\n  theme_cowplot() # choose a theme to give the plot a 'look' that we like\n\n\n\n\n\n\n\n\nHere, we have added the points themselves on top of the box plot. When there are not too many data points, this can be useful. The ‘jitter’ adds some horizontal or vertical jitter, or both, so that the points do not lie on top of each other. In this case we see that the variability of petal widths is not the same for each species and that the data are roughly symmetrically distributed around the median values in each case. This information is useful in helping us determine which statistical test might be appropriate for these data.\n\n\n2.0.9.3 Violin plot\nA useful alternative to the box plot, especially when the data set is large, is the violin plot:\n\niris |&gt;\n  ggplot(aes(x = species, y = petal_width)) + # what we want to plot\n  geom_violin(fill=\"#a6bddb\",notch=TRUE) + # what kind of plot we want\n  #geom_jitter(width=0.1, colour = \"#f03b20\",alpha=0.5) +\n  labs (x = \"species\",\n        y = \"Petal Width (mm)\") +\n  theme_cowplot() # choose a theme to give the plot a 'look' that we like\n\n\n\n\n\n\n\n\nThe widths of the blobs (I am probably supposed to call them ‘violins’!) show us the distribution of the data - where they are widest is where the data are concentrated, while the height of the blobs shows us the range of variation of the data. The positions of the blobs tells us the mean petal widths of the different species and gives us an idea of the differences between them.\n\n\n2.0.9.4 Ridge plot\nA bit like a violin plot. This needs the package ggridges to be installed.\n\nlibrary(ggridges)\niris |&gt;\n  ggplot(aes(x = petal_width,y = species)) + # what we want to plot\n  geom_density_ridges(fill=\"#a6bddb\") + # what kind of plot we want\n  #geom_jitter(width=0.1, colour = \"#f03b20\",alpha=0.5) +\n  labs (x = \"Petal Width (mm)\",\n        y = \"species\") +\n  theme_cowplot() # choose a theme to give the plot a 'look' that we like\n\n\n\n\n\n\n\n\nHaving seen the summary and one of these plots of the data, would you be inclined to reject, or fail to reject, a null hypothesis that said that there was no difference between the petal widths of the three species?\n\n\n\n2.0.10 Statistical analysis\nOnly now do we move on to the statistical analysis to try to answer our intial question(s). But by now, after the summary and plot(s), we may already have a pretty good idea what that answer will turn out to be.\nThe exact form of the analysis could take many forms. In a typical ecology project you might carry out several types of analysis, each one complementing the other. Here, an appropriate analysis might be to use the linear model in the form of a one-way ANOVA, since we have one factor (species) with three levels (setosa, versicolor and virginica) and an output variable that is numeric and likely to be normally distributed. We can use the lm() function for this.\n\n2.0.10.1 Create the model object\n\npw.model &lt;-lm (petal_width ~ species, data = iris)\n\n\n\n2.0.10.2 Check the validity of the model\nWe won’t go into this here, but an important step is to check that the data satisfy the often finicky requirements of whatever statistical test we have decided to use. The autoplot() function form the ggfortify package is great for doing this graphically.\n\nautoplot( pw.model) + theme_cowplot()\n\n\n\n\n\n\n\n\nHere we note in particular that although the spread of data within each level is not roughly the same (top left figure)), the QQ plot is pretty straight (top-right figure). This means that the data are approximately normally distributed around their respective means. Taken together, this means that these data satisfy reasonably well the requirements of a linear model, so the output of that model should be reliable.\n\n\n2.0.10.3 The overall picture\nTypically, statistical tests are testing the likelihood of the data being as they are, or more ‘extreme’ than they are, if the null hypothesis were true. Thus, the null hypothesis is central to statistical testing.\nThe null hypothesis is typically that the ‘nothing going on’, ‘no difference’ or ’ no association’ scenario is true. In this case, it would be that there is no difference between the petal widths of the the three species of iris being considered here.\nTypically too, a test will in the end spit out a p-value which is the probability that we would have got the data we got, or more extreme data, if the null hypothesis were true. Being a probability, it will always be a value between 0 and 1, where 0 means impossible, and 1 means certain. The closer the p-value is to zero, the less likely it is we would have got our data if the null hypothesis were true. At some point, if the p-value is small enough, we will decide that the probability of getting the data we actually got if the null hypothesis were true is so small that we reject the null hypothesis. Typically, the threshold beyond which we do this is when p = 0.05, but we could choose other thresholds. (Sounds arbitrary - yes, it is, but the choice of 0.05 is a compromise value that makes the risk of making each of two types of error - rejecting the null when we should not, and failing to reject it when we should, both acceptably small. This is a big topic which we won’t explore further here.)\nIn the end, whatever other information we get from it, the outcome of a statisical test is typically that we either reject the null hypothesis or we fail to reject it. If we reject it then we are claiming to have detected evidence for an ‘effect’ and we go on to determine how big that effect is and whether it is scientifically interesting. If we fail to reject the null, that does not necessarily mean that there is no ‘effect’ (difference, trend, association etc). That might be the case, but it might also just mean that we didn’t find evidence for one from our data.\nIt is all a bit like in a law court where the ‘null hypothesis’ is that the defendant is innocent, and at the end of the proceedings this null is either rejected (Guilty!) because the evidence is such as to make it untenable to hold onto the null hypothesis, or not rejected, because the evidence is not strong enough to convict, in which case the defendant walks free - but is not declared innocent. Formally, the court has simply found insufficient evidence to convict. In the latter case, the court would have failed to reject the null hypothesis. Crucially, it would not have declared that the defendant was innocent. In the same way, in a scientific study, we either reject or fail to reject a null hypothesis. We never ever accept the null hypothesis as true.\nActually, many researchers are unhappy wih this so-called ‘frequentist’ narrative and have sought to use an alternative ‘Bayesian’ approach to testing hypotheses. In this approach we can accept hypotheses and we can bring in prior knowledge. This is an interesting topic, but a very big one so we will not pursue it further here.\nWith all that behind us, we are in a better place to understand what the output of the test is telling us.\nFor the 1-way ANOVA, as with other examples of the linear model, this output comes in two stages:\n\n\n2.0.10.4 Overall picture\nIs there evidence for a difference between at least two of the mean values?\nTo see if there is evidence for this, an ANOVA test calculate the ratio between the dfference betweeN the groups compared to the differences within the groups. it calls this ratio \\(F\\). The bigger \\(F\\) is, the more likely we are to reject the null hypothesis that there is no difference between he groups.\n\nanova(pw.model)\n\nAnalysis of Variance Table\n\nResponse: petal_width\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nspecies     2 80.413  40.207  960.01 &lt; 2.2e-16 ***\nResiduals 147  6.157   0.042                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe F value is huge. The null hypothesis of this test, as with many tests, is that there is no difference between the petal widths of the three populations from which these samples have been drawn. In that case, the F value would be one. The p-value is telling us how likely it is that we would get an F value as big or bigger than the one we got for our samples if the null hypothesis were true. Since the p-value is effectively zero here, we reject the null hypothesis: we have evidence from our data that there is a significant varation of petal width between species.\nThe degrees of freedom Df tells us the number of independent pieces of information that were used to calculate the result. Let’s not dwell on this here, but there are two that we have to report in this case: the number of levels minus one ie 3-1 = 2, and the number of individual data points in each level minus one, times the number of levels ie (50-1) x 3 = 147.\n\n\n2.0.10.5 Effect size\nNow that we have established that at least two species of iris have differing petal widths, we go onto investigate where the differences lie, and how big they are. This is important: effect sizes matter. It is one thing to establish that a difference is statistically significant (and typically even the tiniest difference can show up as significant in a study if the sample size is big enough), it is quite another to establish whether the difference is big enough to be scientifically interesting.\n\nsummary(pw.model)\n\n\nCall:\nlm(formula = petal_width ~ species, data = iris)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-0.626 -0.126 -0.026  0.154  0.474 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        0.24600    0.02894    8.50 1.96e-14 ***\nspeciesversicolor  1.08000    0.04093   26.39  &lt; 2e-16 ***\nspeciesvirginica   1.78000    0.04093   43.49  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2047 on 147 degrees of freedom\nMultiple R-squared:  0.9289,    Adjusted R-squared:  0.9279 \nF-statistic:   960 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nThe output here is typical of that from a 1-way ANOVA analysis in R. Each line refers to one of the three levels of the factor being investigated, which is petal width in this case. By default, those levels are arranged alphabetically, so in this case the order is setosa, versicolor then virginica. The first row is always labelled (Intercept), so here that row is referring to setosa. This level is used as the ‘control’ or reference level- the one with which the others are compared. If we are happy to have setosa as that control then we can just carry on, but if we are not, then we have to tell R which level we want to play that role. We’ll go through how to do that later on.\nIn the Estimate column the value 0.246 cm in the first row refers to the actual mean petal width of the setosa plants in the sample. If we go back to the summary table we created earlier on, or look at one of the plots we created, we see that that is the case.\nFor all other rows, the value in the Estimate column is not referring to the absolute mean petal width but to the difference between the mean petal width for that species and the mean petal width of the control species. So we see that the mean petal width of the versicolor in our sample is 1.08 cm greater than that of setosa and so is equal to .246 + 1.08 = 1.326 cm, while that of the virginica is 1.78 cm greater and so is equal to 2.026 cm. Check from the table of mean values we created and the plots that this is correct.\nHere though, we are not interested in absolute values so much as we are in differences, which is why that is what the summary table here gives us. Look again at the differences between the mean petal widths for versicolor and virginica and that for setosa and compare them with the standard erros of those differences, which are given in the second column of the table. These standard errors are much smaller than the differences, meaning that we can have confidence that the differences are statistically significant.\nThis is borne out by the p-value in the right hand column of the table. The null hypothesis of this table is that there is no difference in petal width between populations of the different species from which these samples have been drawn.\nLastly, the adjusted \\(R^2\\) tells us the proportion of variation of petal width that is accounted for by taking note of the species. Here, the value is 0.93, which tells us hat little else besides species determines the relative petal widths. Ther are no other variables that we need to have taken into account.\n\n\n\n2.0.11 Report in plain English\nYou would say something like\nWe find evidence that petal widths are not the same acros thhree species of iris, with virginica &gt; versicolor &gt; setosa. (ANOVA, df = 2, p &lt; 0.001)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>A recommended analysis workflow</span>"
    ]
  }
]