% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrreprt}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tikz}{}{\usepackage{tikz}}
\makeatother
        \newcommand*\circled[1]{\tikz[baseline=(char.base)]{
          \node[shape=circle,draw,inner sep=1pt] (char) {{\scriptsize#1}};}}  
                  

\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={r4nqy},
  pdfauthor={Michael Hunt},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{r4nqy}
\author{Michael Hunt}
\date{2025-07-23}

\begin{document}
\maketitle

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}

\bookmarksetup{startatroot}

\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

\markboth{Preface}{Preface}

This is a Quarto book.

To learn more about Quarto books visit
\url{https://quarto.org/docs/books}.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2
\end{verbatim}

\bookmarksetup{startatroot}

\chapter*{Introduction}\label{introduction}
\addcontentsline{toc}{chapter}{Introduction}

\markboth{Introduction}{Introduction}

This is a compilation of the methods for data analysis that you are
likely to find useful in completing your undergraduate studies.

Data analysis in the life sciences is only part of the wider process of
forming and then answering as best we can well-formed questions about
the way this or that aspect of the natural world works.

\bookmarksetup{startatroot}

\chapter{A recommended analysis
workflow}\label{a-recommended-analysis-workflow}

This is intended as a rough outline of the sequence of steps one
commonly goes through when working on scripts:

\begin{itemize}
\tightlist
\item
  Before you start on the script, ask yourself: am I working in a
  Project?. If not, fix this!
\item
  What is my question? AM I clear about what I want the script to do?
\item
  Load packages
\item
  Load data
\item
  Inspect data
\item
  Clean up or tidy or manipulate the data in some way - whatever it
  takes to get it in the form needed for the analysis steps
\item
  Summarise the data
\item
  Plot the data
\item
  Do statistical analysis
\item
  Decide what all this has told you and report it in plain English.
\end{itemize}

Details will differ from script to script, but this sequence of steps is
very common.

\section{Are you working within your
Project?}\label{are-you-working-within-your-project}

Before we even think of the script, we need to make sure that we are
working within our Project. If we are not doing this, bad things will
happen. If you are, the Project name will be at the top right of the
RStudio window. If you are not, save the script you are working on, and
go to File/Open Project and open your Project. If you haven't even got a
`Project' or don't know what that means then just make sure that
everything you need for whatever you are working on is in one folder and
then turn that folder into a Project. (So a `Project' is just a regular
folder that has been given superpowers.) You do that by going to
File/New Project/Existing Directory. Then you navigate to your folder
and click on Create Project. RStudio will then restart and you will see
the name of your newly anointed Project folder at the top-right of the
RStudio window. You know that a folder is a `Project' because it will
have a .Rproj file inside it.

If all this sounds complicated, don't worry. It really isn't. Just get
someone to show you how to do it and you will be fine.

Now, to the script itself:

\section{Statement of the question(s) to be
investigated}\label{statement-of-the-questions-to-be-investigated}

Without thinking this through, you won't know what your script is
for\ldots{}

What is the analysis that will follow for? What question are you trying
to answer? What hypotheses are you trying to test?

Suppose we were trying to test the hypothesis that there is no
difference between the petal widths of the \emph{setosa},
\emph{versicolor} and \emph{virginica} species of iris. All we have to
go on are the petal widths of the plants we happened to measure. From
these measurements we want to make a statement about these three species
in general.

\section{Open a notebook}\label{open-a-notebook}

In RStudio, go to File/New File/ R Notebook. Delete everything below the
yaml section at the top. This strangeley named section is the bit
between the two lines with three dashes in. For the most part, we will
not need to worry about this section. We just should not delete it
entirely. What is useful to do is to amend the title to something
sensible, and to add \texttt{author:\ "your\ name"} and
\texttt{date:\ "the\ date\ in\ any\ old\ format"} lines, so that your
yaml will look something like this:

\begin{verbatim}
---
title: "A typical workflow"
author: "Who wrote this?"
date: "Today's date"
output:
  html_document:
    df_print: paged
---
\end{verbatim}

Delete everything beneath this yaml section. The big empty space that
then leaves you with is where you write your code. Remember that in
notebooks, the code goes in `chunks' that are started and finished with
by lines with three backticks. Any other text goes between the chunks
and you can format this text using the simple rule of Markdown,
available in the RStudio Help menu. Thus your script will end up looking
something like this:

\begin{verbatim}
---
title: "A typical workflow"
author: "Who wrote this?"
date: "Today's date"
output:
  html_document:
    df_print: paged
---
\end{verbatim}

\section{First header}\label{first-header}

Any text we want to add. Note that a code chunk starts with
\texttt{\{r\}\ and\ ends\ with}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse) }\CommentTok{\# some actual R code}
\end{Highlighting}
\end{Shaded}

\section{Second header}\label{second-header}

Any text we want to add to explain what this next chunk does

\begin{verbatim}
```{r, include=FALSE}
library(tidyverse) # some actual R code
```
\end{verbatim}

\section{Set-up chunk}\label{set-up-chunk}

Just put this chunk in at the top. Worry about it later. Or don't worry
about it at all, if you prefer. It is there to suppress warnings and
messages from appearing in the rendered version of your script.

\begin{verbatim}
```{r, include=FALSE}
# makes the rendered version look prettier
knitr::opts_chunk$set(message=FALSE,warning=FALSE)
```
\end{verbatim}

\section{Load Packages}\label{load-packages}

You will nearly always want the first five packages, and often you will
appreciate the sixth, \texttt{janitor}. Others, such as \texttt{vegan}
will be useful from time to time, depending on what you are doing. If
any of these lines throw an error, it is most likely because you have
not yet installed that package. Do so in the console pane (not in this
script!) using the function
\texttt{install.packages("name\ of\ package")}. Then run this whole
chunk again.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(here)}
\FunctionTok{library}\NormalTok{(ggfortify)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(cowplot)}
\FunctionTok{library}\NormalTok{(janitor)}
\FunctionTok{library}\NormalTok{(vegan)}
\end{Highlighting}
\end{Shaded}

\section{Load data}\label{load-data}

There are several ways to do this, so details will differ depending on
what file type your data is saved in and where it is stored.

Here are two examples. In each case code here presumes that the data is
stored in a subfolder called `data' within the Project folder, and we
use the function \texttt{here()} from the \texttt{here} package. In my
experience this dramatically simplifies the business of finding your
data, wherever your script is. It makes it easier for you to share your
script with others and be confident that what worked for you will work
for them. It \emph{does} require that you are working within your
project.

\subsection{If from a csv file}\label{if-from-a-csv-file}

If you have your data in a \texttt{data} subfolder within your project,
this chunk will work. Just substitute the name of your data file

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath}\OtherTok{\textless{}{-}}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"iris.csv"}\NormalTok{)}
\NormalTok{iris}\OtherTok{\textless{}{-}}\FunctionTok{read\_csv}\NormalTok{(filepath)}
\FunctionTok{glimpse}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 150
Columns: 5
$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.~
$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.~
$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.~
$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.~
$ Species      <chr> "setosa", "setosa", "setosa", "setosa", "setosa", "setosa~
\end{verbatim}

\subsection{If from an Excel file}\label{if-from-an-excel-file}

You will need to use \texttt{read\_excel()} from the \texttt{readxl}
package, and you have to specify the name of the worksheet that holds
the data you want. You can, if you want, specify the exact range that is
occupied by the data. However I suggest you avoid doing this unless it
turns out that you need to do so. If your data is a nice, neat,
rectangular block of rows and columns, you should find that you don't
need to specify the range.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath}\OtherTok{\textless{}{-}}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"difference\_data.xlsx"}\NormalTok{)}
\NormalTok{iris}\OtherTok{\textless{}{-}}\FunctionTok{read\_excel}\NormalTok{(}\AttributeTok{path =}\NormalTok{ filepath,}
                 \AttributeTok{sheet =} \StringTok{"iris"}\NormalTok{, }\CommentTok{\# delete the comma if you choose not to specify the range in the line below}
                 \AttributeTok{range=} \StringTok{"A1:F151"} \CommentTok{\# optional {-} try leaving it out first. Only include if necessary.}
\NormalTok{                 ) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{clean\_names}\NormalTok{()}
\FunctionTok{glimpse}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 150
Columns: 6
$ id           <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~
$ sepal_length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.~
$ sepal_width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.~
$ petal_length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.~
$ petal_width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.~
$ species      <chr> "setosa", "setosa", "setosa", "setosa", "setosa", "setosa~
\end{verbatim}

\subsection{If from a URL}\label{if-from-a-url}

You can load data into R directly from a URL if you are given one, and
that is in fact how you will mainly access data to be used in this
statistics text.

here, we load data from a file stored in a `'repo' on my github account:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris}\OtherTok{\textless{}{-}}\FunctionTok{read\_csv}\NormalTok{(}\StringTok{"https://raw.githubusercontent.com/mbh038/r4nqy/refs/heads/main/data/iris.csv"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{clean\_names}\NormalTok{()}
\FunctionTok{glimpse}\NormalTok{(iris)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 150
Columns: 5
$ sepal_length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.~
$ sepal_width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.~
$ petal_length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.~
$ petal_width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.~
$ species      <chr> "setosa", "setosa", "setosa", "setosa", "setosa", "setosa~
\end{verbatim}

\section{Clean / Manipulate the data}\label{clean-manipulate-the-data}

Often we need to do some sort of data `wrangling' to get the data into
the form we want. For example we may wish to tidy it (this has a
particular meaning when applied to data sets), to remove rows with
missing values, to filter out rows from sites or time periods that we
don't want to include in our analysis, to create new columns and so on.

For example, lets create a new data frame for just the \emph{setosa}
species of iris:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{setosa }\OtherTok{\textless{}{-}}\NormalTok{ iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(species }\SpecialCharTok{==} \StringTok{"setosa"}\NormalTok{) }\CommentTok{\# filter picks out rows according to criteria being satisfied in some column}
\FunctionTok{glimpse}\NormalTok{(setosa)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 50
Columns: 5
$ sepal_length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.~
$ sepal_width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.~
$ petal_length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.~
$ petal_width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.~
$ species      <chr> "setosa", "setosa", "setosa", "setosa", "setosa", "setosa~
\end{verbatim}

or maybe we just want the column that contain numeric data and not the
one containing the species identifiers, which is text:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_numeric }\OtherTok{\textless{}{-}}\NormalTok{ iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{species) }\CommentTok{\# select() retains or leaves out particular columns. Here, we leave out the species column.}
\FunctionTok{glimpse}\NormalTok{(iris\_numeric)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 150
Columns: 4
$ sepal_length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.~
$ sepal_width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.~
$ petal_length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.~
$ petal_width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.~
\end{verbatim}

\section{Summarise the data}\label{summarise-the-data}

How big is the difference between the mean of this group over here and
that group over there, and how big is that difference compared to the
precision with which we know those means? We nearly always want to do
this as a first way to get insight into whether we will or will not
reject our hypothesis. For example, let's find the mean petal widths of
the three species, the standard errors of those means and save the
results to a data frame called \texttt{petal\_summary}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{petal\_summary}\OtherTok{\textless{}{-}}\NormalTok{iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(species) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean.Pwidth =} \FunctionTok{mean}\NormalTok{(petal\_width),}
            \AttributeTok{se.Pwidth =} \FunctionTok{sd}\NormalTok{(petal\_width}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{())))}
\NormalTok{petal\_summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 3
  species    mean.Pwidth se.Pwidth
  <chr>            <dbl>     <dbl>
1 setosa           0.246    0.0149
2 versicolor       1.33     0.0280
3 virginica        2.03     0.0388
\end{verbatim}

We can look at this table and already get an idea as to whether the
petal widths are the same or are different for the three species.

\section{Plot the data}\label{plot-the-data}

The next step is usually to plot the data in some way. We would
typically use the \texttt{ggplot2} package from \texttt{tidyverse} to do
this.

\subsection{Bar plot with error bars}\label{bar-plot-with-error-bars}

We could plot a bar plot with error bars, working from the summary data
frame that we created:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{petal\_summary }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{y =}\NormalTok{ mean.Pwidth)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{fill=}\StringTok{"\#a6bddb"}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# this is the geom that gives us a bar plot when we have already done the calculations}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean.Pwidth }\SpecialCharTok{{-}}\NormalTok{ se.Pwidth, }\AttributeTok{ymax =}\NormalTok{ mean.Pwidth }\SpecialCharTok{+}\NormalTok{ se.Pwidth), }\AttributeTok{width =} \FloatTok{0.15}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{( }\AttributeTok{x =} \StringTok{"species"}\NormalTok{,}
        \AttributeTok{y =} \StringTok{"Mean petal width (mm)"}\NormalTok{,}
        \AttributeTok{caption =} \StringTok{"Error bars are Â± one standard error of the mean"}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# important to say what these error bars denote}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{workflow_files/figure-pdf/unnamed-chunk-10-1.pdf}}

Note that we have given the bars a fill colour - we got this color from
\href{https://colorbrewer2.org/\#type=sequential&scheme=PuBu&n=3}{this
site} due to the cartographer Cynthia Brewer, who is behind the various
incarnations of the \texttt{Brewer} package in R, which is great for
getting colours that work well. We have used the same colour for each
species since the x-axis labels already tell us which bar relates to
which species. To use a different colour for each bar would imply there
is some extra information encoded by colour. Since there is not, it
serves no purpose to have different colours, and potentially confuses
the reader. Remember always that a plot is intended to convey a message.
Anything that detracts from that message should be avoided, however
pretty you think it is.

A couple of points could be made about this type of plot:

First, what about those error bars? Three types of error bar are in
common usage and there are arguments in favour and against the use of
each of them:

\begin{itemize}
\tightlist
\item
  the \emph{standard deviation} tells us about the spread of values in a
  sample, and is an estimate of the spread of values in a population;\\
\item
  the \emph{standard error of the mean}, as used here, is an estimate of
  the precision with which the sample means estimates the respective
  population means for each of the species.
\item
  the \emph{confidence interval}, typically a \emph{95\% confidence
  interval}, gives us the region within which we are (say) 95\%
  confident that the true species mean petal width might plausibly lie.
\end{itemize}

Which type of error bar is best to use depends on what story you want to
tell. Here, because we are interested in whether there is evidence of a
difference in the mean petal width of different species, we have gone
for the standard eror of the mean.

Regardless of which error bar you use and why, you should always tell
the reader which one you have gone for, as we have in the caption to the
figure.

A second point about this bar plot is that it doesn't tell us very much,
and indeed nothing that we didn't already know. It only conveys the mean
and standard error values for each species, which is information we
already have, arguably more compactly and in more easily readable form,
in the table we created. Further, it potentially obscures information
that might come from knowing the \emph{distribution} of the data.

Here are three other plot types that do show the distribution of petal
widths for each species and thus add extra information to what we
already know from the summary table

\subsection{Box plot}\label{box-plot}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{species, }\AttributeTok{y=}\NormalTok{petal\_width)) }\SpecialCharTok{+} \CommentTok{\# what we want to plot}
  \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{fill=}\StringTok{"\#a6bddb"}\NormalTok{,}\AttributeTok{notch=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# what kind of plot we want}
  \FunctionTok{geom\_jitter}\NormalTok{(}\AttributeTok{width=}\FloatTok{0.1}\NormalTok{, }\AttributeTok{colour =} \StringTok{"\#f03b20"}\NormalTok{,}\AttributeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{ (}\AttributeTok{x =} \StringTok{"species"}\NormalTok{,}
        \AttributeTok{y =} \StringTok{"Petal Width (mm)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{() }\CommentTok{\# choose a theme to give the plot a \textquotesingle{}look\textquotesingle{} that we like}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{workflow_files/figure-pdf/unnamed-chunk-11-1.pdf}}

Here, we have added the points themselves on top of the box plot. When
there are not too many data points, this can be useful. The `jitter'
adds some horizontal or vertical jitter, or both, so that the points do
not lie on top of each other. In this case we see that the variability
of petal widths is not the same for each species and that the data are
roughly symmetrically distributed around the median values in each case.
This information is useful in helping us determine which statistical
test might be appropriate for these data.

\subsection{Violin plot}\label{violin-plot}

A useful alternative to the box plot, especially when the data set is
large, is the violin plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{y =}\NormalTok{ petal\_width)) }\SpecialCharTok{+} \CommentTok{\# what we want to plot}
  \FunctionTok{geom\_violin}\NormalTok{(}\AttributeTok{fill=}\StringTok{"\#a6bddb"}\NormalTok{,}\AttributeTok{notch=}\ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# what kind of plot we want}
  \CommentTok{\#geom\_jitter(width=0.1, colour = "\#f03b20",alpha=0.5) +}
  \FunctionTok{labs}\NormalTok{ (}\AttributeTok{x =} \StringTok{"species"}\NormalTok{,}
        \AttributeTok{y =} \StringTok{"Petal Width (mm)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{() }\CommentTok{\# choose a theme to give the plot a \textquotesingle{}look\textquotesingle{} that we like}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{workflow_files/figure-pdf/unnamed-chunk-12-1.pdf}}

The widths of the blobs (I am probably supposed to call them `violins'!)
show us the distribution of the data - where they are widest is where
the data are concentrated, while the height of the blobs shows us the
range of variation of the data. The positions of the blobs tells us the
mean petal widths of the different species and gives us an idea of the
differences between them.

\subsection{Ridge plot}\label{ridge-plot}

A bit like a violin plot. This needs the package \texttt{ggridges} to be
installed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggridges)}
\NormalTok{iris }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ petal\_width,}\AttributeTok{y =}\NormalTok{ species)) }\SpecialCharTok{+} \CommentTok{\# what we want to plot}
  \FunctionTok{geom\_density\_ridges}\NormalTok{(}\AttributeTok{fill=}\StringTok{"\#a6bddb"}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# what kind of plot we want}
  \CommentTok{\#geom\_jitter(width=0.1, colour = "\#f03b20",alpha=0.5) +}
  \FunctionTok{labs}\NormalTok{ (}\AttributeTok{x =} \StringTok{"Petal Width (mm)"}\NormalTok{,}
        \AttributeTok{y =} \StringTok{"species"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{() }\CommentTok{\# choose a theme to give the plot a \textquotesingle{}look\textquotesingle{} that we like}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{workflow_files/figure-pdf/unnamed-chunk-13-1.pdf}}

Having seen the summary and one of these plots of the data, would you be
inclined to reject, or fail to reject, a null hypothesis that said that
there was no difference between the petal widths of the three species?

\section{Statistical analysis}\label{statistical-analysis}

Only now do we move on to the statistical analysis to try to answer our
intial question(s). But by now, after the summary and plot(s), we may
already have a pretty good idea what that answer will turn out to be.

The exact form of the analysis could take many forms. In a typical
ecology project you might carry out several types of analysis, each one
complementing the other. Here, an appropriate analysis might be to use
the linear model in the form of a one-way ANOVA, since we have one
factor (species) with three levels (\emph{setosa}, \emph{versicolor} and
\emph{virginica}) and an output variable that is numeric and likely to
be normally distributed. We can use the \texttt{lm()} function for this.

\subsection{Create the model object}\label{create-the-model-object}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pw.model }\OtherTok{\textless{}{-}}\FunctionTok{lm}\NormalTok{ (petal\_width }\SpecialCharTok{\textasciitilde{}}\NormalTok{ species, }\AttributeTok{data =}\NormalTok{ iris)}
\end{Highlighting}
\end{Shaded}

\subsection{Check the validity of the
model}\label{check-the-validity-of-the-model}

We won't go into this here, but an important step is to check that the
data satisfy the often finicky requirements of whatever statistical test
we have decided to use. The \texttt{autoplot()} function form the
\texttt{ggfortify} package is great for doing this graphically.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{( pw.model) }\SpecialCharTok{+} \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{workflow_files/figure-pdf/unnamed-chunk-15-1.pdf}}

Here we note in particular that although the spread of data within each
level is not roughly the same (top left figure)), the QQ plot is pretty
straight (top-right figure). This means that the data are approximately
normally distributed around their respective means. Taken together, this
means that these data satisfy reasonably well the requirements of a
linear model, so the output of that model should be reliable.

\subsection{The overall picture}\label{the-overall-picture}

Typically, statistical tests are testing the likelihood of the data
being as they are, or more `extreme' than they are, \emph{if} the null
hypothesis were true. Thus, the null hypothesis is central to
statistical testing.

The null hypothesis is typically that the `nothing going on', `no
difference' or ' no association' scenario is true. In this case, it
would be that there is no difference between the petal widths of the the
three species of iris being considered here.

Typically too, a test will in the end spit out a \emph{p}-value which is
the probability that we would have got the data we got, or more extreme
data, \emph{if} the null hypothesis were true. Being a probability, it
will always be a value between 0 and 1, where 0 means impossible, and 1
means certain. The closer the \emph{p}-value is to zero, the less likely
it is we would have got our data if the null hypothesis were true. At
some point, if the \emph{p}-value is small enough, we will decide that
the probability of getting the data we actually got if the null
hypothesis were true is so small that we reject the null hypothesis.
Typically, the threshold beyond which we do this is when \emph{p} =
0.05, but we could choose other thresholds. (Sounds arbitrary - yes, it
is, but the choice of 0.05 is a compromise value that makes the risk of
making each of two types of error - rejecting the null when we should
not, and failing to reject it when we should, both acceptably small.
This is a big topic which we won't explore further here.)

In the end, whatever other information we get from it, the outcome of a
statisical test is typically that we either reject the null hypothesis
or we fail to reject it. If we reject it then we are claiming to have
detected evidence for an `effect' and we go on to determine how big that
effect is and whether it is scientifically interesting. If we fail to
reject the null, that does not necessarily mean that there is no
`effect' (difference, trend, association etc). That might be the case,
but it might also just mean that we didn't find evidence for one from
our data.

It is all a bit like in a law court where the `null hypothesis' is that
the defendant is innocent, and at the end of the proceedings this null
is either rejected (Guilty!) because the evidence is such as to make it
untenable to hold onto the null hypothesis, or not rejected, because the
evidence is not strong enough to convict, in which case the defendant
walks free - but is not declared innocent. Formally, the court has
simply found insufficient evidence to convict. In the latter case, the
court would have failed to reject the null hypothesis. Crucially, it
would \emph{not} have declared that the defendant was innocent. In the
same way, in a scientific study, we either reject or fail to reject a
null hypothesis. We never \emph{ever} accept the null hypothesis as
true.

Actually, many researchers are unhappy wih this so-called `frequentist'
narrative and have sought to use an alternative `Bayesian' approach to
testing hypotheses. In this approach we can accept hypotheses and we can
bring in prior knowledge. This is an interesting topic, but a very big
one so we will not pursue it further here.

With all that behind us, we are in a better place to understand what the
output of the test is telling us.

For the 1-way ANOVA, as with other examples of the linear model, this
output comes in two stages:

\subsection{Overall picture}\label{overall-picture}

Is there evidence for a difference between at least two of the mean
values?

To see if there is evidence for this, an ANOVA test calculate the ratio
between the dfference \emph{betweeN} the groups compared to the
differences \emph{within} the groups. it calls this ratio \(F\). The
bigger \(F\) is, the more likely we are to reject the null hypothesis
that there is no difference between he groups.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(pw.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: petal_width
           Df Sum Sq Mean Sq F value    Pr(>F)    
species     2 80.413  40.207  960.01 < 2.2e-16 ***
Residuals 147  6.157   0.042                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The \emph{F} value is huge. The null hypothesis of this test, as with
many tests, is that there is no difference between the petal widths of
the three populations from which these samples have been drawn. In that
case, the \emph{F} value would be one. The \emph{p}-value is telling us
how likely it is that we would get an \emph{F} value as big or bigger
than the one we got for our samples if the null hypothesis were true.
Since the \emph{p}-value is effectively zero here, we reject the null
hypothesis: we have evidence from our data that there is a significant
varation of petal width between species.

The degrees of freedom \texttt{Df} tells us the number of independent
pieces of information that were used to calculate the result. Let's not
dwell on this here, but there are two that we have to report in this
case: the number of levels minus one ie 3-1 = 2, and the number of
individual data points in each level minus one, times the number of
levels ie (50-1) x 3 = 147.

\subsection{Effect size}\label{effect-size}

Now that we have established that at least two species of iris have
differing petal widths, we go onto investigate where the differences
lie, and how big they are. This is important: effect sizes matter. It is
one thing to establish that a difference is statistically significant
(and typically even the tiniest difference can show up as significant in
a study if the sample size is big enough), it is quite another to
establish whether the difference is big enough to be scientifically
interesting.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(pw.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = petal_width ~ species, data = iris)

Residuals:
   Min     1Q Median     3Q    Max 
-0.626 -0.126 -0.026  0.154  0.474 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)        0.24600    0.02894    8.50 1.96e-14 ***
speciesversicolor  1.08000    0.04093   26.39  < 2e-16 ***
speciesvirginica   1.78000    0.04093   43.49  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.2047 on 147 degrees of freedom
Multiple R-squared:  0.9289,    Adjusted R-squared:  0.9279 
F-statistic:   960 on 2 and 147 DF,  p-value: < 2.2e-16
\end{verbatim}

The output here is typical of that from a 1-way ANOVA analysis in R.
Each line refers to one of the three levels of the factor being
investigated, which is petal width in this case. By default, those
levels are arranged alphabetically, so in this case the order is
\emph{setosa}, \emph{versicolor} then \emph{virginica}. The first row is
always labelled \texttt{(Intercept)}, so here that row is referring to
\emph{setosa}. This level is used as the `control' or reference level-
the one with which the others are compared. If we are happy to have
\emph{setosa} as that control then we can just carry on, but if we are
not, then we have to tell R which level we want to play that role. We'll
go through how to do that later on.

In the Estimate column the value 0.246 cm in the first row refers to the
actual mean petal width of the \emph{setosa} plants in the sample. If we
go back to the summary table we created earlier on, or look at one of
the plots we created, we see that that is the case.

For all other rows, the value in the Estimate column is not referring to
the absolute mean petal width but to the difference between the mean
petal width for that species and the mean petal width of the control
species. So we see that the mean petal width of the \emph{versicolor} in
our sample is 1.08 cm greater than that of \emph{setosa} and so is equal
to .246 + 1.08 = 1.326 cm, while that of the \emph{virginica} is 1.78 cm
greater and so is equal to 2.026 cm. Check from the table of mean values
we created and the plots that this is correct.

Here though, we are not interested in absolute values so much as we are
in differences, which is why that is what the summary table here gives
us. Look again at the differences between the mean petal widths for
\emph{versicolor} and \emph{virginica} and that for \emph{setosa} and
compare them with the standard erros of those differences, which are
given in the second column of the table. These standard errors are much
smaller than the differences, meaning that we can have confidence that
the differences are statistically significant.

This is borne out by the \emph{p}-value in the right hand column of the
table. The null hypothesis of this table is that there is no difference
in petal width between populations of the different species from which
these samples have been drawn.

Lastly, the adjusted \(R^2\) tells us the proportion of variation of
petal width that is accounted for by taking note of the species. Here,
the value is 0.93, which tells us hat little else besides species
determines the relative petal widths. Ther are no other variables that
we need to have taken into account.

\section{Report in plain English}\label{report-in-plain-english}

You would say something like

We find evidence that petal widths are not the same acros thhree species
of iris, with \emph{virginica} \textgreater{} \emph{versicolor}
\textgreater{} \emph{setosa}. (ANOVA, df = 2, p \textless{} 0.001)

\bookmarksetup{startatroot}

\chapter{Tests for difference: one factor, two
levels}\label{tests-for-difference-one-factor-two-levels}

In this document we consider tests for difference where there are two
levels being compared.

\section{Test finder flow chart}\label{test-finder-flow-chart}

First, use this flowchart to see if a two-sample t-test or its
non-parametric counterpart the Mann-Whitney-U test is appropriate for
your question, your study design and your data:

\includegraphics[width=24.17in,height=23.59in]{tests_for_difference_two_levels_files/figure-latex/mermaid-figure-1.png}

If this chart suggests you need something other than the two sample
t-test or Mann-Whitney test, you need to go to the descriptions of that
test.

\section{Two sample t-test: the parametric
case}\label{two-sample-t-test-the-parametric-case}

In this exercise we find out how to run a two-sample \emph{t}-test, to
determine whether there is evidence to reject the hypothesis that two
samples are drawn from the same population.

\subsection{\texorpdfstring{When to use the two-sample
\emph{t}-test}{When to use the two-sample t-test}}\label{when-to-use-the-two-sample-t-test}

\begin{itemize}
\item
  It can be used when we have two independent samples of
  \textbf{numerical} (not ordinal) response data, and our question is
  whether the data provide evidence that the samples are drawn from
  different populations. Even when this criterion is met and the data
  are numerical and independent, the normality criterion described below
  still needs to be met. That apart, two common examples where we have
  two sets of data but we should not use the two sample \emph{t}-test
  are:

  \begin{itemize}
  \item
    If the data in your two samples are not independent because you have
    measured the same individual replicate before and after some event
    or treatment, then you should probably be using a \textbf{paired
    \emph{t}-test} instead. In this you don't have two samples, each
    comprising a separate and independent set of replicates. Instead,
    you have multiple pairs of values, one pair per replicate. The
    replicates are still assumed to be independent of each other
  \item
    If your response data are the answers to a Likert scale such as
    might be used in a survey then they are \emph{ordinal} in nature and
    not numerical, and you should probably be using the non-parametric
    equivalent of the two sample \emph{t}-test, which is variously known
    as the \textbf{Wilcoxon Rank Sum test} or as the \textbf{Mann
    Whitney U test}, or its paired sample version, if appropriate.
  \end{itemize}
\item
  It can be used when the data set is small. But not so small that there
  are no replicates. You \textbf{do} need replicates.
\item
  It can still be used when the data set is large.
\item
  It assumes that the data are drawn from a normally distributed
  population. There are various ways to test if this is plausibly the
  case, and you should try at least one of them, but with small samples,
  just where the \emph{t}-test is most useful, it can be difficult to
  tell. In the end we can also appeal to reason: is there good reason to
  suppose that the data would or would not be normally distributed?
\item
  When comparing the means of two samples, both samples should in
  principle have the same variance, which is a measure of the spread of
  the data, so in principle you need to check that this is at least
  \emph{approximately} the case, or have reason to suppose that it
  should be. \emph{However}, in an actual \emph{t}-test done using R,
  the Welch variant of the \emph{t}-test is carried out by default. This
  works even when the variances of the two sets are different, so in
  practice it is possible to ignore this equal variance requirement.
\item
  We only use it when we are comparing two samples, one for each of the
  two levels of a single factor. When we have samples for more than two
  levels and we use the \emph{t}-test to look for a difference between
  any two of them, it becomes increasingly likely, the more pairs of
  samples we compare, that we will decide that we have found a
  difference because we got a \emph{p}-value that was less than some
  pre-determined threshold (which could be anything, but is most often
  chosen to be 0.05) even if in reality there is none. This is the
  problem of high false positive rates arising from multiple pairwise
  testing and is where ANOVA comes in. \emph{t}-tests are only used to
  detect evidence for a difference between two groups, not more. ANOVAs
  (or their non-parametric equivalent) are used when we are looking for
  differences between more than two groups.
\end{itemize}

\subsection{Motivation and example}\label{motivation-and-example}

In our example we will consider the impact of pesticide use on the
masses of shells of garden snails (\emph{Cornu aspersum}), as measured
in gardens around a city, ten from randomly selected gardens that have
used a range of pesticides for at least two years and ten that are from
randomly selected gardens that have not ever used pesticides. We leave
aside here the issue of how those gardens were identified and how
randomisation was ensured.

\subsection{Questions and hypotheses}\label{questions-and-hypotheses}

Our \textbf{question} is:

\emph{Is there evidence for a difference between snail shell masses in
the gardens where pesticides were used compared to those where they were
not used?}

From which a suitable \textbf{null hypothesis} is:

\emph{There is no difference between shell masses in the gardens,
whether or not pesticides were used.}

and a suitable \textbf{alternate, two-sided hypothesis} is:

\emph{There is a difference between shell masses.}

\subsection{The data}\label{the-data}

Suppose we had our data arranged in a spreadsheet in three columns, one
giving the garden ID, G1 to G20, one telling us whether pesticides were
used in the garden, yes or no, and one telling us the masses in grams of
the snail shells from each garden. Afficioados of R will see that this
is `tidy' data. Each variable (ID, pesticide use, shell mass) occurs in
only one column, rather than being spread across several. It turns out
that this way of storing your data makes it much easier to analyse.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# there should be a \textquotesingle{}garden\_snails.csv\textquotesingle{} file in your data folder}

\NormalTok{filepath}\OtherTok{\textless{}{-}}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"garden\_snails.csv"}\NormalTok{)}
\NormalTok{snails}\OtherTok{\textless{}{-}}\FunctionTok{read\_csv}\NormalTok{(filepath)}

\CommentTok{\# if not, you should be able to get it from Mike\textquotesingle{}s github repo}

\CommentTok{\# file\_url \textless{}{-} "https://raw.githubusercontent.com/mbh038/r{-}workshop/refs/heads/gh{-}pages/data/garden\_snails.csv"}
\CommentTok{\# snails\textless{}{-}read\_csv(file\_url)}
\FunctionTok{head}\NormalTok{(snails,}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 20 x 3
   garden.ID pesticide shell_mass_g
   <chr>     <chr>            <dbl>
 1 S1        Yes               1.37
 2 S2        Yes               1.15
 3 S3        Yes               0.73
 4 S4        Yes               0.65
 5 S5        Yes               1.03
 6 S6        Yes               1.8 
 7 S7        Yes               1.21
 8 S8        Yes               1.41
 9 S9        Yes               1.27
10 S10       Yes               1.08
11 S11       No                2   
12 S12       No                3.99
13 S13       No                1.99
14 S14       No                1.75
15 S15       No                2.81
16 S16       No                2.15
17 S17       No                1.87
18 S18       No                3.46
19 S19       No                2.8 
20 S20       No                2.89
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Is this a tidy data set?
\item
  Is the data in the \texttt{pesticide} column categorical?
\item
  If so, how many levels does it have and what are they?
\end{itemize}

\section{The Process}\label{the-process}

\subsection{Step One: Summarise the
data}\label{step-one-summarise-the-data}

With numerical data spread across more than one level of a categorical
variable, we often want summary information such as mean values and
standard errors of the mean for each level.

Here we will calculate the number of replicates, the mean and the
standard error of the mean for both levels of \texttt{pesticide} ie Yes
and No:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{snail.summary}\OtherTok{\textless{}{-}}\NormalTok{ snails }\SpecialCharTok{|\textgreater{}}
\FunctionTok{group\_by}\NormalTok{(pesticide) }\SpecialCharTok{|\textgreater{}}
\FunctionTok{summarise}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{(),}
          \AttributeTok{mean.mass =} \FunctionTok{mean}\NormalTok{(shell\_mass\_g),}
          \AttributeTok{se.mass =} \FunctionTok{sd}\NormalTok{(shell\_mass\_g)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()))}
\NormalTok{snail.summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2 x 4
  pesticide     n mean.mass se.mass
  <chr>     <int>     <dbl>   <dbl>
1 No           10      2.57   0.236
2 Yes          10      1.17   0.105
\end{verbatim}

From these data, does it look as though there is evidence for a
difference between shell masses in the two types of garden? Clearly, the
snails in the ten gardens that did not use pesticide had a higher mean
shell mass than the ten from gardens that did use pesticide. But is this
a fluke? How precisely do we think these sample means reflect the truth
about the impact of the use of pesticides? That is what the standard
error column tells us. You can think of the standard error as being an
estimate of how far our sample means, drawn from just ten gardens of
each type are likely to differ from the true shell masses for all
gardens that did use pesticides and all gardens that did not.

Bottom line: the difference between the sample means is about ten times
the size of the standard errors of each. It really does look as though
snails shells in gardens where pesticides are not used are indeed
heavier than in gardens where pesticides are used.

\subsection{Step Two: Plot the data}\label{step-two-plot-the-data}

Remember, before we do any statistical analysis, it is almost always a
good idea to plot the data in some way. We can often get a very good
idea as to the answer to our research question just from the plots we
do.

In Figure~\ref{fig-histograms}, we will use \texttt{ggplot()} in R to
plot a histogram of ozone levels, one for each side of the city. We will
stack the histograms one above the other, all the better to help us spot
any differences between east and west.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{snails }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{shell\_mass\_g)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth=}\FloatTok{0.2}\NormalTok{,}\AttributeTok{fill=}\StringTok{"darkred"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{pesticide,}\AttributeTok{ncol=}\DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/fig-histograms-1.pdf}}

}

\caption{\label{fig-histograms}Stacked histograms}

\end{figure}%

Instead of histograms, we could have drawn box plots, as in:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{snails }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{pesticide,}\AttributeTok{y=}\NormalTok{shell\_mass\_g))}\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"Pestice use?"}\NormalTok{,}
       \AttributeTok{y=}\StringTok{"Shell mass (g)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/fig-boxplot-1.pdf}}

}

\caption{\label{fig-boxplot}Side-byside box and whisker plots of the
distribution of values in each snail sample. The lower and upper edges
of each box show the 25th and 75th percentiles of each sample, and the
thick black line between them shows the median value ie the 50th
percentile}

\end{figure}%

or as a dot plot of the means with standard errors of the mean included
as error bars, as in Figure~\ref{fig-means-se}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# for this chart we will use the summary table that we created above.}

\NormalTok{snail.summary }\SpecialCharTok{|\textgreater{}} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{pesticide,}\AttributeTok{y=}\NormalTok{mean.mass))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin=}\NormalTok{mean.mass}\SpecialCharTok{{-}}\NormalTok{se.mass,}\AttributeTok{ymax=}\NormalTok{mean.mass}\SpecialCharTok{+}\NormalTok{se.mass),}\AttributeTok{width=}\FloatTok{0.1}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# try leaving this line out. What happens? Which is better?}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"Pesticide use?"}\NormalTok{,}
       \AttributeTok{y=}\StringTok{"Shell mass (g)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

\centering{

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/fig-means-se-1.pdf}}

}

\caption{\label{fig-means-se}The data points show mean values, the error
bars show plus or minus one standard error of the mean}

\end{figure}%

\begin{itemize}
\item
  Do the data look as though they are inconsistent with the null
  hypothesis ?
\item
  In addition, do the data look as though each group is drawn from a
  normally distributed population? One of the types of graphs gives you
  no indication of that while the other two do. Which is the odd one
  out? Even when looking at the other two figures, when there are so few
  data it's kind of hard to tell, no?
\end{itemize}

Let's now do some stats.

\subsection{Step Three: Check the validity of the data - are the data
normally
distributed?}\label{step-three-check-the-validity-of-the-data---are-the-data-normally-distributed}

We can go about establishing this in three ways: using an analytical
test of normality, using a graphical method and by thinking about what
kind of data we have. Let's consider these in turn.

\subsubsection{Normality test - analytical
method}\label{normality-test---analytical-method}

There are several analytical tests one can run on a set of data to
determine if it is plausible that it has been drawn from a normally
distributed population. One is the Shapiro-Wilk test.

For more information on the Shapiro-Wilk test in R, type
\texttt{?shapiro.test} into the console window. For kicks, try it out on
the examples that appear in the help window (which is the bottom right
pane, Help tab). One example is testing a sample of data that explicitly
\emph{is} drawn from a normal distribution, the other tests a sample of
data that definitely \emph{is not}. What \emph{p}-value do you get in
each case? How closely do the histograms of each sample resemble a
normal distribution?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#first we create a data frame containing the two example data sets}
\NormalTok{example1}\OtherTok{\textless{}{-}}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{, }\AttributeTok{mean =} \DecValTok{5}\NormalTok{, }\AttributeTok{sd =} \DecValTok{3}\NormalTok{) }\CommentTok{\# first example from the help pane}
\NormalTok{example2}\OtherTok{\textless{}{-}}\FunctionTok{runif}\NormalTok{(}\DecValTok{500}\NormalTok{, }\AttributeTok{min =} \DecValTok{2}\NormalTok{, }\AttributeTok{max =} \DecValTok{4}\NormalTok{) }\CommentTok{\# second example from the help pane}

\NormalTok{df}\OtherTok{\textless{}{-}}\FunctionTok{tibble}\NormalTok{(}\AttributeTok{data=}\FunctionTok{c}\NormalTok{(example1,example2), }\AttributeTok{distribution=}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"example 1: normal"}\NormalTok{,}\DecValTok{500}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\StringTok{"example 2: not at all normal"}\NormalTok{,}\DecValTok{500}\NormalTok{)))}

\CommentTok{\# then we plot a histogram of each data set}
\FunctionTok{ggplot}\NormalTok{(df,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{data)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{bins=}\DecValTok{20}\NormalTok{,}\AttributeTok{fill=}\StringTok{"cornflowerblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{distribution) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/unnamed-chunk-5-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# and finally we run a Shapiro{-}Wilk normality test on each data set}
\FunctionTok{shapiro.test}\NormalTok{(example1) }\CommentTok{\# 100 samples drawn from a normally distributed population}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  example1
W = 0.99553, p-value = 0.1628
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(example2) }\CommentTok{\# 100 samples drawn from a uniformly (ie NOT normally) distributed population}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  example2
W = 0.94303, p-value = 6.307e-13
\end{verbatim}

For the examples above, we see that Shapiro-Wilk test gave a high
\emph{p}-value for the data that we knew \emph{were} drawn from a normal
distribution, and a very low \emph{p}-value for the data that we knew
were not.

The Shapiro-Wilk test tests your data against the null hypothesis that
it is drawn from a normally distributed population. It gives a
\emph{p}-value which, as always, is the probably of you having data as
far from normality, or further, as yours are if the null hypothesis were
true. If the \emph{p}-value is less than 0.05 then we reject the null
hypothesis and cannot suppose our data is drawn froma normally
distributed population. In that case we would have to ditch the
\emph{t}-test for a difference, and choose another difference test in
its place that could cope with data that was not normally distributed.
For a two-sample \emph{t}-test such as we are hoping to use here, the
so-called non-parametric alternative that we could use instead is the
Wilcoxon Rank Sum test, often called the Mann-Whitney U test.

Why don't we do that in the first place, I hear you ask? Why bother with
this finicky \emph{t}-test that requires that we go through the faff of
testing the data for normality before we can use it? The answer is that
it is more powerful than other, so-called non-parametric tests that
\emph{can} cope with non-normal data. It is more likely than they are to
spot a difference if there really is a difference. So if we can use it,
that is what we would rather do.

So, onwards, let's do the Shapiro-Wilk test on our data

We want to test each garden group for normality, so we group the data by
location as before and and then summarise, this time asking for the
\emph{p}-value returned by the Shapiro-Wilk test of normality.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{snails }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(pesticide) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\StringTok{\textquotesingle{}Shapiro{-}Wilk p{-}value\textquotesingle{}}\OtherTok{=}\FunctionTok{shapiro.test}\NormalTok{(shell\_mass\_g)}\SpecialCharTok{$}\NormalTok{p.value)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 2 x 2
  pesticide `Shapiro-Wilk p-value`
  <chr>                      <dbl>
1 No                         0.223
2 Yes                        0.854
\end{verbatim}

For both groups the \emph{p}-value is more than 0.05, so at the 5\%
significance level we cannot reject the null hypothesis that the data
are normally distributed, so we can go on and use the \emph{t}-test.
Yay!

\subsubsection{Graphical methods - the quantile-quantile or QQ
plot.}\label{graphical-methods---the-quantile-quantile-or-qq-plot.}

Confession: I don't normally bother with numerical tests for normality
such as Shapiro-Wilk. I usually use a graphical method instead.

We have already seen two ways of plotting the data that might help
suggest whether it is plausible that the data are drawn from normally
distributed populations. Histograms and box plots both indicate how data
is distributed, and for normally distributed data both would be
symmetrical. Well, they would be, more or less, if the data set was
large enough but for small data sets it can be quite hard to tell from
either type of plot whether the data are drawn from a normally
distributed population.

A better type of plot for making this judgement call is the
quantile-quantile or `qq' plot which basically compares the distribution
of your data to that of a normal distribution. If your data are
approximately normally distributed then a qq plot will give a
straight(-ish) line. Even with small data sets, this is usually easy to
spot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{snails }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{sample=}\NormalTok{shell\_mass\_g)) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq}\NormalTok{(}\AttributeTok{colour=}\StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_qq\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{pesticide) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/unnamed-chunk-7-1.pdf}}

Nothing outrageously non-linear there, so that also suggests we can
safely use the \emph{t}-test.

For an overview of how normally distributed and non-normally distributed
data looks when plotted in histograms, box plots and quantile-quantile
plots, see \href{https://rpubs.com/mbh038/725314}{this review}

\subsubsection{The `thinking about the data' normality
test}\label{the-thinking-about-the-data-normality-test}

As you might have guessed, this isn't a test as such, but a suggestion
that you think about what kind of data you have: is it likely to be
normally distributed within its subgroups or not? If the data are
numerical values of some physical quantity that is the result of many
independent processes, and if the data are not bounded on either side
(say by 0 and 100 as for exam scores) then it is quite likely that that
they are. If they are count data, or ordinal data, then it is quite
likely that they are not.

This way of thinking may be all you can do when data sets are very small
and any of the more robust tests for normality presented here leave you
not much the wiser.

\subsection{\texorpdfstring{Do the actual two-sample
\emph{t}-test}{Do the actual two-sample t-test}}\label{do-the-actual-two-sample-t-test}

So, it looks as though it is plausible that the data are drawn from
normal distributions. That means we can go on to use a parametric test
such as a two sample \emph{t}-test and have confidence in its output.

If we were doing this in R we could use the \texttt{t.test()} function
for this (other functions are available!). This needs to be given a
formula and a data set as arguments. Look up \texttt{t.test()} in R's
help documentation, and see if you can get the \emph{t}-test to tell you
whether there is a significant difference between ozone levels in the
east and in the west of the city.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(shell\_mass\_g}\SpecialCharTok{\textasciitilde{}}\NormalTok{pesticide,}\AttributeTok{data=}\NormalTok{snails)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Welch Two Sample t-test

data:  shell_mass_g by pesticide
t = 5.4172, df = 12.442, p-value = 0.0001372
alternative hypothesis: true difference in means between group No and group Yes is not equal to 0
95 percent confidence interval:
 0.8397234 1.9622766
sample estimates:
 mean in group No mean in group Yes 
            2.571             1.170 
\end{verbatim}

\subsection{\texorpdfstring{Interpret the output of the
\emph{t}-test.}{Interpret the output of the t-test.}}\label{interpret-the-output-of-the-t-test.}

Study the output of the \emph{t}-test. Here are some questions to ask
yourself.

\begin{itemize}
\tightlist
\item
  What kind of test was carried out?

  \begin{itemize}
  \tightlist
  \item
    \emph{A Welch two sample t-test}
  \end{itemize}
\item
  What data was used for the test?

  \begin{itemize}
  \tightlist
  \item
    \emph{The snail shell mass in g (the output variable) and pesticide
    use (the explanatory variable)}
  \end{itemize}
\item
  What is the test statistic of the data?

  \begin{itemize}
  \tightlist
  \item
    \emph{This is t = 5.4172.}
  \end{itemize}
\item
  How many degrees of freedom were there? This number is the number of
  independent pices of information that were used to calculate the final
  result. It is usually one, two, or three or so less than the number of
  data points. Don't overthink it at this stage, especially not the fact
  that here it is not an integer.

  \begin{itemize}
  \tightlist
  \item
    \emph{df = 12.442}
  \end{itemize}
\item
  What is the p-value?

  \begin{itemize}
  \tightlist
  \item
    \emph{p = 0.0001372. You would most likely report this as p
    \textless{} 0.001}
  \end{itemize}
\item
  What does the p value mean?

  \begin{itemize}
  \tightlist
  \item
    \emph{It is the likelihood of seeing a difference between sample
    means as large or larger than the one we found if in fact pesticides
    made no difference to snail shell mass.}
  \end{itemize}
\item
  What is the confidence interval for the difference between shell
  masses in gardens that use pesticides and in gardens that do not? Does
  it encompass zero? Remember that the confidence interval gives the
  range of values within which the true difference between mean shell
  masses might reasonably lie, given the data. If that range includes
  zero then the test is telling is that zero is a plausible value for
  the difference, and hence that we cannot reject the null hypothesis.

  \begin{itemize}
  \tightlist
  \item
    \emph{The 95\% confidence interval has lower bound 0.8397 and upper
    bound 1.962.}
  \end{itemize}
\item
  Is there sufficient evidence to reject the null hypothesis?

  \begin{itemize}
  \tightlist
  \item
    \emph{Yes. We see this in two ways. First the p value is much less
    than 0.05 and second, the 95\% confidence interval does not
    encompass zero. In a way, the confidence interval is giving us more
    information than the p-value, since not only can we deduce whether
    there is evidence for a significant difference, we can also see how
    big that difference is and how precisely we know it.}
  \end{itemize}
\item
  What does the word `Welch' tell you - Google it or look it up in the
  help for \texttt{t.test()}.

  \begin{itemize}
  \tightlist
  \item
    \emph{It tells us that a variant of the t-test is being used in
    which it does not matter if the two. samples have difference
    variances (spreads).}
  \end{itemize}
\end{itemize}

\section{\texorpdfstring{Other examples where a two sample \emph{t}-test
might be
used.}{Other examples where a two sample t-test might be used.}}\label{other-examples-where-a-two-sample-t-test-might-be-used.}

Remember that \emph{t}-tests in general are used when you have
independent samples with multiple replicates drawn from populations
corresponding to \textbf{two} levels of some factor (eg north coast,
south coast; this beach, that beach; polluted place, clean place etc)
and you have measured something numerical, like a length or a mass,
temperature or concentration. You still have to do the tests for
normality described above, but these are the basic criteria.

\subsection{\texorpdfstring{Can you think of examples of where you might
use a two-sample
\emph{t}-test?}{Can you think of examples of where you might use a two-sample t-test?}}\label{can-you-think-of-examples-of-where-you-might-use-a-two-sample-t-test}

Here are a few suggestions:

\begin{itemize}
\item
  Is there a difference between the flight initiation distance of
  redstarts when confronted by dogs compared to when they are confronted
  by drones?
\item
  Is the nitrate concentration of water in a river below a beaver dam
  different from the nitrate content above that dam?
\end{itemize}

Can you think of another example?

\section{\texorpdfstring{What if I can't use a two sample
\emph{t}-test?}{What if I can't use a two sample t-test?}}\label{what-if-i-cant-use-a-two-sample-t-test}

\begin{itemize}
\item
  Assuming you have two independent samples, this might be because one
  or both sets failed the normality criterion, or your data are ordinal.
  In that case the likely alternative is the \textbf{non-parametric}
  equivalent of the \emph{t}-test, variously known as the Wilcoxon Rank
  Sum test or the Mann Whitney U test.
\item
  If your data are in fact sets of \textbf{paired values}, for example
  because you measured some attribute of the same individuals before and
  after some treatment, or at two points in time, then you need to use
  the paired \emph{t}-test.
\item
  If you only have \textbf{one sample} of replicates and want to compare
  its mean value to a threshold, then you use a one sample t-test. You
  might do this, for example, if you had collected sediment samples from
  an estuary, measured the concentration in those samples of some
  pollutant such as pathogens from sewage, or phosphates from farm
  runoff, and then wanted to see if the water was compliant with water
  quality thresholds as dictated by, say, the Water Framework Directive.
\end{itemize}

\section{The non-parametric case}\label{the-non-parametric-case}

A common scenario is that we have two sets of measurements, and we want
to see if there is evidence that they are drawn from different
populations. For some data types we can use a \emph{t}-test to do this,
but for others we cannot.

A \emph{t}-test requires in particular that the two sets of data are
normally distributed around their respective means. With \emph{ordinal}
data this makes no sense. The mean is undefined as a concept for such
data.

To see this , reflect that for a collection \(X\) of numerical data,
say, 5, 3, 3, 4, and 5 we would calculate the mean as:

\[
\bar{X} = \frac{5+3+3+4+5}{5} = \frac{20}{5}=4
\]

But trying doing the same to five responses of a Likert scale survey.
Say the responses you had to five Likert items (individual questions)
were ``strongly disagree'', ``strongly agree'', ``mildly disagree'',
``strongly disagree'' and ``don't care either way''. If you tried to
calculate a `mean' response you would be attempting to add up all these
responses and to divide the `sum' by five, like this:

\[\text{mean response}=\frac{\text{stongly disagree}+\text{strongly agree}+\text{mildly disagree}+\text{stongly disagree}+\text{don't care either way}}{5} = ?
\] This sum makes no sense, I hope you will agree. It makes no sense,
not because we are using words to describe our responses, but because,
as these are ordinal data, we do not know the size of the gaps between
the different points on the scale. Is the difference in agreement
between the lowest two, ``strongly disagree'' and ``midly disagree'' the
same as the gap between the highest two, ``mildly agree'' and ``strongly
agree''? We don't know, mainly because `agreement' is not something that
can be measured easily using something like a weighing machine. And if
we don't know, then we shouldn't really be adding these responses up or
dividing them by anything.

Nevertheless, ordinal data are very common, since they are typically
what is generated by survey data, where for example repondents may
answer a series of questions (`items'), each with typically five
possible responses, but maybe more or fewer, these responses being
ordinal in the sense that there is a definite order to them. They might
encompass responses like those above, say, or something similar like
``very unhappy'' to ``very happy''. They are also common in clinical and
veterinary practice where ordinal pain scores are widely used - patients
being asked (if they are human) or assessed as to their level of pain on
a scale of 1-10, for example. Note that even if the pain value is
recorded as a number it is actually a label, that could just as well
have been recorded as one of a series of letters, A, B, C etc or emojis,
or any symbol you like. You can't take the average of a set of faces!

Thus, formally, we need another kind of test for a difference. Broadly,
we need to use some form of \emph{non-parametric} test where we do not
assume that the data has any form of distribution, and where, often, we
do not use the actual values of the measurements in our dataset but
instead use only their \emph{ranks}. The smallest value would be given
rank 1, the next rank 2 and so on.

There are many non-parametric tests out there. Here we will look at only
one - the \textbf{Wilcoxon Rank Sum Test}, often referred to as a
\textbf{Mann-Whitney U} test for a difference. We can use this for the
scenario we have painted above, where we have two sets of data and we
wish to know if these provide evidence that the populations from which
the samples have been drawn are in fact different.

\subsection{Example}\label{example}

This example uses actual data gathered by a student at Newquay
University Centre.

The student wished to assess peoples' sense of wellbeing using two
different sets of questions designed to assess this. The scales chosen
were the Warwick--Edinburgh Mental Well-being Scale (WEMWBS) and the New
Ecological Paradigm (NEP) Scale. The student wished in particular to
determine whether this sense of well-being was affected by whether a
person often and actively frequented the coast and made it and the sea a
substantive part of their life in one way or another. ie to find out
whether there was evidence to support the notion that it could be good
for your mental wellbeing to be by the sea and to make it part of your
life.

Each scale used consists of 15 questions or `Likert items', each of
which is answered on a 5 point ordinal scale, where a score of 1
indicates lowest wellbeing and a score of 5 indicates highest wellbeing.
Thus each respondent could score anything from 15 to 75.

The student got responses from 374 people, 86 of whom were not
``marine'' users, while the other 288 say that they \emph{were} marine
users. The total scores from each respondent were recorded for each type
of survey and stored in the file \texttt{wellness.csv} which you should
find on the module Moodle site / Teams page. Please put this file in the
\texttt{data} folder of your R project.

\subsection{Script}\label{script}

Code chunks for a script to carry out the analysis of this data are
provided below. To use them you should create a new Quarto document
using File/New File/Quarto document, from which you delete all the
exemplar material below the yaml section at the top. The first few
chunks of this script carry out the same old-same old that we see in
script after script: load packages, load data, summarise data , plot
data. Copy and paste any chunks you want to use into your own script
then adapt them as necessary.

You can run your script by running each chunk in sequence, which you do
by clicking the green arrow in the top-right corner of each chunk.

Try also to `Render' the script by clicking on the Render button at the
top of the script pane.

\subsubsection{Load packages}\label{load-packages-1}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(here)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Load data}\label{load-data-1}

Our data set is in a \texttt{.csv} file which we have placed in the data
folder within our project folder.

Note that this data set has been stored in `tidy' form: each variable
appears in only column, and each observation appears in only one row.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath}\OtherTok{\textless{}{-}}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"wellness.csv"}\NormalTok{)}
\NormalTok{wellness}\OtherTok{\textless{}{-}}\FunctionTok{read\_csv}\NormalTok{(filepath)}
\FunctionTok{glimpse}\NormalTok{(wellness)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 748
Columns: 4
$ id          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,~
$ scale       <chr> "WEMWBS", "WEMWBS", "WEMWBS", "WEMWBS", "WEMWBS", "WEMWBS"~
$ marine      <chr> "Yes", "No", "No", "No", "Yes", "Yes", "Yes", "No", "Yes",~
$ total_score <dbl> 48, 51, 37, 39, 38, 40, 54, 39, 54, 39, 51, 50, 49, 51, 54~
\end{verbatim}

\subsubsection{Summarise the data}\label{summarise-the-data-1}

We'll calculate the median score (50th percentile) and the 25th and 75th
percentile scores. For ordinal data, these summary statistics are well
defined, whereas means and standard deviations are not.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wellness }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(scale,marine) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{median.score=}\FunctionTok{median}\NormalTok{(total\_score),}\AttributeTok{iqr\_25=}\FunctionTok{quantile}\NormalTok{(total\_score,}\FloatTok{0.25}\NormalTok{),}\AttributeTok{iqr\_75=}\FunctionTok{quantile}\NormalTok{(total\_score,}\FloatTok{0.75}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 5
# Groups:   scale [2]
  scale  marine median.score iqr_25 iqr_75
  <chr>  <chr>         <dbl>  <dbl>  <dbl>
1 WEMWBS No             42.5   36       49
2 WEMWBS Yes            47     41       51
3 nep    No             51     48.2     53
4 nep    Yes            50     48       53
\end{verbatim}

\subsubsection{Plot the data}\label{plot-the-data-1}

Box plots are particularly suitable for ordinal data since they show the
25th and 75th percentiles of the data (the bottom and top of the box)
plus the 50th percentile aka the median, which is the thick line across
each box. All of these percentiles are well defined quantities for
ordinal data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wellness }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ scale,}\AttributeTok{y =}\NormalTok{ total\_score,}\AttributeTok{fill =}\NormalTok{ marine)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Likert Scale"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Wellbeing Score"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/unnamed-chunk-12-1.pdf}}

Looking at the plot, what do you think each scale suggests about whether
proximity to the sea makes a difference to wellbeing?

\subsubsection{Wilcoxon-Mann-Whitney U
test}\label{wilcoxon-mann-whitney-u-test}

First let's pull out the scores as measured by the WEMWBS scale and do a
test for a difference between the scores of marine users and those of
non-marine users. We can use the \texttt{filter()} function to do this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{WEMWBS}\OtherTok{\textless{}{-}}\NormalTok{wellness }\SpecialCharTok{|\textgreater{}} \FunctionTok{filter}\NormalTok{(scale}\SpecialCharTok{==}\StringTok{"WEMWBS"}\NormalTok{) }\CommentTok{\# save the WEMWBS data into a data frame called WEMWBS}
\FunctionTok{glimpse}\NormalTok{(WEMWBS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 374
Columns: 4
$ id          <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,~
$ scale       <chr> "WEMWBS", "WEMWBS", "WEMWBS", "WEMWBS", "WEMWBS", "WEMWBS"~
$ marine      <chr> "Yes", "No", "No", "No", "Yes", "Yes", "Yes", "No", "Yes",~
$ total_score <dbl> 48, 51, 37, 39, 38, 40, 54, 39, 54, 39, 51, 50, 49, 51, 54~
\end{verbatim}

Now let's do the actual Wilcoxon-Mann-Whitney U test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(total\_score}\SpecialCharTok{\textasciitilde{}}\NormalTok{marine,}\AttributeTok{data=}\NormalTok{WEMWBS)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Wilcoxon rank sum test with continuity correction

data:  total_score by marine
W = 9077.5, p-value = 0.0001687
alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

The null hypothesis of this test is that there is no evidence that the
data are drawn from different populations. In this case, the
\emph{p}-value is very small, so we can confidently reject that null
hypothesis and assert that there is evidence, according to the WEMWBS
scale that marine use makes a difference to peoples' sense of wellbeing.

Does it make it worse or better? - we can see from the summary table and
from the box plot that higher scores are associated with those people
who were exposed to a marine environment.

We might report this results as follows, first using a plain English
statement of the main finding, and then reporting the type of test use,
the value of the test statistic that it calculated and the p value. In
this case, because the p value is so small, we would not report its
exact value, but simply give an indication of how small it is:

\emph{We find evidence, according to the WEMWBS scale, that the
wellbeing score is 4.5 or about 10\% higher for people exposed to a
marine environment (Mann-Whitney U, W = 9077.5, p \textless{} 0.001).}

\subsection{Exercise}\label{exercise}

Adapt the code of the last chunk so that you can do the same test but
for data as recorded by the nep scale

\subsection{When should I use this Wilcoxon-Mann-Whitney U
test?}\label{when-should-i-use-this-wilcoxon-mann-whitney-u-test}

The test we have used here is an example of a \emph{non-parametric}
test. This means that it does not assume that the data follow a known
mathematical distribution and, further, that it can be used with ordinal
data.

We used the Mann-Whitney U test in particular because we were testing
for a difference, and because the factor of interest - marine exposure -
had just two levels - Yes or No.~This test is only suitable when there
are just two levels, so you can think of it as as a non-parametric
alternative to a t-test.

In another setting where we still had just one factor (eg zone of a
rocky shore) but there were more than two levels (eg low, mid and high
zones of the shore) and we decided that we wanted to do a non-parametric
test for a difference, then we would probably use the
\textbf{Kruskal-Wallis} test, which you can think of as the
non-parametric alternative to a one-way ANOVA.

In this example we used the Mann-Whitney U test because the data were
ordinal and thus not suitable to use with a parametric test (but see
below!). Where we can, we usually try to use a parametric test as they
are more powerful than their non-parametric equivalents, meaning, if
there is a trend or a difference in the data, they are better able to
detect it. However those parametric tests (t-test, ANOVA, pearson
correlation, PCA, GLM to name but a few) typically require not only that
the data are numerical but also a host of other things, including that
they follow a particular distribution, usually (but not always) the
normal distribution, and this is often not the case with real biological
data. Often, especially with count data, there are lots of zeros, or the
data distribution is heavily skewed, usually to the right. In these
cases, providing the data are independent of each other, we can usually
still use a non-parametric test such as we have here. it might not be
the most powerful test we can use (GLMs are typically way better if you
can use them), but it will work.

\subsection{Hang on!}\label{hang-on}

The eagle eyed among you may have spotted a massive flaw in the line of
argument presented above. We said that ordinal data can't be added up,
can't be used to calculate averages and so on. Thus we can't run
parametric tests on them and have to look for alternatives, namely,
non-parametric tests.

And yet, these non-parametric tests are usually run on the output of
Likert \emph{scales} such as we have considered here, where for each
person we have a number of Likert \emph{Items} (ie individual questions)
that together constitute the \emph{scale}, that each generate a score
1-5, then we \emph{add up the scores} to get a total score. But that
means we are adding up ordinal data!!!

It turns out that you actually get much the same results with Likert
scale data if you analyse them using supposedly inappropriate parametric
tests such as a 2-sample \emph{t}-test as you do if you use a
non-parametric test such as the one we considered here, the Mann-Whitney
test.

A study by De Winter and Dodou (2010) shows this convincingly.

de Winter, J. F. C., \& Dodou, D. (2010). Five-Point Likert Items: t
test versus Mann-Whitney-Wilcoxon (Addendum added October 2012).
Practical Assessment, Research, and Evaluation,15, 1--16.
https://doi.org/10.7275/bj1p-ts64

For an enlightening discussion of this paper, see
\href{https://statisticsbyjim.com/hypothesis-testing/analyze-likert-scale-data/}{this
blog by Jim Frost}

\section{Paired data}\label{paired-data}

Often one has a sample of replicated data where each element has a
counterpart in another matched sample - paired data. A common scenario
for this is when there are data for the same individual at two different
points in time, for example before and after some event such as the
application of a treatment.

In order to determine whether there is a difference between the two
sets, one should take the paired aspect into account and not simply
match the whole before-set against the whole after-set without doing
this. That would be to throw away the information whereby there is
likely to be a greater degree of correlation between the responses of an
individual before and after the event than there is between any randomly
chosen pairs of individuals before and after the event.

\subsection{Which test: paired t-test or Wilcoxon signed rank
test?}\label{which-test-paired-t-test-or-wilcoxon-signed-rank-test}

There is a choice between at least two tests: the parametric paired
t-test and the non-parametric Wilcoxon signed rank test. Ideally one
would use the t-test since it is more powerful than the Wilcoxon test.
This means several things, but in particular it means that, all else
being equal, it can detect a small difference with higher probability
than the Wilcoxon test can.

\subsection{The paired t-test}\label{the-paired-t-test}

Where the data are numerical (ie not ordinal) and where the before and
after data are both normally distributed around their respective mean
values one would use the \emph{paired t-test} in this scenario. One can
test for normality using either a test such as the Shapiro-Wilk test, or
graphically using either a histogram, a box plot, or (best), a
quantile-quantile plot.

\subsection{The Wilcoxon Signed Rank
test}\label{the-wilcoxon-signed-rank-test}

The t-test, an example of a so-called parametric test, is actually
pretty robust against departures from normality, but where one doubts
its validity due to extreme non-normality or for other reasons such as
the ordinal nature of the data, the Wilcoxon signed rank test is a
useful non-parametric alternative. It is called non-parametric because
it does not make any assumption about the distribution of the data
values. It only uses their ranks, where the smallest value gets rank 1,
the next smallest gets rank 2, and so on.

So, you typically use this test when you would like to use the paired
t-test, but you cannot because one or both of the data sets is way off
being normally distributed or is ordinal.

\subsubsection{Null Hypotheses}\label{null-hypotheses}

In both the t-test and the Wilcoxon signed rank tests, the null
hypothesis is the usual `nothing going on', `there is no difference'
scenario, but there is a subtle difference between them that reflects
the different information that they use. In the Wilcoxon signed rank
test the null is that the difference between the \emph{medians} of pairs
of observations is zero. This is different from the null hypothesis of
the paired t--test, which is that the difference between the
\emph{means} of pairs is zero.

\subsubsection{Test output}\label{test-output}

Both tests will give a p value. This is the probability that the mean
(t-test) or median (Wilcoxon signed rank) paired differences between the
corresponding before and after sample elements would be equal to or
greater than it actually is for the data if the null hypothesis were
true. If the p value is less than some pre-decided `significance level',
usually taken to be 0.05, then we reject the null hypothesis. If it is
not, then we fail to reject the null hypothesis.

\subsection{Example}\label{example-1}

We will use as an example a data set from Laureysens et al.~(2004) that
has measurements of metal content in the wood of 13 poplar clones
growing in a polluted area, once from each clone in August and once
again from each of them in November. The idea was to investigate the
extent to which poplars could absorb metals from the soil and thus be
useful in cleaning that up. Under a null hypothesis, there would be no
change in the metal concentrations in the plant tissue of each clone
between August and November. Under an alternate hypothesis, there would
be.

Laureysens, I. et al.~(2004) `Clonal variation in heavy metal
accumulation and biomass production in a poplar coppice culture: I.
Seasonal variation in leaf, wood and bark concentrations', Environmental
Pollution, 131(3), pp.~485--494. Available at:
https://doi.org/10.1016/j.envpol.2004.02.009.

Concentrations of aluminum (in micrograms of Al per gram of wood) are
shown below.

\textbf{Load packages}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{ (tidyverse)}
\FunctionTok{library}\NormalTok{(here)}
\FunctionTok{library}\NormalTok{(cowplot) }\CommentTok{\# to make the plots look nice}
\end{Highlighting}
\end{Shaded}

\textbf{Load data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath }\OtherTok{\textless{}{-}} \FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"poplars{-}paired\_np.csv"}\NormalTok{)}
\NormalTok{poplars }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(filepath,}\AttributeTok{show\_col\_types =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{head}\NormalTok{(poplars,}\DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 13 x 4
      ID Clone          August November
   <dbl> <chr>           <dbl>    <dbl>
 1     1 Balsam_Spire      8.1     11.2
 2     2 Beaupre          10       16.3
 3     3 Hazendans        16.5     15.3
 4     4 Hoogvorst        13.6     15.6
 5     5 Raspalje          9.5     10.5
 6     6 Unal              8.3     15.5
 7     7 Columbia_River   18.3     12.7
 8     8 Fritzi_Pauley    13.3     11.1
 9     9 Trichobel         7.9     19.9
10    10 Gaver             8.1     20.4
11    11 Gibecq            8.9     14.2
12    12 Primo            12.6     12.7
13    13 Wolterson        13.4     36.8
\end{verbatim}

\textbf{Plot the data}

Before we do any test on some data to find evidence for a difference or
a trend, it is a good idea to plot the data. This will reveal whatever
patterns there are in the data and how likely they are to reveal a truth
about the population from which they have been drawn.

\textbf{Tidy the data}

In this case there is work to do before we can plot the data. The
problem is that the data is `untidy'. The two levels of the factor
\texttt{month} are spread across two columns, August and November. For
plotting purposes it will be useful to `tidy' the data so that there is
only one column containing both levels of \texttt{month} and another
containing the aluminium concentrations. The function
\texttt{pivot\_longer()} can do this for us:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poplars\_tidy }\OtherTok{\textless{}{-}}\NormalTok{ poplars }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pivot\_longer}\NormalTok{ (August}\SpecialCharTok{:}\NormalTok{November,}\AttributeTok{names\_to=}\StringTok{"month"}\NormalTok{,}\AttributeTok{values\_to=}\StringTok{"Al\_conc"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(poplars\_tidy,}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 8 x 4
     ID Clone        month    Al_conc
  <dbl> <chr>        <chr>      <dbl>
1     1 Balsam_Spire August       8.1
2     1 Balsam_Spire November    11.2
3     2 Beaupre      August      10  
4     2 Beaupre      November    16.3
5     3 Hazendans    August      16.5
6     3 Hazendans    November    15.3
7     4 Hoogvorst    August      13.6
8     4 Hoogvorst    November    15.6
\end{verbatim}

Now we can plot the data as a box plot, with one box for August and one
for November ie one for each level of the factor \texttt{month}. Had we
not first tidied the data, we could not have done this.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poplars\_tidy }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ month, }\AttributeTok{y =}\NormalTok{ Al\_conc, }\AttributeTok{fill =}\NormalTok{ month, }\AttributeTok{colour =}\NormalTok{ month)) }\SpecialCharTok{+} 
  \CommentTok{\# alpa (= opacity) \textless{} 1 in case any points are on top of each other}
  \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{outlier.size=}\DecValTok{0}\NormalTok{,}\AttributeTok{alpha=}\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# group = ID makes the lines join elements of each pair}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{group=}\NormalTok{ID),}\AttributeTok{colour =} \StringTok{"grey60"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Month"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Al conc.(mu g Al / g wood)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{tests_for_difference_two_levels_files/figure-pdf/unnamed-chunk-18-1.pdf}}

Does it look as though the difference between the medians could
plausibly be zero for the population from which these samples were
drawn? Or, put another way, if it was zero, how big a fluke would this
sample be? That is what the p value actually tells us.

\subsection{Two sample paired t-test}\label{two-sample-paired-t-test}

\textbf{Check for normality of differences}

Before we use the t-test, we need to check that it is OK to do so. This
means checking whether the paired differences are plausibly drawn from a
normal distribution centred on zero.

The null hypothesis of the Shapiro-Wilk test is that the data set given
to it \emph{is} plausibly drawn from a normally distributed population.
So let us give our sample of paired differences:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(poplars}\SpecialCharTok{$}\NormalTok{August}\SpecialCharTok{{-}}\NormalTok{poplars}\SpecialCharTok{$}\NormalTok{November)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  poplars$August - poplars$November
W = 0.92667, p-value = 0.3081
\end{verbatim}

The p value is very high. Thus we do not reject the null hypothesis and
we can reasonably assume that the differences between the August and
November aluminium concentrations in the sample could plausibly have
been drawn from a normally distributed population, despite the outlier
value in the November sample. Thus we can reasonably test for difference
using a paired t-test.

\textbf{The actual t-test}

We can do this in R using the function \texttt{t.test()}, where we give
to the function both the August and the November data, knowing that each
August value has a counterpart November value, and we set the argument
\texttt{paired} to \texttt{TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(poplars}\SpecialCharTok{$}\NormalTok{August, poplars}\SpecialCharTok{$}\NormalTok{November, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Paired t-test

data:  poplars$August and poplars$November
t = -2.3089, df = 12, p-value = 0.03956
alternative hypothesis: true mean difference is not equal to 0
95 percent confidence interval:
 -9.5239348 -0.2760652
sample estimates:
mean difference 
           -4.9 
\end{verbatim}

All parts of the output have meaning and are useful, but here we will
focus on just two:

\begin{itemize}
\tightlist
\item
  the p value is equal to 0.040. Hence, if we have chosen the usual
  significance value of 0.05, we can take this to mean that there is
  evidence of a significant difference between the August and November
  values.
\item
  the lower and upper bounds of the 95\% confidence interval are (-9.52,
  -0.28). YOu can think of this interval as the range of values within
  which the difference can plausibly lie, at the 95\% confidence level.
  The key thing is that this range does not encompass zero. This means
  that we can be confident at the 95\% level that there is a non-zero
  change on going from August to November, and, in particular, that the
  August value is lower than the November value.
\end{itemize}

\subsection{The non-parametric alternative: The Wilcoxon signed rank
test}\label{the-non-parametric-alternative-the-wilcoxon-signed-rank-test}

To be safe, because of that outlier, let us test for difference using
the Wilcoxon signed rank test. In R this is done using the function
\texttt{wilcox.test()}, with the argument \texttt{paired} set to
\texttt{TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(poplars}\SpecialCharTok{$}\NormalTok{August, poplars}\SpecialCharTok{$}\NormalTok{November, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Wilcoxon signed rank exact test

data:  poplars$August and poplars$November
V = 16, p-value = 0.03979
alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

We see that the conclusion (in this case) is the same.

\subsection{Relation to one-sample paired
test}\label{relation-to-one-sample-paired-test}

The two-sample paired tests as we have done above are the same as doing
a one-sample test to see if the differences between the August and
November paired values is different from zero. This is true whether we
do a t-test or a Wilcoxon signed rank test.

In either case, the first argument is the vector of differences, and the
second \texttt{mu} is the threshold value against which we want to
compare those differences, in this case zero.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(poplars}\SpecialCharTok{$}\NormalTok{August }\SpecialCharTok{{-}}\NormalTok{ poplars}\SpecialCharTok{$}\NormalTok{November, }\AttributeTok{mu =} \DecValTok{0}\NormalTok{, }\AttributeTok{data =}\NormalTok{ poplars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    One Sample t-test

data:  poplars$August - poplars$November
t = -2.3089, df = 12, p-value = 0.03956
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 -9.5239348 -0.2760652
sample estimates:
mean of x 
     -4.9 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(poplars}\SpecialCharTok{$}\NormalTok{August }\SpecialCharTok{{-}}\NormalTok{ poplars}\SpecialCharTok{$}\NormalTok{November, }\AttributeTok{mu =} \DecValTok{0}\NormalTok{, }\AttributeTok{data =}\NormalTok{ poplars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Wilcoxon signed rank exact test

data:  poplars$August - poplars$November
V = 16, p-value = 0.03979
alternative hypothesis: true location is not equal to 0
\end{verbatim}

Note that the output from both these one-sample tests, where the one
sample is the vector of differences and the threshold with which it is
compared is zero, is exactly the same as the output of the two-sample
tests where the two samples were the vectors between which we were
interested in detecting a difference, ie the August and November values.
This is not surprising since the two cases are just two ways of doing
exactly the same thing, which is to ask if there is evidence from the
sample for a difference in the population between the August and
November concentrations of aluminium.

\bookmarksetup{startatroot}

\chapter{Analysis of Variance aka
ANOVA}\label{analysis-of-variance-aka-anova}

Material used from Chapter One of Grafen and Hails: Modern Statistics
for the Life Sciences

\section{What is ANOVA?}\label{what-is-anova}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fertilizer }\OtherTok{\textless{}{-}}\NormalTok{ fertilizer }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{FERTIL=}\FunctionTok{as.factor}\NormalTok{(FERTIL))}
\end{Highlighting}
\end{Shaded}

\subsection{The basic principles of
ANOVA}\label{the-basic-principles-of-anova}

In a simple case we consider the comparison of three means. This is done
by the analysis of variance (ANOVA). In this case we will go through an
example in detail and work out all the mechanics, but once we have done
that and seen how the output is derived from the input we will not need
to do it again. We will use R to do the heavy lifting. We will just need
to know when it is appropriate to use ANOVA, how to get R to do it and
how to interpret the output that R produces.

\subsection{The Scenario}\label{the-scenario}

Suppose we have three fertilizers and wish to compare their efficacy.
This has been done in a field experiment where each fertilizer is
applied to 10 plots and the 30 plots are later harvested, with the crop
yields being calculated. We end up with three groups of 10 figures and
we wish to know if there are any differences between these groups.

When we plot the data we see that the fertilizers do differ in the
amount of yield produced but that there is also a lot of variation
between the plots that were given the same fertilizer.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g1}\OtherTok{\textless{}{-}}\FunctionTok{ggplot}\NormalTok{(fertilizer,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{FERTIL,}\AttributeTok{y=}\NormalTok{YIELD, }\AttributeTok{fill=}\NormalTok{ FERTIL,}\AttributeTok{alpha=}\FloatTok{0.1}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{colour=}\NormalTok{FERTIL))}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{limits=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Fertilizer\textquotesingle{}}\NormalTok{, }\AttributeTok{y=}\StringTok{\textquotesingle{}Yield\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g2}\OtherTok{\textless{}{-}}\FunctionTok{ggplot}\NormalTok{(fertilizer,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{plot,}\AttributeTok{y=}\NormalTok{YIELD,}\AttributeTok{colour=}\NormalTok{FERTIL))}\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{()}\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{limits=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Plot number\textquotesingle{}}\NormalTok{,}\AttributeTok{y=}\StringTok{\textquotesingle{}Yield per plot (tonnes)\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{grid.arrange}\NormalTok{(g2,g1,}\AttributeTok{nrow=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-1-1.pdf}}

\subsection{What does an ANOVA do?}\label{what-does-an-anova-do}

An ANOVA (ANalysis Of VAriance) analysis attempts to determine whether
the differences between the effect of the fertilizers is significant by
investigating the variability in the data. We investigate how the
variability \emph{between} groups compares to the variability
\emph{within} groups.

\subsection{Grand Mean}\label{grand-mean}

First we calculate the `grand mean', the mean of the yields across all
30 plots:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grand\_mean}\OtherTok{=}\FunctionTok{mean}\NormalTok{(fertilizer}\SpecialCharTok{$}\NormalTok{YIELD)}
\NormalTok{grand\_mean}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 4.643667
\end{verbatim}

\subsubsection{Deviations from the grand
mean}\label{deviations-from-the-grand-mean}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SST.plot}\OtherTok{\textless{}{-}}\NormalTok{g2}\SpecialCharTok{+}\FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\NormalTok{grand\_mean,}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dashed\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ plot, }\AttributeTok{y =}\NormalTok{ YIELD, }\AttributeTok{xend =}\NormalTok{ plot, }\AttributeTok{yend =}\NormalTok{ grand\_mean),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}
\NormalTok{SST.plot}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/SST plot-1.pdf}}

\subsubsection{Mean value of yield for each
fertilizer}\label{mean-value-of-yield-for-each-fertilizer}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f\_means}\OtherTok{\textless{}{-}}\NormalTok{fertilizer }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(FERTIL) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{fmean=}\FunctionTok{mean}\NormalTok{(YIELD))}
\NormalTok{f\_means}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 2
  FERTIL fmean
  <fct>  <dbl>
1 1       5.44
2 2       4.00
3 3       4.49
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fertilizer}\OtherTok{\textless{}{-}}\FunctionTok{mutate}\NormalTok{(fertilizer,}\AttributeTok{fmean=}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(f\_means}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\DecValTok{10}\NormalTok{),}\FunctionTok{rep}\NormalTok{(f\_means}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{2}\NormalTok{],}\DecValTok{10}\NormalTok{),}\FunctionTok{rep}\NormalTok{(f\_means}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{3}\NormalTok{],}\DecValTok{10}\NormalTok{)))}

\NormalTok{f1}\OtherTok{\textless{}{-}}\FunctionTok{filter}\NormalTok{(fertilizer,FERTIL}\SpecialCharTok{==}\DecValTok{1}\NormalTok{)}
\NormalTok{f2}\OtherTok{\textless{}{-}}\FunctionTok{filter}\NormalTok{(fertilizer,FERTIL}\SpecialCharTok{==}\DecValTok{2}\NormalTok{)}
\NormalTok{f3}\OtherTok{\textless{}{-}}\FunctionTok{filter}\NormalTok{(fertilizer,FERTIL}\SpecialCharTok{==}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g3}\OtherTok{\textless{}{-}}\FunctionTok{ggplot}\NormalTok{()}\SpecialCharTok{+}
  
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data=}\NormalTok{f1,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{plot,}\AttributeTok{y=}\NormalTok{YIELD))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\FunctionTok{min}\NormalTok{(f1}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{y=}\NormalTok{f1}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\AttributeTok{xend=}\FunctionTok{max}\NormalTok{(f1}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{yend=}\NormalTok{f1}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ f1}\SpecialCharTok{$}\NormalTok{plot, }\AttributeTok{y =}\NormalTok{ f1}\SpecialCharTok{$}\NormalTok{YIELD, }\AttributeTok{xend =}\NormalTok{ f1}\SpecialCharTok{$}\NormalTok{plot, }\AttributeTok{yend =}\NormalTok{ f1}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data=}\NormalTok{f2,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{plot,}\AttributeTok{y=}\NormalTok{YIELD))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\FunctionTok{min}\NormalTok{(f2}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{y=}\NormalTok{f2}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\AttributeTok{xend=}\FunctionTok{max}\NormalTok{(f2}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{yend=}\NormalTok{f2}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ f2}\SpecialCharTok{$}\NormalTok{plot, }\AttributeTok{y =}\NormalTok{ f2}\SpecialCharTok{$}\NormalTok{YIELD, }\AttributeTok{xend =}\NormalTok{ f2}\SpecialCharTok{$}\NormalTok{plot, }\AttributeTok{yend =}\NormalTok{ f2}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{data=}\NormalTok{f3,}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{plot,}\AttributeTok{y=}\NormalTok{YIELD))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\FunctionTok{min}\NormalTok{(f3}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{y=}\NormalTok{f3}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\AttributeTok{xend=}\FunctionTok{max}\NormalTok{(f3}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{yend=}\NormalTok{f3}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ f3}\SpecialCharTok{$}\NormalTok{plot, }\AttributeTok{y =}\NormalTok{ f3}\SpecialCharTok{$}\NormalTok{YIELD, }\AttributeTok{xend =}\NormalTok{ f3}\SpecialCharTok{$}\NormalTok{plot, }\AttributeTok{yend =}\NormalTok{ f3}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{limits=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{10}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Plot number\textquotesingle{}}\NormalTok{,}\AttributeTok{y=}\StringTok{\textquotesingle{}Yield per plot (tonnes)\textquotesingle{}}\NormalTok{,}\AttributeTok{title=}\StringTok{"SSE: Error sum of squares"}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\subsection{Measures of variability}\label{measures-of-variability}

\subsubsection{SST - Total sum of
squares}\label{sst---total-sum-of-squares}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SST}\OtherTok{=}\FunctionTok{sum}\NormalTok{((fertilizer}\SpecialCharTok{$}\NormalTok{YIELD}\SpecialCharTok{{-}}\NormalTok{grand\_mean)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\NormalTok{SST}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 36.4449
\end{verbatim}

SST is the \textbf{total sum of squares.} It is the sum of squares of
the deviations of the data around the grand mean. This is a measure of
the total variability of the data set.

\subsubsection{SSE - Error sum of
squares}\label{sse---error-sum-of-squares}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSE}\OtherTok{\textless{}{-}}\NormalTok{fertilizer }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(FERTIL) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fmean=}\FunctionTok{mean}\NormalTok{(YIELD)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{se=}\NormalTok{(YIELD}\SpecialCharTok{{-}}\NormalTok{fmean)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{sse=}\FunctionTok{sum}\NormalTok{(se),}\AttributeTok{.groups =} \StringTok{\textquotesingle{}drop\textquotesingle{}}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{SSE=}\FunctionTok{sum}\NormalTok{(sse),}\AttributeTok{.groups =} \StringTok{\textquotesingle{}drop\textquotesingle{}}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{(SSE)}
\end{Highlighting}
\end{Shaded}

SSE is the \textbf{error sum of squares}. It is the sum of the squares
of the deviations of the data around the three separate group means.
This is a measure of the variation between plots that have been given
the same fertilizer.

\subsubsection{SSF - Fertilizer sum of
squares}\label{ssf---fertilizer-sum-of-squares}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSF}\OtherTok{\textless{}{-}}\NormalTok{fertilizer }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(FERTIL) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{fmean=}\FunctionTok{mean}\NormalTok{(YIELD)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{se=}\NormalTok{(fmean}\SpecialCharTok{{-}}\NormalTok{grand\_mean)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{sse=}\FunctionTok{sum}\NormalTok{(se),}\AttributeTok{.groups =} \StringTok{\textquotesingle{}drop\textquotesingle{}}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{SSF=}\FunctionTok{sum}\NormalTok{(sse),}\AttributeTok{.groups =} \StringTok{\textquotesingle{}drop\textquotesingle{}}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{pull}\NormalTok{(SSF)}
\end{Highlighting}
\end{Shaded}

SSF is the \textbf{fertilizer sum of squares}. This is the sum of the
squares of the deviations of the group means from the grand mean. This
is a measure of the variation between plots given different fertilizers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{g4}\OtherTok{\textless{}{-}}\FunctionTok{ggplot}\NormalTok{()}\SpecialCharTok{+}
  
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept=}\NormalTok{grand\_mean,}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dashed\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\FunctionTok{min}\NormalTok{(f1}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{y=}\NormalTok{f1}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\AttributeTok{xend=}\FunctionTok{max}\NormalTok{(f1}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{yend=}\NormalTok{f1}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{mean}\NormalTok{(f1}\SpecialCharTok{$}\NormalTok{plot), }\AttributeTok{y =}\NormalTok{ grand\_mean, }\AttributeTok{xend =} \FunctionTok{mean}\NormalTok{(f1}\SpecialCharTok{$}\NormalTok{plot), }\AttributeTok{yend =}\NormalTok{ f1}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\FunctionTok{min}\NormalTok{(f2}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{y=}\NormalTok{f2}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\AttributeTok{xend=}\FunctionTok{max}\NormalTok{(f2}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{yend=}\NormalTok{f2}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{mean}\NormalTok{(f2}\SpecialCharTok{$}\NormalTok{plot), }\AttributeTok{y =}\NormalTok{ grand\_mean, }\AttributeTok{xend =} \FunctionTok{mean}\NormalTok{(f2}\SpecialCharTok{$}\NormalTok{plot), }\AttributeTok{yend =}\NormalTok{ f2}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\FunctionTok{min}\NormalTok{(f3}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{y=}\NormalTok{f3}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{],}\AttributeTok{xend=}\FunctionTok{max}\NormalTok{(f3}\SpecialCharTok{$}\NormalTok{plot),}\AttributeTok{yend=}\NormalTok{f3}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]))}\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{mean}\NormalTok{(f3}\SpecialCharTok{$}\NormalTok{plot), }\AttributeTok{y =}\NormalTok{ grand\_mean, }\AttributeTok{xend =} \FunctionTok{mean}\NormalTok{(f3}\SpecialCharTok{$}\NormalTok{plot), }\AttributeTok{yend =}\NormalTok{ f3}\SpecialCharTok{$}\NormalTok{fmean[}\DecValTok{1}\NormalTok{]),}\AttributeTok{linetype=}\StringTok{\textquotesingle{}dotted\textquotesingle{}}\NormalTok{)}\SpecialCharTok{+}
  
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{limits=}\FunctionTok{c}\NormalTok{(}\FloatTok{2.5}\NormalTok{,}\FloatTok{7.5}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{\textquotesingle{}Plot number\textquotesingle{}}\NormalTok{,}\AttributeTok{y=}\StringTok{\textquotesingle{}Yield per plot (tonnes)\textquotesingle{}}\NormalTok{,}\AttributeTok{title=}\StringTok{"SSF:Fertilizer sum of squares"}\NormalTok{)}\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{grid.arrange}\NormalTok{(g3,g4,}\AttributeTok{nrow=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-4-1.pdf}}

When the three group means are fitted, there is an obvious reduction in
variability around the three means compared to that around the grand
mean, but it is not obvious if the fertilizers have had an effect on
yield.

At what point do we decide if the amount of variation explained by
fitting the means is significant? By this, we mean, ``When is the
variability between the group means greater than we would expect by
chance alone?

First, we note that SSF and SSE partition between them the total
variability in the data:

\subsection{SST = SSF + SSE}\label{sst-ssf-sse}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SST}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 36.4449
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSF}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 10.82275
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 25.62215
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSF}\SpecialCharTok{+}\NormalTok{SSE}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 36.4449
\end{verbatim}

So the total variability has been divided into two components. That due
to differences between plots given different treatments and that due to
differences between plots given the same treatment. Variability must be
due to one or other of these components. Separating the total SS into
its component SS is known as partitioning the sums of squares.

A comparison of SSF and SSE is going to indicate whether fitting the
three fertilizer means accounts for a significant amount of variability.

However, to make a proper comparison, we really need to compare the
variability per degree of freedom ie the variance.

\subsection{Partitioning the degrees of
freedom}\label{partitioning-the-degrees-of-freedom}

Every sum of squares (SS) has been calculated using a number of
independent pieces of information. In each, case, we call this number
the number of degrees of freedom for the SS.

For SST this number is one less than the number of data points \emph{n}.
This is because when we calculate the deviations of each data point
around a grand mean there are only \emph{n-1} of them that are
independent, since by definition the sum of these deviations is zero,
and so when \emph{n-1} of them have been calculated, the final one is
pre-determined.

Similarly, when we calculate SSF, which measures the deviation of the
group means from the grand mean, we have \(k\)-1 degrees of freedom,
(where in the present example \(k\), the number of treatments, is equal
to three) since the deviations must sum to zero, so when \(k\)-1 of them
have been calculated, the last one is pre-determined.

Finally, SSE, which measure deviation around the group means will have
\emph{n}-\emph{k} degrees of freedom, since the sum of each of the
deviations around one of the group means must sum to zero, and so when
all but one of them have been calculated, the final one is
pre-determined. There are \(k\) group means, so the total degrees of
freedom for SSE is \emph{n}-\emph{k}.

The degrees of freedom are additive: \[
df(\text{SST}) = df(\text{SSE}) + df(\text{SSF})
\] Check:

\begin{align*}
df(\text{SST}) &= n-1\\
df(\text{SSE}) &= k-1\\
df(\text{SSF}) &= n-k\\
\therefore df(\text{SSE}) + df(\text{SSF}) &= k-1 + n-k\\
&=n-1\\
&=df(\text{SST}) 

\end{align*}

\subsection{Mean Squares}\label{mean-squares}

Now we can calculate the \emph{variances} which are a measure of the
amount of variability per degree of freedom.

In this context, we call them \emph{mean squares}. To find each one we
divided each of the sums of squares (SS) by their corresponding degrees
of freedom.

Fertiliser Mean Square (FMS) = SSF / \emph{k} - 1. This is the variation
per \emph{df} between plots given different fertilisers.

Error Mean Square (EMS) = SSE / \emph{n} - \emph{k}. This is the
variation per \emph{df} between plots given the same fertiliser.

Total Mean Square (TMS) = SST / \emph{n} - 1. This is the total variance
per \emph{df} of the dataset.

Unlike the SS, the MS are not additive. That is, FMS + EMS \(\neq\) TMS.

\subsection{\texorpdfstring{\emph{F}-ratios}{F-ratios}}\label{f-ratios}

If none of the fertilizers influenced yield, we would expect as much
variation between the plots treated with the same fertilizer as between
the plots treated with different fertilizers.

We can express this in terms of the mean squares: the mean square for
fertilizer would be the same as the mean square for error:

\[
\frac{\text{FMS}}{\text{EMS}}=1
\] We call this ratio the \emph{F}-ratio. It is the end result of ANOVA.
\emph{F}-ratios can never be negative since they are the ratio of two
mean square values, both of which must be non-negative, but there is no
limit to how large they can be.

Even if the fertilizers were identical, the \emph{F}-ratio is unlikely
to be exactly 1 - it could by chance take a whole range of values. The
\textbf{F-distribution} represents the range and likelihood of all
possible \emph{F} ratios under the null hypothesis. ie when the
fertilizers were identical.

The shape of the F distribution depends on the degrees of freedom of FMS
and EMS, and we normally specify it by giving the values of each. Below
we show F distributions for 2 and 27 degrees of freedom (ie 3 plots, so
\emph{k} = 3, so the degrees of freedom of FMS = \emph{k}-1 =2, and 10
plants per plot, so \emph{n} = 3 x 10 =30, and hence the degrees of
freedom of EMS = \emph{n}-\emph{k} = 30 - 3 = 27), and for 10 and 27
degrees of freedom.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dfs}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"df = 2, 27"}\NormalTok{,}\DecValTok{601}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\StringTok{"df = 10, 27"}\NormalTok{,}\DecValTok{601}\NormalTok{))}
\NormalTok{xs}\OtherTok{\textless{}{-}}\FunctionTok{rep}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{6}\NormalTok{,}\FloatTok{0.01}\NormalTok{),}\DecValTok{2}\NormalTok{)}
\NormalTok{ys}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FunctionTok{df}\NormalTok{(xs[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{601}\NormalTok{],}\DecValTok{2}\NormalTok{,}\DecValTok{27}\NormalTok{),}\FunctionTok{df}\NormalTok{(xs[}\DecValTok{602}\SpecialCharTok{:}\DecValTok{1202}\NormalTok{],}\DecValTok{10}\NormalTok{,}\DecValTok{27}\NormalTok{))}
\NormalTok{fdata}\OtherTok{\textless{}{-}}\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x=}\NormalTok{xs,}\AttributeTok{y=}\NormalTok{ys,}\AttributeTok{dfs=}\NormalTok{dfs)}

\NormalTok{fdata }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{dfs =} \FunctionTok{fct\_relevel}\NormalTok{(dfs,}\StringTok{"df = 2, 27"}\NormalTok{,}\StringTok{"df = 10, 27"}\NormalTok{)) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{xs,}\AttributeTok{y=}\NormalTok{ys)) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{6}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x=}\StringTok{"F{-}ratio"}\NormalTok{,}
       \AttributeTok{y=}\StringTok{"Probability density"}\NormalTok{,}
       \AttributeTok{caption=}\StringTok{"The F{-}distributions for (left) 2 and 27 degrees of freedom and (right) 10 and 27 degrees of freedom"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{colour=}\StringTok{"darkblue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{dfs) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-5-1.pdf}}

Note that, whatever the degrees of freedom, \emph{F}-distributions are
examples of so-called probability density functions. The area beneath
them between any two values of \emph{F}-ratio is equal to the
probability of getting an \emph{F}-ratio in that range. Hence the total
area under the curves is equal to 1, since the \emph{F}-ratio must take
some value between zero and infinity, and the area under the tail to the
right of any given \emph{F}-ratio is the probability of getting an
\emph{F}-ratio bigger than that value.

Hence, the probability under the null hypothesis of getting an
\emph{F}-ratio as large or larger than the value we actually got is the
area to the right of this \emph{F}-ratio under the appropriate F
distribution. We often call this probability the \emph{p}-value. p for
probability. p-values are the the probability of getting data as extreme
(same \emph{F}-ratio,) or more extreme (bigger \emph{F}-ratio) as the
data you got you got if the null hypothesis were true.

If the fertilizers were very different, then the FMS would be much
greater than the EMS and the \emph{F}-ratio would be greater than one.
However it can be quite large even when there are no treatment
differences. So how do we decide when the size of the \emph{F}-ratio is
due to treatment rather than to chance?

Traditionally, we decide that it sufficiently larger than one to be due
to treatment differences if it would be this large or larger under the
null hypothesis only 5\% or less of the time. If we had inside knowledge
that the null hypothesis was in fact true then we would still get an
\emph{F}-ratio that large or larger 5\% of the time.

Our \emph{p}-value ie the probability that the \emph{F}-ratio would have
been as large as it is or larger, under the null hypothesis, represents
the strength of evidence against the null hypothesis. The smaller it is,
the stronger the evidence, and only when it is less than 0.05 do we
regard the evidence as strong enough to reject the null.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Fratio}\OtherTok{\textless{}{-}}\ControlFlowTok{function}\NormalTok{(p,k,st\_dev)\{}
\NormalTok{  n}\OtherTok{\textless{}{-}}\NormalTok{p}\SpecialCharTok{*}\NormalTok{k }\CommentTok{\# k plots, p replicates per plot}
\NormalTok{  plots}\OtherTok{\textless{}{-}}\FunctionTok{tibble}\NormalTok{(}\AttributeTok{plot=}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"a"}\NormalTok{,p),}\FunctionTok{rep}\NormalTok{(}\StringTok{"b"}\NormalTok{,p),}\FunctionTok{rep}\NormalTok{(}\StringTok{"c"}\NormalTok{,p)),}\AttributeTok{response=}\FunctionTok{rnorm}\NormalTok{(n,}\AttributeTok{mean=}\DecValTok{0}\NormalTok{,}\AttributeTok{sd=}\NormalTok{st\_dev))}
\NormalTok{  lm.mod}\OtherTok{\textless{}{-}}\FunctionTok{lm}\NormalTok{(response}\SpecialCharTok{\textasciitilde{}}\NormalTok{plot,}\AttributeTok{data=}\NormalTok{plots)}
  \FunctionTok{tidy}\NormalTok{(}\FunctionTok{anova}\NormalTok{(lm.mod))}\SpecialCharTok{$}\NormalTok{statistic[}\DecValTok{1}\NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{ANOVA example 1}\label{anova-example-1}

We will carry out the ANOVA analysis of the fertilizer data discussed on
the previous tab.

Our question is whether yield depends on fertilizer.

What is our null hypothesis?

Start a new notebook with these two code chunks to begin with:

\begin{verbatim}
```{r global-options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, warning=FALSE, message=FALSE,echo=FALSE)
```

```{r load packages, message=FALSE,warning=FALSE,echo=FALSE}
library(tidyverse)
library(here)
library(cowplot)
library(gridExtra)
library(ggfortify)
```
\end{verbatim}

Load the \texttt{fertilizer.csv} data into an object call `fertilizer

Is it tidy data? If not, tidy it.

Convert the FERTIL column to a factor, using this code:

\begin{verbatim}
```{r make_factor}
fertilizer <- fertilizer |>
  mutate(FERTIL=as.factor(FERTIL))
```
\end{verbatim}

Make a box plot of yield vs fertilizer, like the one on the previous
tab.

Now use the \texttt{lm()} function to create the anova model (There are
several ways to do this in R - this is just one)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fertil.model}\OtherTok{\textless{}{-}}\FunctionTok{lm}\NormalTok{(YIELD}\SpecialCharTok{\textasciitilde{}}\NormalTok{FERTIL,}\AttributeTok{data=}\NormalTok{fertilizer)}
\end{Highlighting}
\end{Shaded}

Now inspect the model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(fertil.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: YIELD
          Df Sum Sq Mean Sq F value   Pr(>F)   
FERTIL     2 10.823  5.4114  5.7024 0.008594 **
Residuals 27 25.622  0.9490                    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

So we find that we can reject the null hypothesis. There is thus
evidence that fertilizer does affect yield (ANOVA, df = 2,27, F=5.7,
p\textless{} 0.01)

What this test has not done so far is show us where the differences lie.
An ANOVA is a holistic test that tells you whether or not there is
evidence for a difference between at least one pair of groups being
compared. To identify which gruopd, if any, are differeny, we need to do
so-called post-hoc tests.

\section{ANOVA example 2}\label{anova-example-2}

An experiment was performed to compare four melon varieties. It was
designed so that each variety was grown in six plots, but two plots
growing variety 3 were accidentally destroyed.

We wish to find out if there is evidence for a difference in yield
between the varieties.

\subsection{Null hypothesis}\label{null-hypothesis}

What is the null hypothesis of this study?

The data are in the \texttt{melons.csv} dataset.

Write code chunks to

\subsection{Load data and inspect the
data}\label{load-data-and-inspect-the-data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath}\OtherTok{\textless{}{-}}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"melons.csv"}\NormalTok{)}
\NormalTok{melons}\OtherTok{\textless{}{-}}\FunctionTok{read\_csv}\NormalTok{(filepath)}
\FunctionTok{glimpse}\NormalTok{(melons)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 22
Columns: 2
$ YIELDM  <dbl> 25.12, 17.25, 26.42, 16.08, 22.15, 15.92, 40.25, 35.25, 31.98,~
$ VARIETY <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4,~
\end{verbatim}

\subsection{Prepare the data}\label{prepare-the-data}

Ensure that the VARIETY column is a factor

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons }\OtherTok{\textless{}{-}}\NormalTok{ melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{VARIETY=}\FunctionTok{as.factor}\NormalTok{(VARIETY))}
\end{Highlighting}
\end{Shaded}

\subsection{Plot the data}\label{plot-the-data-2}

Create a scatter plot of the yield.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{VARIETY,}\AttributeTok{y=}\NormalTok{YIELDM)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{limits=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{45}\NormalTok{),}\AttributeTok{breaks=}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{5}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Melon variety"}\NormalTok{, }\AttributeTok{y=}\StringTok{"Yield"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-12-1.pdf}}

\subsection{Summarise the data}\label{summarise-the-data-2}

Create a summary table that shows the mean yield for each variety.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(VARIETY) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{N=}\FunctionTok{n}\NormalTok{(),}
    \AttributeTok{Mean=}\FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(YIELDM),}\DecValTok{2}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 3
  VARIETY     N  Mean
  <fct>   <int> <dbl>
1 1           6  20.5
2 2           6  37.4
3 3           4  20.5
4 4           6  29.9
\end{verbatim}

\subsection{1-way ANOVA}\label{way-anova}

\subsubsection{Create the model}\label{create-the-model}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons.model}\OtherTok{\textless{}{-}}\FunctionTok{lm}\NormalTok{(YIELDM}\SpecialCharTok{\textasciitilde{}}\NormalTok{VARIETY,}\AttributeTok{data=}\NormalTok{melons)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Check the validity of the
model}\label{check-the-validity-of-the-model-1}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(melons.model,}\AttributeTok{smooth.colour=}\ConstantTok{NA}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-15-1.pdf}}

DO the data look as though they meet the criteria for an ANOVA? - the
variance of the residuals is roughly constant across all groups and the
qq-plot is fairly straight. We could confirm with a normality test if we
like. For example, we could use a Shapiro-Wilk test.

What is the null hypothesis of this test?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(melons.model}\SpecialCharTok{$}\NormalTok{residuals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  melons.model$residuals
W = 0.94567, p-value = 0.2586
\end{verbatim}

What do we conclude from this test?

\subsubsection{Inspect the model}\label{inspect-the-model}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(melons.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: YIELDM
          Df  Sum Sq Mean Sq F value    Pr(>F)    
VARIETY    3 1115.28  371.76  23.798 1.735e-06 ***
Residuals 18  281.19   15.62                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

What conclusions would you draw from the output of this model and the
table of mean yields for each variety?

\subsection{Confidence intervals of the
means}\label{confidence-intervals-of-the-means}

Let us find the 95\% confidence intervals for each mean

These we calculate as

\[
\text{Mean}\pm t_{\text{crit}}\text{SE}_{\text{mean}}
\] For a 95\% confidence interval and 18 degrees of freedom,
\(t_{\text{crit}}\) is 2.1, so we find that the intervals are:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t\_crit}\OtherTok{\textless{}{-}}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{,}\DecValTok{18}\NormalTok{)}
\NormalTok{melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(VARIETY) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{Mean=}\FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(YIELDM),}\DecValTok{2}\NormalTok{),}
    \AttributeTok{LB=}\FunctionTok{round}\NormalTok{(Mean}\SpecialCharTok{{-}}\NormalTok{t\_crit}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(}\FloatTok{15.6}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()),}\DecValTok{2}\NormalTok{),}
    \AttributeTok{UB=}\FunctionTok{round}\NormalTok{(Mean}\SpecialCharTok{+}\NormalTok{t\_crit}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(}\FloatTok{15.6}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()),}\DecValTok{2}\NormalTok{)}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 4
  VARIETY  Mean    LB    UB
  <fct>   <dbl> <dbl> <dbl>
1 1        20.5  17.1  23.9
2 2        37.4  34.0  40.8
3 3        20.5  16.3  24.6
4 4        29.9  26.5  33.3
\end{verbatim}

\section{ANOVA example 2 solution}\label{anova-example-2-solution}

An experiment was performed to compare four melon varieties. It was
designed so that each variety was grown in six plots, but two plots
growing variety 3 were accidentally destroyed.

We wish to find out if there is evidence for a difference in yield
between the varieties.

\subsection{Null hypothesis}\label{null-hypothesis-1}

What is the null hypothesis of this study?

The data are in the \texttt{melons.csv} dataset.

Write code chunks to

\subsection{Load data and inspect the
data}\label{load-data-and-inspect-the-data-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath}\OtherTok{\textless{}{-}}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{,}\StringTok{"melons.csv"}\NormalTok{)}
\NormalTok{melons}\OtherTok{\textless{}{-}}\FunctionTok{read\_csv}\NormalTok{(filepath)}
\FunctionTok{glimpse}\NormalTok{(melons)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 22
Columns: 2
$ YIELDM  <dbl> 25.12, 17.25, 26.42, 16.08, 22.15, 15.92, 40.25, 35.25, 31.98,~
$ VARIETY <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4,~
\end{verbatim}

\subsection{Prepare the data}\label{prepare-the-data-1}

Ensure that the VARIETY column is a factor

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons }\OtherTok{\textless{}{-}}\NormalTok{ melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{VARIETY=}\FunctionTok{as.factor}\NormalTok{(VARIETY))}
\end{Highlighting}
\end{Shaded}

\subsection{Plot the data}\label{plot-the-data-3}

Create a scatter plot of the yield.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{VARIETY,}\AttributeTok{y=}\NormalTok{YIELDM)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{limits=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{45}\NormalTok{),}\AttributeTok{breaks=}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{45}\NormalTok{,}\DecValTok{5}\NormalTok{))}\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Melon variety"}\NormalTok{, }\AttributeTok{y=}\StringTok{"Yield"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-21-1.pdf}}

\subsection{Summarise the data}\label{summarise-the-data-3}

Create a summary table that shows the mean yield for each variety.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(VARIETY) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{N=}\FunctionTok{n}\NormalTok{(),}
    \AttributeTok{Mean=}\FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(YIELDM),}\DecValTok{2}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 3
  VARIETY     N  Mean
  <fct>   <int> <dbl>
1 1           6  20.5
2 2           6  37.4
3 3           4  20.5
4 4           6  29.9
\end{verbatim}

\subsection{1-way ANOVA}\label{way-anova-1}

\subsubsection{Create the model}\label{create-the-model-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melons.model}\OtherTok{\textless{}{-}}\FunctionTok{lm}\NormalTok{(YIELDM}\SpecialCharTok{\textasciitilde{}}\NormalTok{VARIETY,}\AttributeTok{data=}\NormalTok{melons)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Check the validity of the
model}\label{check-the-validity-of-the-model-2}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(melons.model,}\AttributeTok{smooth.colour=}\ConstantTok{NA}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_how_it_works_files/figure-pdf/unnamed-chunk-24-1.pdf}}

The data look as though they meet the criteria for an ANOVA - the
variance of the residuals is roughly constant across all groups and the
qq-plot is fairly straight. We could confirm with a normality test if we
like. For example, we could use a Shapiro-Wilk test.

The null hypothesis of this test is that the residuals are drawn from a
population that is normally distributed

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{shapiro.test}\NormalTok{(melons.model}\SpecialCharTok{$}\NormalTok{residuals)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Shapiro-Wilk normality test

data:  melons.model$residuals
W = 0.94567, p-value = 0.2586
\end{verbatim}

Since \emph{p}\textgreater0.05 we conclude that there is no reason to
reject the null hypothesis that the residuals are normally disributed.

\subsubsection{Inspect the model}\label{inspect-the-model-1}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(melons.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: YIELDM
          Df  Sum Sq Mean Sq F value    Pr(>F)    
VARIETY    3 1115.28  371.76  23.798 1.735e-06 ***
Residuals 18  281.19   15.62                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(melons.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = YIELDM ~ VARIETY, data = melons)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.4233 -2.2781 -0.5933  2.6694  5.9300 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  20.4900     1.6136  12.699 2.02e-10 ***
VARIETY2     16.9133     2.2819   7.412 7.14e-07 ***
VARIETY3     -0.0275     2.5513  -0.011  0.99152    
VARIETY4      9.4067     2.2819   4.122  0.00064 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.952 on 18 degrees of freedom
Multiple R-squared:  0.7986,    Adjusted R-squared:  0.7651 
F-statistic:  23.8 on 3 and 18 DF,  p-value: 1.735e-06
\end{verbatim}

What conclusions would you draw from the output of this model and the
table of mean yields for each variety?

We see that the null hypothesis is rejected with a \emph{p}-value of
less than 0.001. We conclude that there are significant differences in
the mean yield of melons across the varieties. We estimate that variety
2 has the highest mean yield and varieties 1 and 3 have the lowest mean
yields.

The unexplained variance ie the error \emph{s} for each group is 15.6
with 18 degrees of freedom. So the standard error for each group is
\(\frac{s}{\sqrt{n}}\) where s=\(\sqrt{15.6}\) = 3.95 divided by the
number of elements in each group, giving us standard errors of 1.97 for
variety 3, and 1.61 for the other varieties.

\subsection{Confidence intervals of the
means}\label{confidence-intervals-of-the-means-1}

Let us find the 95\% confidence intervals for each mean

These we calculate as

\[
\text{Mean}\pm t_{\text{crit}}\text{SE}_{\text{mean}}
\] For a 95\% confidence interval and 18 degrees of freedom,
\(t_{\text{crit}}\) is 2.1, so we find that the intervals are:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t\_crit}\OtherTok{\textless{}{-}}\FunctionTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{,}\DecValTok{18}\NormalTok{)}
\NormalTok{melons }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(VARIETY) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{Mean=}\FunctionTok{round}\NormalTok{(}\FunctionTok{mean}\NormalTok{(YIELDM),}\DecValTok{2}\NormalTok{),}
    \AttributeTok{LB=}\FunctionTok{round}\NormalTok{(Mean}\SpecialCharTok{{-}}\NormalTok{t\_crit}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(}\FloatTok{15.6}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()),}\DecValTok{2}\NormalTok{),}
    \AttributeTok{UB=}\FunctionTok{round}\NormalTok{(Mean}\SpecialCharTok{+}\NormalTok{t\_crit}\SpecialCharTok{*}\FunctionTok{sqrt}\NormalTok{(}\FloatTok{15.6}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()),}\DecValTok{2}\NormalTok{)}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 4
  VARIETY  Mean    LB    UB
  <fct>   <dbl> <dbl> <dbl>
1 1        20.5  17.1  23.9
2 2        37.4  34.0  40.8
3 3        20.5  16.3  24.6
4 4        29.9  26.5  33.3
\end{verbatim}

\bookmarksetup{startatroot}

\chapter{One-way ANOVA}\label{one-way-anova}

\subsection{Introduction}\label{introduction-1}

In this exercise we will carry out a method of analysis known as ANOVA -
this is what is commonly used when you have one or more categorical
variables, such as species, sex and so on, and a numerical response
variable such as body mass and you want to know if there is a difference
in the response variable between when the levels of the factors take
different values.

A one-way ANOVA is used where where we have one categorical variable
with three or more level (you could also use it where there are just two
levels, but we use a t-test for that). For example if you want to see if
a captive bird species prefers red, green or blue food pellets, then the
factor would be be food colour, and three levels of that would be the
three colours.

A two-way ANOVA is used where we have two categorical variables, each of
which has at least two levels. (Even if both have two levels, we still
call it a two-way ANOVA. There is no such thing as a two-way t-test!).
So, sticking with the captive birds, if were interested in whether they
had a preference for colour (red, blue, green) and/or shape (round,
square) of food pellets, then we could use a two way ANOVA to investigae
the data, where the two factors or `ways' would be food colour and food
shape, with food colour having three levels (red, blue and green) and
food shape having two levels (round and square).

ANOVAs involving three ways or more (the horror, the horror!) are rarely
used since their interpretation is in practice difficult due to the
multiplicity of possible so-called `interaction' effects that commonly
arise, whereby the impact on the output of the levels of one factor
depend on the values of the levels of one or more other factors. Best
avoided!

ANOVAs, whatever their flavour (one way, two way, repeated measures,
ANCOVA etc) are examples of parametric tests. That is, they can only be
used if the data at least approximately meet certain requirements such
as equal variance across the data sets, normality of residuals etc. At
the very least, the data should be numerical and not ordinal. Hence
whenever we think of using an ANOVA we need to check that these
requirements are at least approximately met. If they are not, then we
may choose to turn to non-parametric alternatives.

A non-parametric alternative to a one-way ANOVAs is commonly used,
especially for studies that involve ordinal data such as Likert-type
outputs from surveys. It is called a Kruskal-Wallis test.

\section{Example: penguin data from the palmerpenguins
package}\label{example-penguin-data-from-the-palmerpenguins-package}

In the following, we show how a one-way ANOVA might be carried out on a
set of data on penguins, where we have a numerical output such as body
mass, and categorical variables such as species (three levels: Adelie,
Gentoo and Chinstrap) and sex (two levels: female and male). If we were
interested in whether there was a difference in the output across the
levels of species, then a one-way ANOVA might well be suitable.

\subsection{Load packages}\label{load-packages-2}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse) }\CommentTok{\# for data manipulation and plots, and more besides}
\FunctionTok{library}\NormalTok{(ggfortify) }\CommentTok{\# this is useful for diagnostics}
\FunctionTok{library}\NormalTok{(palmerpenguins) }\CommentTok{\# for the palmer penguin data}
\end{Highlighting}
\end{Shaded}

The \texttt{palmerpenguins} package comes with two in-built data sets on
penguins. The simplest of them is called \texttt{penguins} and is the
one we will use in this exercise:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glimpse}\NormalTok{(penguins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 344
Columns: 8
$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel~
$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse~
$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ~
$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ~
$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186~
$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ~
$ sex               <fct> male, female, female, NA, female, male, female, male~
$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007~
\end{verbatim}

\subsection{Remove observations with missing
values}\label{remove-observations-with-missing-values}

We can see from the first few values of the glimpse table that some rows
have missing values (NAs). We need to decide what to do with them. Here
we will simply remove them! Here is a way to remove any row that
contains missing values in one column or another:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_clean }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{drop\_na}\NormalTok{()}
\FunctionTok{glimpse}\NormalTok{(penguins\_clean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 333
Columns: 8
$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel~
$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse~
$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6~
$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2~
$ flipper_length_mm <int> 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18~
$ body_mass_g       <int> 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800~
$ sex               <fct> male, female, female, female, male, female, male, fe~
$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007~
\end{verbatim}

That has removed 11 rows of data, so we haven't lost too much
information.

\subsection{Summary - group by species and
sex}\label{summary---group-by-species-and-sex}

Here we use the famliar \texttt{group\_by()} and \texttt{summarise()}
construction to find the mean body mass for each combination of species
and sex. We also calculate the standard error of those means and the
number of individuals in each group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_clean }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(species, sex) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{(), }\AttributeTok{mean\_bm =} \FunctionTok{mean}\NormalTok{(body\_mass\_g), }\AttributeTok{se\_bm =} \FunctionTok{sd}\NormalTok{(body\_mass\_g)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()) ) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ungroup}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 5
  species   sex        n mean_bm se_bm
  <fct>     <fct>  <int>   <dbl> <dbl>
1 Adelie    female    73   3369.  31.5
2 Adelie    male      73   4043.  40.6
3 Chinstrap female    34   3527.  48.9
4 Chinstrap male      34   3939.  62.1
5 Gentoo    female    58   4680.  37.0
6 Gentoo    male      61   5485.  40.1
\end{verbatim}

Looking at this table, does it look as though females and males have
different weights? If so, which is heavier? Is this true for all
species? Do the different species weigh the same?

\subsection{Plot the data}\label{plot-the-data-4}

To get further insight into these questions, we can plot the data. Here
we will do a box plot

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_clean  }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{species, }\AttributeTok{y =}\NormalTok{ body\_mass\_g, }\AttributeTok{fill =}\NormalTok{ sex)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Body mass (g)"}\NormalTok{,}
       \AttributeTok{fill =} \StringTok{"Sex"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_brewer}\NormalTok{(}\AttributeTok{palette =} \StringTok{"Set1"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position=} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{,}\FloatTok{0.8}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_one_way_files/figure-pdf/unnamed-chunk-5-1.pdf}}

What do you think now about size differences between species and the two
sexes?

There is a lot going on here, so let's approach this more simply to
begin with and concentrate solely on the difference between the females
of the species.

\subsection{One-way ANOVA}\label{one-way-anova-1}

Let's ask the question: do the body weights differ between females of
the different species?

There is just one \textbf{factor} here, species, and it has more than
two \textbf{levels} - the three different species - and the reponse
variable is numeric, so it is highly likely that the appropriate test to
answer this question is a one-way ANOVA. `One way' because there is one
factor, and `ANOVA' (instead of t-test) because there are more than two
levels.

\subsubsection{Null hypothesis}\label{null-hypothesis-2}

Pretty much all of the commonly used statistics tests are asking the
question: what is the probability that you would have got this data, or
more extreme data, if the null hypothesis were true? Their job is to
calculate that probability, which is called a p-value. There is a lot
more besides, but what this means is that in carrying out any of these
tests we at least need to have a hypothesis in mind and its
corresponding null hypothesis. The null, remember, is typically the
`nothing going on', there is no effect, no difference scenario.

So in this case, a suitable null hypothesis would be that there is no
difference in body mass between the females of the different penguin
species.

To see if there is evidence from the data to reject this null, we will
follow a sequence of steps that will be common to many analyses:

\begin{itemize}
\tightlist
\item
  get the data
\item
  clean/prepare the data
\item
  summarise the data
\item
  plot the data
\item
  construct the model using whatever test is appropriate, in this case a
  one-way ANOVA
\item
  check whether the model is valid
\item
  inspect the model output
\item
  reject or fail to reject the null hypothesis
\item
  if we reject the null, carry out post-hoc tests
\item
  (maybe) simplify the model and redo the analysis
\end{itemize}

For the penguin data, getting it was easy as it came with the
\texttt{palmerpenguins} package.

To prepare the data, we start with the full data set and narrow it down
to just the females, using the \texttt{filter()} function, and again
make sure there are no lines with missing values, using
\texttt{drop\_na()}. We save this cleaned data set in an object called
\texttt{females}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{filter}\NormalTok{(sex }\SpecialCharTok{==} \StringTok{"female"}\NormalTok{) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{drop\_na}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Then let's summarise these values to find the number of individuals, the
mean body mass for each species, and the standard errors of those means:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(species) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{(), }\AttributeTok{mean.mass\_f =} \FunctionTok{mean}\NormalTok{(body\_mass\_g), }\AttributeTok{se.mass\_f =} \FunctionTok{sd}\NormalTok{(body\_mass\_g)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{()))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 3 x 4
  species       n mean.mass_f se.mass_f
  <fct>     <int>       <dbl>     <dbl>
1 Adelie       73       3369.      31.5
2 Chinstrap    34       3527.      48.9
3 Gentoo       58       4680.      37.0
\end{verbatim}

We should inspect this summary table and see what we already think about
whether the null hypothesis is likely to be rejected, or not.

Now let's plot them, using a box plot (but choose your favourite plot
type):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females  }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{species, }\AttributeTok{y =}\NormalTok{ body\_mass\_g)) }\SpecialCharTok{+}
  \FunctionTok{geom\_boxplot}\NormalTok{(}\AttributeTok{fill =} \StringTok{"\#9ebcda"}\NormalTok{) }\SpecialCharTok{+}  \CommentTok{\# pick your favourite colour from https://colorbrewer2.org/}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Body mass (g)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_one_way_files/figure-pdf/unnamed-chunk-8-1.pdf}}

From the summary table and the plot, what do you think? Do the masses
differ between the species?

\subsubsection{The actual ANOVA}\label{the-actual-anova}

You probably have a good idea what the answer is, as to our question,
but now we will move on to the actual statistics test, in this case a
one-way ANOVA.

An ANOVA is one variant of a range of anlysis techniques known as
`linear models'. If you were to look under the hood, you would see that
mathematics behind it is exactly the same as that behind linear
regression, which we use when we have a continuous explanatory variable
and where we fit straight lines onto a scatter plot. Thus it is no
surprise that the ANOVA is carried out in R in exactly the same way as
linear regression would be:

First, we use the \texttt{lm()} function to construct a linear model of
the data:

\subsubsection{Construct the model}\label{construct-the-model}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females.model }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(body\_mass\_g }\SpecialCharTok{\textasciitilde{}}\NormalTok{ species, }\AttributeTok{data =}\NormalTok{ females)}
\end{Highlighting}
\end{Shaded}

Here the \texttt{lm()} function has done all the maths of the ANOVA, and
we have saved the results of that in an object called
\texttt{females.model}. Note the use of the formula
\texttt{body\_mass\_g\ \textasciitilde{}\ species} as the first argument
of the \texttt{lm()} function, where this means `body mass as a function
of species'.

\subsubsection{Is the model valid?}\label{is-the-model-valid}

All linear models are only valid if the data meet a number of criteria.
Chief among these for an ANOVA is that the spread of the data should be
roughly the same in each subset, and that the data within each subset
should be normally distributed around their respective mean values. Only
if these conditions are at least approximately met can we just go on and
trust the output of the model. If they are not, we need to transform the
data in some way until they are, or use a different test. A commonly
used non-parametric alternative to the one-way ANOVA is the
Kruskal-Wallis test.

There are various ways we can find out whether these conditions are met.
A useful one is to do it graphically, and a useful way to do that is to
use the \texttt{autoplot()} function from the \texttt{ggfortify}
package. Let's do it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(females.model) }\SpecialCharTok{+} \FunctionTok{theme\_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_one_way_files/figure-pdf/unnamed-chunk-10-1.pdf}}

All four graphs presented here tell us something about the validity or
not of our model. Here we will just focus on the upper two:

\begin{itemize}
\item
  top-left: this shows the spread of the residual masses (diference
  between an individual's mass and the mean mass for its species) for
  each species. We see that the spread of these values is aout the same
  for all three species. Check!
\item
  top-right: this is a \texttt{quantile-quantile} plot, often referred
  to as a qq-plot. This compares the distribution of the residuals for
  each species with a normal distribution. If the residuals are normally
  distributed, we will get a straight line. If not, we won't. To get an
  idea of what qq-plots, histograms and box-plots look like for data
  that definitely are not normally distriuted, see
  \href{https://rpubs.com/mbh038/725314}{this useful summary}. In our
  case, there is a hint of a curve, but this qq-plot is really a pretty
  good approximation to linear for a real data set. No such data is ever
  perfectly normally distributed, so the best we are looking for, in
  practice is something approximating a straight line, often with some
  raggedness at either end. So, check again!
\end{itemize}

On both counts, we are good to go: we can reasonably trust the output of
the ANOVA.

So what is this output? We find this in three steps

\subsubsection{The overall picture}\label{the-overall-picture-1}

First, we use the \texttt{anova()} function

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(females.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: body_mass_g
           Df   Sum Sq  Mean Sq F value    Pr(>F)    
species     2 60350016 30175008  393.25 < 2.2e-16 ***
Residuals 162 12430757    76733                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

This gives us an overview of all the data and asks the question: how
likely is it that you would have got your data if species made no
difference to body mass. There are three things to note:

\begin{itemize}
\item
  the test statistic, here called an F-value. This is a number
  calculated from the data. Roughly speaking, it is the ratio of the
  spread of values (aka variance) between the subgroups to that within
  the subgroups If the validity criteria for the test have been met by
  the data, then this has a known distribution. The bigger the F-value,
  the more likely it is that the null will be rejected.
\item
  the \texttt{degrees\ of\ freedom}, here denoted as Df and listed in
  the first column. These are the number of independent pieces of
  information in the data, which here means, how many species and how
  many penguins.
\item
  the p-value, which is the probability of getting an F value as big as
  or bigger than the one actually found, if the null hypothesis were
  true. This is is the number listed at the right as Pr(\textgreater F).
\end{itemize}

The F value here is huge and the p-value is tiny, so tiny that it is
essentially zero. Thus we can confidently reject the null hypothesis and
assert that there is evidence from the data that body mass of females
differs between at least one pair of species. Which two, or between all
of them, and by how much we don't yet know. This first step just tells
us whether there is some difference somewhere. If there were no evidence
of any difference we would stop the analysis right here.

But there is a difference in this case, so we continue.

\subsubsection{The detailed picture}\label{the-detailed-picture}

We use the \texttt{summary()} function for this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(females.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = body_mass_g ~ species, data = females)

Residuals:
    Min      1Q  Median      3Q     Max 
-827.21 -193.84   20.26  181.16  622.79 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)       3368.84      32.42 103.908  < 2e-16 ***
speciesChinstrap   158.37      57.52   2.754  0.00657 ** 
speciesGentoo     1310.91      48.72  26.904  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 277 on 162 degrees of freedom
Multiple R-squared:  0.8292,    Adjusted R-squared:  0.8271 
F-statistic: 393.2 on 2 and 162 DF,  p-value: < 2.2e-16
\end{verbatim}

There is a lot in ths output, so let's just consider the coefficient
table, to begin with. Focus first on the top left value, in the Estimate
column. This tells us the mean body mass of the reference or `Intercept'
species. In this case that is `Adelie', purely because `Adelie' comes
alphabetically before the other two species names, `Chinstrap' and
`Gentoo'. By default, R will always order levels of a factor
alpabetically. This is often a nuisance, and with many data sets we have
to tell R to reorder the levels the way we want them, but here the order
is OK.

So, the mean mass of female Adelie penguins in our sample is 3368 g.
Cross check that with your initial summary table and the box plot. What
about the other two species? Here's the thing: for all rows except the
first in the Estimate column we are not given the absolute value but the
difference between their respective mean values and the reference mean
in the first, `Intercept' row.

Thus, we are being told that Chinstrap females in the sample have a mean
body mass that is 158.37 g heavier than that of Adelie females, so that
their mean body mass is 3368.84 + 158.37 = 3527.27g. Again, cross check
that with your summary table and the box plot. Is it right?

What about Gentoo females? Were they heavier than Adelie penguins, and
if so, by how much? What was their mean body mass.

Why doesn't \texttt{summary()} just tell us the actual body masses
instead for all three species instead of doing it in this round about
way? The reason is that ANOVA is concerned with detecting evidence of
\emph{difference}. This is why we are being told what the differences
are between each of the levels and one reference level, which here is
Adelie.

Are those differences signifcant? We use the right hand p-value column
for that. Look in the rows for Chinstrap and Gentoo penguins. In both
cases the p values are much less than 0.05. This is telling us that in
both cases there is evidence that females of these species are
significantly heavier than those of the Adelie species.

Note that we have only been told, so far, about the magnitude and
significance of differences between all the levels and the reference
level. We are not told the significance of any difference between any
other pair of levels. So in particular, the ANOVA does not tell us
whether there is a significant difference between the masses of
Chinstrap and Gentoo females (although we may have a good idea what the
answer is, from our initial summary table and plot).

To find the answer to that, we do post-hoc tests:

\subsubsection{Post hoc tsts.}\label{post-hoc-tsts.}

A final step of most ANOVA analyses is to perform so-called post-hoc
(`after the fact') tests which make pairwise comparisons between all
possible pairs of levels, tell us what the differences are between those
pairs and whether the differences are significant. Whatever method is
used for this, it needs to take account of the danger of making Type-one
errors that arises when multiple pair-wise tests are done.

A commonly used function for doing this is Tukey's Honest Signficant
Difference: \texttt{TukeyHSD()}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{TukeyHSD}\NormalTok{(}\FunctionTok{aov}\NormalTok{(body\_mass\_g }\SpecialCharTok{\textasciitilde{}}\NormalTok{ species, }\AttributeTok{data =}\NormalTok{ females))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
  Tukey multiple comparisons of means
    95% family-wise confidence level

Fit: aov(formula = body_mass_g ~ species, data = females)

$species
                      diff        lwr       upr     p adj
Chinstrap-Adelie  158.3703   22.32078  294.4197 0.0179471
Gentoo-Adelie    1310.9058 1195.64908 1426.1624 0.0000000
Gentoo-Chinstrap 1152.5355 1011.00620 1294.0648 0.0000000
\end{verbatim}

In each row of the output we see the difference between the mean masses
of the females of two species, where a positive value tells us that the
first named species has the heavier mass. So, we see that Gentoo females
in the sample were on average 1310.9 g heavier than Adelie females.

Compare these differences with your initial summary table and your box
plot. Do they agree? They should!

The right-hand column `p adj' tells us whether these difference are
significant. If the p values are less than 0.05 then they are, at the
5\% significance level. In this case they all are. The p values are so
tiny for the differences between Gentoo and the other two species that
that they are reported as zero.

\subsection{Reporting the Result.}\label{reporting-the-result.}

We try to use plain English to report our results, while still telling
the reader what test was used and the key outputs of the test. Try to
report the name of the test, the test statistic, the degrees of freedom,
and the p-value. if. the p-value is really small then it is common to
report it as p\textless0.01, or p\textless0.001. No one cares if it is a
billionth or a squillionth. It just matters that is t is \emph{really}
small, if that is the case. If it is only just below 0.05, then I would
report it in full, so we might write p = 0.018. If p \textgreater{} 0.05
then conventiallly it is not reported, except to say p \textgreater{}
0.05.

In this case, we might say something like:

\emph{We find evidence that there is a difference between the body
masses of females of the penguin species Adelie, Chinstrap and Gentoo
(ANOVA, df = 2, 162, F = 393, p \textless{} 0.001). In particular Gentoo
are more than 1 kg heavier than the other two (p\textless{} 0.001) while
the difference between Chinstrap and Adelie is smaller, at 158 g, but
still significant (p = 0.018).}

\bookmarksetup{startatroot}

\chapter{Two-way ANOVA with model
simplification}\label{two-way-anova-with-model-simplification}

This exercise sheet is heavily indebted to Michael Crawley's
\emph{Statistics: An introduction using R}, 2nd Ed, Wiley. Published in
2015 this emphasises statistics over R (in fact, much of the R he
presents is written prior to the advent of the \texttt{tidyverse}
dialect which we use here, and so may seem terse if that is what you are
used to). It is very useful and is at a higher level than Beckerman,
Childs and Petchey's \emph{Getting Started in R: An introduction for
biologists}, 2nd Ed. OUP published in 2017. Their book also includes a
simpler version of the example explored here.

\subsection{Factorial experiments and model
simplification}\label{factorial-experiments-and-model-simplification}

The best model is the one that adequately explains the data with fewest
parameters. This means with the smallest possible number of degrees of
freedom.

If we have a very large number of parameters, a model can fit any data
set but be of limited use in generalising beyond it (we will have
overfitted the data). If we have too few we will not explain much of the
variance of the data. A balance must be struck. Hence we want the
\emph{minimal} \emph{adequate} model.

As Einstein almost said, a model should be as simple as possible, but no
simpler. (Not to be outdone, the British statistician George Box also
had a pithy saying about models: ``All models are wrong, but some are
useful''.)

A \textbf{factorial} experiment has two or more factors, each with two
or more levels, plus replication for each combination of factor levels.
This means that we can investigate whether statistical interactions
occur in which the effect of one factor depends on the value of another
factor.

We take an example from a farm-trial of animal diets. There are two
factors: \texttt{diet} and \texttt{supplement}. \texttt{diet} is a
factor with three levels: \texttt{barley}, \texttt{oats} and
\texttt{wheat}, where \texttt{barley} is the diet that has always been
used and the other two are potential alternatives. The purpose of the
trial is to see if their use makes a difference to growth outcomes.
\texttt{supplement} is a factor with four levels: \texttt{control},
\texttt{agrimore}, \texttt{supergain} and \texttt{supersupp}, where
\texttt{control} could mean the absence of any supplement or the
supplement used up to now, whose effects we are hoping to improve upon
through use of one of the others included in the trial. The response
variable \texttt{gain} is weight gain after 6 weeks. There were 48
individual cows in total with 4 for each combination of \texttt{diet}
and \texttt{supplement}. Having the same number of replicates for each
combination of levels means that this is a \emph{balanced} design.

\includegraphics[width=4.03in,height=\textheight,keepaspectratio]{figures/factorial_design.png}

\subsection{Files needed}\label{files-needed}

\begin{itemize}
\item
  To be put in the Project/scripts folder:

  \begin{itemize}
  \tightlist
  \item
    \texttt{ANOVA\_two\_way\_with\_model\_simplification.html} (this
    worksheet)
  \item
    \texttt{ANOVA\_two\_way\_template.Rmd} (the script where you fill in
    the code chunks)
  \end{itemize}
\item
  To be put in Project/data folder

  \begin{itemize}
  \tightlist
  \item
    \texttt{growth.csv}
  \end{itemize}
\end{itemize}

In the following, we present the code you need to analyse this data
together with explanatory text. Read the text closely so that you
understand what each chunk of code is intended to do. In the
accompanying template file, fill in the code as you go in the empty
chunks, using this worksheet as a guide. As you complete each line of
code, run it using Ctrl-Enter or Cmd-Enter on a Mac. Alternatively, wait
until you have completed the code for a chunk then run the whole chunk
in one go by pressing the little green arrow at the top right of the
chunk. Whichever way you choose, you are encouraged to view the code
presented here as \emph{one} way to do the analysis. Feel free to hack
away at it and change things, to try different approaches and see what
happens. That way you will learn. You may also wish to add your own text
between the chunks.

\subsection{Open your Project}\label{open-your-project}

You should be working within a folder that you have designated as what
RStudio calls a `Project'. If you are, the name of your Project will
appear at the top right of the RStudio window. Inside your Project
folder you should have a \texttt{scripts} folder for scripts like the
one you are working from, and a \texttt{data} folder for all the data
files. You will also see, at the top level of the Project, the
\texttt{.RProj} file. You can see all this in the Files pane,
bottom-right.

\subsection{Load packages}\label{load-packages-3}

I normally load all the packages in the chunk below into every script.
The most important is the \texttt{tidyverse} package which is a goody
bag containing several other packages. Loading this saves you from
having to load each of those individually. The most often used among
these is \texttt{readr} for reading and writing data from/to files,
\texttt{dplyr} for data manipulation, and \texttt{ggplot2} for plotting.
Others will be used from time to time, and we don't really need to be
aware of that when it happens or to worry about it, so long as
\texttt{tidyverse} has been loaded.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)  }\CommentTok{\# for data manipulation and plotting, and much else besides}
\FunctionTok{library}\NormalTok{(here) }\CommentTok{\# for finding our data easily}
\FunctionTok{library}\NormalTok{(cowplot) }\CommentTok{\# gives a nice theme for plots}
\FunctionTok{library}\NormalTok{(ggfortify) }\CommentTok{\# for diagnostic plots}
\end{Highlighting}
\end{Shaded}

\subsection{Read in the data}\label{read-in-the-data}

The \texttt{growth.csv} data file needs to be in the \texttt{data}
folder within the Project folder.

In this chunk we read the \texttt{growth.csv} data into an R object to
which we give the name \texttt{weights}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{filepath }\OtherTok{\textless{}{-}} \FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"growth.csv"}\NormalTok{)}
\NormalTok{weights }\OtherTok{\textless{}{-}} \FunctionTok{read\_csv}\NormalTok{(filepath) }\CommentTok{\# this function is from the readr package, part of tidyverse}
\FunctionTok{glimpse}\NormalTok{(weights)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 48
Columns: 3
$ supplement <chr> "supergain", "supergain", "supergain", "supergain", "contro~
$ diet       <chr> "wheat", "wheat", "wheat", "wheat", "wheat", "wheat", "whea~
$ gain       <dbl> 17.37125, 16.81489, 18.08184, 15.78175, 17.70656, 18.22717,~
\end{verbatim}

You see from the output of the \texttt{glimpse()} function that
\texttt{weights} has three columns and 48 rows. Two columns are of data
type \texttt{\textless{}chr\textgreater{}} which is R-speak for text,
and the other is data type \texttt{\textless{}dbl\textgreater{}} which
is R-speak for numerical data with a decimal point.

\subsection{Make R recognise the categorical variables as factors, and
order the
levels.}\label{make-r-recognise-the-categorical-variables-as-factors-and-order-the-levels.}

At the moment, the contents within the variables \texttt{supplement} and
\texttt{diet} are not being recognised as levels of factors. R is just
thinking of them as text (or \texttt{\textless{}chr\textgreater{}} in
R-speak), as we can see from the output of the \texttt{glimpse()}
function in the chunk above. Let us fix that, as it will be useful for
them to be recognized for what they are so that we can order the levels
in a way that makes sense for our context, our plots and our analysis.

Sometimes levels of a factor have a natural order, such as \emph{Low},
\emph{Mid} and \emph{High} as the levels of the factor \emph{Tidal Zone}
and sometimes they do not, for example \emph{Apples}, \emph{Oranges} and
\emph{Pears} as levels of the factor \emph{Fruit}. Here, in the case of
both our factors, we only wish to impose order among the levels in so
far as we would like what we regard as the control or reference level to
be first. By default, R puts the levels of a factor in alphabetical
order. This is the order in which the boxes of a box plot would be
displayed, reading left to right. In an ANOVA setting it means that
differences of outcome (in this case, weight gain of the cows) are later
calculated for each combination of levels with respect to the outcome
for the combination of levels that are alphabetically first, in this
case \texttt{barley} for \texttt{diet} and \texttt{agrimore} for
\texttt{supplement}. In both the box-plot and the ANOVA output case this
default ordering is not necessarily what we want. Normally, we want what
we regard as the control levels to be the reference level and in this
case that means \texttt{barley} for \texttt{diet} and \texttt{control}
for \texttt{supplement}.

To ensure that a variable is regarded as a factor, and then to get its
levels in the order we would like, we use the \texttt{factor()}
function.

In the following chunk, \texttt{factor()} is used to designate both the
\texttt{supplement} and \texttt{diet} columns of the data set as
factors, and the level order of each is specified, with \texttt{control}
coming first for \texttt{supplement} and \texttt{barley} coming first
for \texttt{diet}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This line of code designates the supplement and diet columns of weights as factors, orders the levels of these factors as required and saves the result under the original name.}
\NormalTok{weights }\OtherTok{\textless{}{-}}\NormalTok{ weights }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{supplement =} \FunctionTok{factor}\NormalTok{(supplement, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"control"}\NormalTok{,}\StringTok{"agrimore"}\NormalTok{, }\StringTok{"supergain"}\NormalTok{, }\StringTok{"supersupp"}\NormalTok{))) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{diet =} \FunctionTok{factor}\NormalTok{(diet, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"barley"}\NormalTok{, }\StringTok{"oats"}\NormalTok{, }\StringTok{"wheat"}\NormalTok{)))}

\CommentTok{\# check that this worked}
\FunctionTok{glimpse}\NormalTok{(weights)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 48
Columns: 3
$ supplement <fct> supergain, supergain, supergain, supergain, control, contro~
$ diet       <fct> wheat, wheat, wheat, wheat, wheat, wheat, wheat, wheat, whe~
$ gain       <dbl> 17.37125, 16.81489, 18.08184, 15.78175, 17.70656, 18.22717,~
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# check the level order of each factor {-} does the \textquotesingle{}reference\textquotesingle{} level come first?}
\FunctionTok{levels}\NormalTok{(weights}\SpecialCharTok{$}\NormalTok{supplement)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "control"   "agrimore"  "supergain" "supersupp"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{levels}\NormalTok{(weights}\SpecialCharTok{$}\NormalTok{diet)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "barley" "oats"   "wheat" 
\end{verbatim}

Do you see how the variable types of the \texttt{supplement} and
\texttt{diet} columns have been changed to
\texttt{\textless{}fct\textgreater{}}? It worked!

To get \texttt{control} to be the reference level of \texttt{supplement}
we needed to force the issue in this way. If we hadn't then
\texttt{agrimore} would have been regarded as such, since it is
alphabetically the first among the levels of \texttt{supplement}. We
didn't need to do this for \texttt{diet}, since the stipulated ordering
of the levels is just the alphabetical order and so we would have had
that by default anyway. Sometimes, though, it doesn't hurt to throw in a
little redundancy for the sake of clarity.

So, now we have \texttt{control} as the reference level for
\texttt{supplement} and \texttt{barley} as the reference level for
\texttt{diet}. Now we can see more easily in our analysis what
difference is made to weight gain when we change diet or supplement or
both from a `business as usual' combination of a \texttt{barley}diet and
the \texttt{control} supplement.

\subsection{Summarise the data}\label{summarise-the-data-4}

Our question is a difference question: is there evidence from the data
that using this or that diet in combination with this or that supplement
makes a difference to growth? For an answer to this we will end up doing
a 2-way ANOVA including the possibility of an interaction, then, as we
will see, a simpler ANOVA that ignores the possibility of the
interaction. All well and good, but before we go to those lengths, we do
something more basic: we calculate the mean and standard error of the
mean for each of the twelve combinations of diet and supplement.

There isn't a function in base R with which we can calculate standard
error of the mean directly, but we can do so knowing the standard
deviation of the sample \(\text{SD}\) (using \texttt{sd()}) and the
sample size \(n\) (using \texttt{n()}) using this formula:

\[ \text{SE}=\frac{SD}{\sqrt{n}}\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# we use the group\_by() and summarise() functions from dplyr (the package within tidyverse for data manipulation)}
\NormalTok{growth\_summary }\OtherTok{\textless{}{-}}\NormalTok{ weights }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(diet, supplement) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_gain =} \FunctionTok{mean}\NormalTok{(gain), }\AttributeTok{se\_gain =} \FunctionTok{sd}\NormalTok{(gain)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{())) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ungroup}\NormalTok{()}

\CommentTok{\# if we type the name of an object, it gets printed out for us}
\NormalTok{growth\_summary }\SpecialCharTok{|\textgreater{}} \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}
\centering
\begin{tabular}[t]{l|l|r|r}
\hline
diet & supplement & mean\_gain & se\_gain\\
\hline
barley & control & 23.29665 & 0.7032491\\
\hline
barley & agrimore & 26.34848 & 0.9187479\\
\hline
barley & supergain & 22.46612 & 0.7710644\\
\hline
barley & supersupp & 25.57530 & 1.0599015\\
\hline
oats & control & 20.49366 & 0.5056319\\
\hline
oats & agrimore & 23.29838 & 0.6131592\\
\hline
oats & supergain & 19.66300 & 0.3489388\\
\hline
oats & supersupp & 21.86023 & 0.4132292\\
\hline
wheat & control & 17.40552 & 0.4604420\\
\hline
wheat & agrimore & 19.63907 & 0.7099260\\
\hline
wheat & supergain & 17.01243 & 0.4852821\\
\hline
wheat & supersupp & 19.66834 & 0.4746443\\
\hline
\end{tabular}
\end{table}

Note the ordering of the diet and supplement levels in their respective
columns: just what we have imposed!

\subsection{Plot the data}\label{plot-the-data-5}

The next step, as so often before we launch into actual statistics, is
to plot the data in a way that sheds light on the question we have.
Here, we can use the use the means and standard errors of the mean that
we have just calculated to produce a useful kind of line plot that in
this context is often referred to as an interaction plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{growth\_summary }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ supplement,}\AttributeTok{y =}\NormalTok{ mean\_gain, }\AttributeTok{colour =}\NormalTok{ diet, }\AttributeTok{group =}\NormalTok{ diet)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean\_gain }\SpecialCharTok{{-}}\NormalTok{ se\_gain, }\AttributeTok{ymax =}\NormalTok{ mean\_gain }\SpecialCharTok{+}\NormalTok{ se\_gain), }\AttributeTok{width =} \FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Supplement"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Mean weight gain"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_brewer}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_two_way_with_model_simplification_files/figure-pdf/interaction plot one-1.pdf}}

Note that on this plot the error bars are standard errors of the mean.
Any caption to a figure that contains error bars should explain what
those error bars mean. In particular, it should say whether they are
standard deviations of the sample, standard errors of the mean or
confidence intervals. These are all different from each other. A good
explanation of the difference is given by {[}Cummings et al{]}{[}1{]}.
(2007).

This interaction plot is useful in that we see that both diet and
supplement have an effect on growth and that the effect of one is
altered little by the value of the other, the result of which is that
the lines are more or less parallel. This suggests that we have
\emph{main effects} of both diet and supplement, but little or no
\emph{interaction} between them.

\subsubsection{Questions}\label{questions}

What could the line plot look like if:

\begin{itemize}
\item
  There were no main effect of both diet and supplement, and no
  interaction
\item
  There were a main effect of diet, no main effect of supplement and no
  interaction?
\item
  There were no main effect of diet, a main effect of supplement and no
  interaction?
\item
  There were main effects of both and an interaction between them?
\end{itemize}

The plots tell you a great deal about what main effects and/or
interactions there may be.

\subsection{ANOVA}\label{anova}

Now for the actual statistical test. We will conduct a two-way ANOVA,
which will look to see if there is evidence that either diet or
supplement or both affect growth rate (the so-called main effects), and
if the effect of one depends on the nature of the other (the so-called
interaction).

The null hypothesis is that neither has any main effect and that there
is no interaction.

Now we can use either of the functions \texttt{aov()} or \texttt{lm()}
to carry out a factorial ANOVA (the choice affects only whether we get
an ANOVA table or a list of parameter estimates as the default output
from \texttt{summary()}.). Here, we will use \texttt{lm()}, partly
because we would also use it for one-way ANOVAs and linear regression,
and to do so here reminds of the common mathematical machinery that
underlies all these methods.

We estimate parameters for the main effects of each level of diet and
each level of supplement, plus terms for the interaction between diet
and supplement.

The interaction degrees of freedom are the product of those for diet and
supplement ie (3-1) x (4-1) = 6.

The model is:

\texttt{gain\ \textasciitilde{}\ diet\ +\ supplement\ +\ diet:supplement}

which can be written more simply using the asterisk notation as:

\texttt{gain\ \textasciitilde{}\ diet\ *\ supplement}

\subsubsection{Construct the model}\label{construct-the-model-1}

First we construct the model using \texttt{lm()} and store the outputs
of all the maths that `\texttt{lm()} does in an object called
\texttt{model0}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model0 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(gain }\SpecialCharTok{\textasciitilde{}}\NormalTok{ diet }\SpecialCharTok{*}\NormalTok{ supplement, }\AttributeTok{data =}\NormalTok{ weights)}
\end{Highlighting}
\end{Shaded}

\subsubsection{Do we reject the null
hypothesis?}\label{do-we-reject-the-null-hypothesis}

To get an overall picture, we first use \texttt{anova()} to see if there
is evidence to reject the null

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(model0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Response: gain
                Df  Sum Sq Mean Sq F value    Pr(>F)    
diet             2 287.171 143.586 83.5201 2.999e-14 ***
supplement       3  91.881  30.627 17.8150 2.952e-07 ***
diet:supplement  6   3.406   0.568  0.3302    0.9166    
Residuals       36  61.890   1.719                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

The ANOVA table shows that there a main effect of both \texttt{diet} and
\texttt{supplement} (\emph{p}\textless0.001 in both cases), but that
there is no hint of an interaction between \texttt{diet} and
\texttt{supplement} (\emph{p} = 0.917). Does that tally with what you
see in the interaction plot? Clearly therefore, the effects of
\texttt{diet} and \texttt{supplement} are merely additive (ie whichever
level of one you have it does not affect the impact on growth of
whichever level of the other you choose).

The ANOVA table does not show us effect sizes or allow us to work out
which if any of the levels of the two factors are significantly
different. For this, \texttt{summary()} is more useful:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = gain ~ diet * supplement, data = weights)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.48756 -1.00368 -0.07452  1.03496  2.68069 

Coefficients:
                                Estimate Std. Error t value Pr(>|t|)    
(Intercept)                   23.2966499  0.6555863  35.536  < 2e-16 ***
dietoats                      -2.8029851  0.9271390  -3.023  0.00459 ** 
dietwheat                     -5.8911317  0.9271390  -6.354 2.34e-07 ***
supplementagrimore             3.0518277  0.9271390   3.292  0.00224 ** 
supplementsupergain           -0.8305263  0.9271390  -0.896  0.37631    
supplementsupersupp            2.2786527  0.9271390   2.458  0.01893 *  
dietoats:supplementagrimore   -0.2471088  1.3111726  -0.188  0.85157    
dietwheat:supplementagrimore  -0.8182729  1.3111726  -0.624  0.53651    
dietoats:supplementsupergain  -0.0001351  1.3111726   0.000  0.99992    
dietwheat:supplementsupergain  0.4374395  1.3111726   0.334  0.74060    
dietoats:supplementsupersupp  -0.9120830  1.3111726  -0.696  0.49113    
dietwheat:supplementsupersupp -0.0158299  1.3111726  -0.012  0.99043    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.311 on 36 degrees of freedom
Multiple R-squared:  0.8607,    Adjusted R-squared:  0.8182 
F-statistic: 20.22 on 11 and 36 DF,  p-value: 3.295e-12
\end{verbatim}

This is a complex model as there are 12 estimated parameters: 6 main
effects and 6 interactions. Notice that although the `controls' for diet
and supplement (\texttt{barley} and \texttt{control}) do not appear to
be in the table, they are there really, in the first row.

The value 23.30 kg in the first row of the Estimate column on the left,
labelled `Intercept()' gives us the actual weight gain outcome for the
combination of the two control levels, \texttt{barley} as diet and
\texttt{control} as supplement. Check that this value tallies with what
is shown in summary tables above, and in the interaction plot.

The weight gain values for all the other combinations of the levels of
each factor are given as differences from this reference level.

So for example in row two, where diet is changed from barley to oats but
supplement is still control, the value in the table is -2.8. This means
that the weight gain when the diet is changed to oats but the supplement
left as the control is 2.80 kg less than the reference value, and so
must be 23.30-2.80 = 20.50 kg. This agrees with the value in the summary
table of mean values that was calculated above, and tallies with the
interaction plot.

In row seven we see that the effect of the interaction between the diet
\texttt{oats} and the supplement \texttt{agrimore} is - 0.247. This
means that on going from the reference levels of barley and control, for
which the gain is 23.30, the change in gain is not just the sum of the
two main effects (-2.80 for switch of diet to oats and +3.05 for switch
of supplement to agrimore, but is modified by their interaction, of size
- 0.247. Hence the mean gain for a diet of oats \emph{and} a supplement
of agrimore is the intercept value plus the sum of the two main effects,
plus the interaction term: 23.297 - 2.803 + 3.052 - 0.247 = 23.299)

See if you can tally the other effect values in the summary table with
the mean values given in table above and in the interaction plot for
other combinations of diet and supplement.

Here is a table to help you interpret the output of the
\texttt{summary()} function.

\begin{table}
\centering
\begin{tabular}[t]{l|l|l|r|r|l|l}
\hline
term & meaning & type\_of\_effect & estimate & absolute\_value & p\_value & significance\\
\hline
(Intercept) & barley + control & Main effect & 23.30 & 23.30 & <0.001 & ***\\
\hline
dietoats & oats + control & Main effect & -2.80 & 20.49 & 0.005 & **\\
\hline
dietwheat & wheat + control & Main effect & -5.89 & 17.41 & <0.001 & ***\\
\hline
supplementagrimore & barley + agrimore & Main effect & 3.05 & 26.35 & 0.002 & **\\
\hline
supplementsupergain & barley + supergain & Main effect & -0.83 & 22.47 & 0.376 & \\
\hline
supplementsupersupp & barley + supersupp & Main effect & 2.28 & 25.58 & 0.019 & *.\\
\hline
dietoats:supplementagrimore & oats + agrimore & Interaction & -0.25 & 23.05 & 0.852 & \\
\hline
dietwheat:supplementagrimore & wheat + agrimore & Interaction & -0.82 & 22.48 & 0.537 & \\
\hline
dietoats:supplementsupergain & oats + supergain & Interaction & 0.00 & 23.30 & 1.0 & \\
\hline
dietwheat:supplementsupergain & wheat + supergain & Interaction & 0.44 & 23.73 & 0.741 & \\
\hline
dietoats:supplementsupersupp & oats + supersupp & Interaction & -0.91 & 22.38 & 0.491 & \\
\hline
dietwheat:supplementsupersupp & wheat + supersupp & Interaction & -0.02 & 23.28 & 0.99 & \\
\hline
\end{tabular}
\end{table}

The output of the \texttt{summary()} function re-emphasises that none of
the interaction terms are significant. It also suggests that a minimum
adequate model will contain 5 parameters: an intercept, which just means
that there is non-zero growth when the diet and supplement are the
reference values, a difference from that growth due to changing the diet
to \texttt{oats}, a difference due to changing it to\texttt{wheat}, a
difference due to changing the supplement to \texttt{agrimore} while
keeping barley as the diet, and a difference due to changing the
supplement instead to \texttt{suppersupp}..

\subsection{Model Simplification}\label{model-simplification}

Given the results of the full interaction model, we begin model
simplification by leaving out the interaction terms, to leave us with an
additive model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model\_1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(gain }\SpecialCharTok{\textasciitilde{}}\NormalTok{ diet }\SpecialCharTok{+}\NormalTok{ supplement, }\AttributeTok{data =}\NormalTok{ weights)}
\FunctionTok{summary}\NormalTok{(model\_1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = gain ~ diet + supplement, data = weights)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.30792 -0.85929 -0.07713  0.92052  2.90615 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)          23.4263     0.4408  53.141  < 2e-16 ***
dietoats             -3.0928     0.4408  -7.016 1.38e-08 ***
dietwheat            -5.9903     0.4408 -13.589  < 2e-16 ***
supplementagrimore    2.6967     0.5090   5.298 4.03e-06 ***
supplementsupergain  -0.6848     0.5090  -1.345 0.185772    
supplementsupersupp   1.9693     0.5090   3.869 0.000375 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.247 on 42 degrees of freedom
Multiple R-squared:  0.8531,    Adjusted R-squared:  0.8356 
F-statistic: 48.76 on 5 and 42 DF,  p-value: < 2.2e-16
\end{verbatim}

\subsection{Check the validity of the linear
model}\label{check-the-validity-of-the-linear-model}

We ought to pause here for a moment and just check that we are OK to go
ahead and analyse our data using a general linear model (of which ANOVA
is an example, linear regression and t-tests being others). We will use
\texttt{autoplot()} from the \texttt{ggfortify} package, which gives us
the standard four diagnostic plots.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{autoplot}\NormalTok{(model\_1) }\SpecialCharTok{+} \FunctionTok{theme\_cowplot}\NormalTok{() }\CommentTok{\# autoplot() is from the ggfortify package.}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_two_way_with_model_simplification_files/figure-pdf/diagnostic plots-1.pdf}}

Well, that all looks fine. In particular, from the top-left figure we
see that the variance of the residuals is more or less constant and from
the top-right figure, the quantile-quantile plot, we get a pretty good
approximation of a straight line which tells us that the residuals are
more or less normally distributed. These are two key assumptions that
must be at least approximately satisfied by data if it is going to make
any sense to use a linear model to analyse it. We won't discuss here the
other two diagnostic plots, but they look fine too. So we are good to go
using ANOVA with this data.

Back to interpreting the output of the ANOVA:

It is clear that we need to retain all three levels of diet since the
effect values of each differ from each other by an amount that is
several times the standand errors, so that \emph{t}
\textgreater\textgreater{} 1. It is not clear that we need all the
levels of supplement, however. \texttt{supersupp} is not obviously
different from \texttt{agrimore} (difference = -0.727 with standard
error = 0.509), yet both are clearly different from \texttt{control}.
However \texttt{supergrain} is not obviously different from
\texttt{control} (difference = -0.68, error = 0.509). Hence we are
tempted to try a new model with just two levels of the factor supplement
which we might sensibly call ``best'', by which we mean
\texttt{agrimore} or \texttt{supersupp}, and ``worst'' by which we mean
\texttt{control} or \texttt{supergrain}. We'll name this new factor
\texttt{supp2}.

This code chunk amends the \texttt{weights} data frame by adding a new
column to it called \texttt{supp2} in which the values are either
\texttt{best} if the supplement is agrimore or supersupp, or
\texttt{worst} if the supplement is either of the other two

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weights }\OtherTok{\textless{}{-}}\NormalTok{ weights }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{supp2 =} \FunctionTok{ifelse}\NormalTok{(supplement }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"agrimore"}\NormalTok{, }\StringTok{"supersupp"}\NormalTok{), }\StringTok{"best"}\NormalTok{, }\StringTok{"worst"}\NormalTok{))}
\FunctionTok{glimpse}\NormalTok{(weights)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Rows: 48
Columns: 4
$ supplement <fct> supergain, supergain, supergain, supergain, control, contro~
$ diet       <fct> wheat, wheat, wheat, wheat, wheat, wheat, wheat, wheat, whe~
$ gain       <dbl> 17.37125, 16.81489, 18.08184, 15.78175, 17.70656, 18.22717,~
$ supp2      <chr> "worst", "worst", "worst", "worst", "worst", "worst", "wors~
\end{verbatim}

If we calculate the means and standard errors for weight gain under each
diet for each of the two new classifications of supplement, and then
plot them, we get this new interaction plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{weights }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{group\_by}\NormalTok{(diet, supp2) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_gain =} \FunctionTok{mean}\NormalTok{(gain), }\AttributeTok{se\_gain =} \FunctionTok{sd}\NormalTok{(gain)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{())) }\SpecialCharTok{|\textgreater{}}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{|\textgreater{}}

  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ supp2,}\AttributeTok{y =}\NormalTok{ mean\_gain,}\AttributeTok{colour =}\NormalTok{ diet, }\AttributeTok{group=}\NormalTok{diet)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size=}\DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean\_gain}\SpecialCharTok{{-}}\NormalTok{se\_gain, }\AttributeTok{ymax =}\NormalTok{ mean\_gain }\SpecialCharTok{+}\NormalTok{ se\_gain), }\AttributeTok{width=}\FloatTok{0.1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Supplement"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Mean weight gain"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_brewer}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme\_cowplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{ANOVA_two_way_with_model_simplification_files/figure-pdf/simplified additive model plot-1.pdf}}

From this we can see that diet clearly makes a difference to weight
gain, since the three lines are separated by a distance much larger than
the standard errors, and also that the best supplement clearly makes a
difference since there is a consistent drop on going from `best' to
`worst', again by an amount that is much larger than the error bars, and
there is clearly no interaction between diet and supplement, since the
lines are parallel within the wiggle-room allowed by the error bars,
which means that the effect of diet does not depend on supplement, and
the effect of supplement does not depend on diet.

Now we will make the simpler model, calling it model\_2 (for comparison
with the first additive model, model\_1)

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# additive model whee the supplements have been condensed from four to two: best and worst}
\NormalTok{model\_2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(gain }\SpecialCharTok{\textasciitilde{}}\NormalTok{ diet }\SpecialCharTok{+}\NormalTok{ supp2, }\AttributeTok{data =}\NormalTok{ weights)}
\end{Highlighting}
\end{Shaded}

and then compare the two additive models:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{anova}\NormalTok{(model\_1, model\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Analysis of Variance Table

Model 1: gain ~ diet + supplement
Model 2: gain ~ diet + supp2
  Res.Df    RSS Df Sum of Sq      F Pr(>F)
1     42 65.296                           
2     44 71.284 -2   -5.9876 1.9257 0.1584
\end{verbatim}

When we use \texttt{anova()} in this way it is testing the explanatory
power of the second model against that of the first ie how much of the
variance in the data does each explain. Its null hypothesis is that both
models explain just as much of the variance as the other.

The simpler model has saved two degrees of freedom and is not
significantly different in explanatory power than the more complex model
(\emph{p} = 0.158). Hence this is a better candidate as a minimal
adequate model. All the parameters are significantly different from zero
and from each other.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(model\_2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = gain ~ diet + supp2, data = weights)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.6716 -0.9432 -0.1918  0.9293  3.2698 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  25.7593     0.3674  70.106  < 2e-16 ***
dietoats     -3.0928     0.4500  -6.873 1.76e-08 ***
dietwheat    -5.9903     0.4500 -13.311  < 2e-16 ***
supp2worst   -2.6754     0.3674  -7.281 4.43e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.273 on 44 degrees of freedom
Multiple R-squared:  0.8396,    Adjusted R-squared:  0.8286 
F-statistic: 76.76 on 3 and 44 DF,  p-value: < 2.2e-16
\end{verbatim}

In this table,

\begin{itemize}
\tightlist
\item
  line one \texttt{(Intercept)} tells us that the mean weight gain when
  on the barley diet and best supplement is 25.76 kg
\item
  line two \texttt{dietoats} tells us that there is a significant drop
  in weight gain of 3.1 kg when diet is changed to oats.
\item
  line three \texttt{dietwheat} tells us that there is a significant
  drop in weight gain of 5.99 kg when diet is changed to wheat.
\item
  line four \texttt{supp2worst} tells us that there is a significant
  drop in wight gain of 2.68 kg when supplement is changed to worst.
\end{itemize}

In all cases, p\textless{} 0.001, as indicated not only by the number in
the Pr(\textgreater\textbar t\textbar) column, but also by the `***' in
the right-most column of the table.

\subsection{Reporting the results}\label{reporting-the-results}

We have now reduced our initial 12 parameter model to a four parameter
model that is much more tractable and easier to communicate. Our advice
would be that for maximum weight gain a diet of \texttt{barley} with a
supplement of \texttt{agrimore} or \texttt{supersupp} would be best.

If we were reporting this as a statistical test, we might say something
like: A diet of barley with a supplement of agrimore or supersupp was to
offer significant improvements over alternatives. There was no evidence
of any interaction between diet and supplement. (ANOVA 2-way,
F\textsubscript{3,44} = 76.76, p \textless{} 0.001)

{[}1{]}: Cumming, G., Fidler, F., \& Vaux, D. L. (2007). Error bars in
experimental biology. Journal of Cell Biology, 177(1), 7--11.
\url{https://doi.org/10.1083/jcb.200611141}

\bookmarksetup{startatroot}

\chapter{Chi-squared analysis of count
data}\label{chi-squared-analysis-of-count-data}

\section{When to use chi-square
analysis}\label{when-to-use-chi-square-analysis}

A chi-square analysis is used when our data are in the form of

\begin{itemize}
\tightlist
\item
  raw counts for two or more categorical groups eg pea plants with
  either yellow peas or green peas, survival rate of mice if they took
  drug A or took drug B, etc.
\item
  Each independent observation must definitely belong to either one
  group or the other
\item
  there are no replicates. That is, for each category we just have one
  count.
\item
  Each count is five or more
\end{itemize}

What we do is compare the counts we got to some \emph{expected} value
according either to the long term results of chance or to some prior
theory.

\section{Example: tossing a coin}\label{example-tossing-a-coin}

\begin{itemize}
\item
  If we were tossing a fair coin 1000 times we would expect 500 heads
  and 500 tails, ie heads and tails in the proportion 1:1.
\item
  {In reality, if the coin were fair, we would probably get roughly the
  same number of heads and tails, but probably not exactly 500 of each.}
\item
  \textbf{How far from 50:50 would the proportion of heads and tails
  have to be before we would be justified in rejecting the idea that the
  coin is fair?}
\end{itemize}

\section{Example: throwing a dice}\label{example-throwing-a-dice}

\begin{itemize}
\item
  {If we threw a fair dice a large number of times we would expect each
  possible score, from 1 to 6, to occur the same number of times.}
\item
  ie each score would occur 1/6th of the time.
\item
  {In reality we would probably get each score roughly 1/6 of the time,
  but not exactly 1/6.}
\item
  \textbf{How far from the expected proportions could the numbers of
  each score get before we would be justified in thinking that the dice
  was not fair?}
\end{itemize}

\section{Example: Mendelian
inheritance}\label{example-mendelian-inheritance}

\includegraphics[width=5.29in,height=\textheight,keepaspectratio]{figures/mendelian_pea_plants.png}

How far from 3:1 would the yellow:green ratio need to be before we would
justified in claiming that the outcome was inconsistent with the
Mendelian prediction?

\section{Chi-square Goodness of Fit
Test}\label{chi-square-goodness-of-fit-test}

\begin{itemize}
\item
  {In a chi-square `\textbf{goodness of fit}' test, we are testing data
  where we have a number of counts for each of two or more possible
  outcomes of some procedure (heads/tails, dice scores, pea colour
  etc).}
\item
  We have an idea of how these counts should be distributed under some
  \textbf{null hypothesis} (the coin is fair, the dice is fair, genetic
  inheritance works in this or that way etc).
\item
  {The chi-square goodness of fit test tests how likely it is we would
  have got the counts we actually got or more extreme counts if that
  null hypothesis were correct.}
\item
  We are testing how well our actual counts `fit' the expected values.
\end{itemize}

\section{Chi-square Goodness of Fit Test in
R}\label{chi-square-goodness-of-fit-test-in-r}

\begin{itemize}
\item
  {In a typical software implementation of the test, such as in R, we
  give it the counts we actually got for each possible outcome and also
  the expected proportion for each outcome.}
\item
  The test then gives us a p-value, a probability, for how likely it is
  that we would have got the counts we actually got, or counts even
  further from the null hypothesis, if that null hypothesis were
  correct.
\item
  {If this p-value is too small, and by that we usually mean less than
  0.05, then we reject the null hypothesis.}
\end{itemize}

\section{Example: Mendelian pea
plants}\label{example-mendelian-pea-plants}

\begin{itemize}
\tightlist
\item
  {Suppose we have self-fertilized an F1 generation of pea plants that
  were all heterozygous for yellow/green pea colour. In the F2
  generation we get 176 offspring, of which 130 are yellow and 46 are
  green.}
\end{itemize}

We ask, \textbf{are these numbers consistent with a null hypothesis that
Mendelian genetics is the underlying mechanism of inheriance here, or,
if that were true, are they so unlikely that we sould reject that null?}

\begin{itemize}
\item
  {The data here are raw counts, an individual pea plant offspring
  contributes either to the yellow count or to the green count, but not
  to both, and both counts are much larger than 5.}
\item
  Hence, a Chi-square goodness of fit test can be used to test whether
  our data are plausibly consistent with the null hypothesis.
\item
  {Our expected counts of yellow and green are found by simply dividing
  the total count of offspring, 176, in the ratio 3:1, giving us an
  expected 132 yellow pea plants and an expected 44 green pea plants in
  the offspring F1 generation.}
\end{itemize}

\section{Doing the chi-square test in
R}\label{doing-the-chi-square-test-in-r}

We type this function into the console pane of RStudio:

\texttt{chisq.test(c(130,46),p=c(0.75,0.25))}

We have given the function \texttt{chisq.test()} two \emph{arguments},
separated by a comma:

\begin{itemize}
\item
  The first argument \texttt{c(130,46)} is a vector (denoted by
  \texttt{c()}) of the two observed counts for yellow and green.
\item
  the second argument \texttt{p\ =\ c(0.75,0.25)} is another vector,
  this time of the proportions in which we \emph{expect} the two colours
  to appear. If these proportions were all equal, as is common but not
  the case here, then we could leave out this argument, since that is
  the default presumption.
\end{itemize}

\section{Output of chi-square goodness of fit
test:}\label{output-of-chi-square-goodness-of-fit-test}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{130}\NormalTok{, }\DecValTok{46}\NormalTok{), }\AttributeTok{p =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.75}\NormalTok{, }\FloatTok{0.25}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Chi-squared test for given probabilities

data:  c(130, 46)
X-squared = 0.12121, df = 1, p-value = 0.7277
\end{verbatim}

This output is typical of tests done in R.

\begin{itemize}
\item
  {We get the `test statistic' whose name varies depending on the test.
  Here it is called X-squared, pronounced kai-squared. This is a number
  that the test calculates, based on the data you have given it. For the
  most part, we don't need to worry about how it does that. Then there
  is the p-value, which is the probability of getting this test
  statistic if the null hypothesis were true.}
\item
  In this case, we see that the p-value is 0.73, which is large.
\item
  {We could very plausibly have got yellow:green numbers of 130 and 46
  if the null hypothesis were true, so we cannot reject that null
  hypothesis.}
\item
  In other words, our data are consistent at the 5\% significance level
  with the predictions of simple Mendelian inheritance.
\end{itemize}

\section{Reporting the result in
English}\label{reporting-the-result-in-english}

In English, we might report this result as:

\emph{We found counts of 130 yellow plants and 46 green plants, which
are consistent at the 5\% significance level with the predictions of
Mendelian inheritance (chi-squared test, X-squared = 0.12, p=0.73).}

\subsection{Caution}\label{caution}

Note that we do not say we have proved Mendelian inheritance to be
correct. We haven't. We never prove things in science. We haven't said
anything about the truth of the null hypothesis. All we can say is
whether our data are or are not consistent with the null hypothesis. In
this case they are. We then report the test we used and the values of
the test statistic and p-value. Other tests might give you other details
to report too.

\section{Exercise 1: Is this coin a fair
coin?}\label{exercise-1-is-this-coin-a-fair-coin}

{Suppose you tossed a fair coin 100 times and got 43 heads and 57
tails.}

Under a null hypothesis that the coin is fair, what would the expected
numbers of heads and tails be?

{Now, you use R to do a chi-square test of that null hypothesis. Here is
the code to do that and the output it would give:}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{43}\NormalTok{,}\DecValTok{57}\NormalTok{),}\AttributeTok{p=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\FloatTok{0.5}\NormalTok{)) }\CommentTok{\# we could leave out the second argument here}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Chi-squared test for given probabilities

data:  c(43, 57)
X-squared = 1.96, df = 1, p-value = 0.1615
\end{verbatim}

\begin{itemize}
\item
  {What do you conclude?}
\item
  How would you report the result?
\end{itemize}

\section{Solution 1}\label{solution-1}

\begin{itemize}
\item
  {The expectation is that half the outcomes would be heads and half
  would be tails.}
\item
  The null hypothesis of this test is that heads and tails are equally
  likely, ie that the coin is fair.
\item
  {Under this null hypothesis the expected outcome is 50 heads and 50
  tails.}
\item
  From the output of the R code we see that the p-value, the probability
  of getting an outcome as far or further from that, is 0.161. That is
  pretty high. Would you do anything if you knew that the probability of
  a bad (or worse) outcome was 0.161 (ie about 1 in 6)?
\item
  {In particular, this p-value is greater than 0.05, so we cannot reject
  the null hypothesis that the coin is fair. That is, even with a fair
  coin it is not unlikely that you would get head/tail numbers as
  different or more different from 50/50 as 43/57 if you tossed the coin
  100 times. That will happen about 1/6 of the time if you repeatedly do
  trials where you toss the coin 100 times.}
\end{itemize}

\section{Solution 1 (continued)}\label{solution-1-continued}

\begin{itemize}
\tightlist
\item
  To report this result, you might say something like
\end{itemize}

\emph{From 100 coin tosses we got 43 heads and 57 tails. These counts
are consistent at the 5\% significance level with the coin being fair
(chi-squared test, X2 = 1.96, df = 1, p \textgreater{} 0.05).}

\section{Exercise 2: Is a scientist's competence associated with their
astrological star
sign?}\label{exercise-2-is-a-scientists-competence-associated-with-their-astrological-star-sign}

Suppose someone told you that the competence of scientists was linked to
their astrological zodiac sign. I won't name all of these, but there are
twelve of them: Pisces, Scorpio, Cancer etc.

{To test this hypothesis, you spend a lot of time on Primo and identify
240 scientists, currently active, that have each published at least five
papers in high impact journals in the last year. All of these people,
you presume, are successful scientists. You write to each of them and
ask them their date of birth.}

Amazingly(!) all of them respond. You then assign each of them to a
zodiac sign according to their birth date and get the following counts
for each sign:

{In this code chunk we have typed out the counts and collected them as a
vector, using the function \texttt{c()}, we have saved this under the
name \texttt{stars}.}

\phantomsection\label{annotated-cell-123}%
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stars}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{22}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{17}\NormalTok{,}\DecValTok{22}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{19}\NormalTok{,}\DecValTok{18}\NormalTok{,}\DecValTok{21}\NormalTok{,}\DecValTok{19}\NormalTok{,}\DecValTok{22}\NormalTok{,}\DecValTok{23}\NormalTok{,}\DecValTok{17}\NormalTok{) }\hspace*{\fill}\NormalTok{\circled{1}}
\end{Highlighting}
\end{Shaded}

\begin{description}
\tightlist
\item[\circled{1}]
Create a stars vector
\end{description}

\section{Exercise 2 (continued)}\label{exercise-2-continued}

\begin{itemize}
\item
  {What would be a suitable null hypothesis in this investigation?}
\item
  What proportion of the total count would we expect for each star sign
  if this null were true?
\item
  {Do the data meet the criteria required for use of a chi-square
  goodness of fit test.}
\item
  If you have access to R, use the \texttt{chisq.test()} function to
  implement this test.
\item
  {On the basis of the output of the test, do you reject the null
  hypothesis?}
\item
  Report the result of the test in plain English.
\end{itemize}

\section{Solution 2}\label{solution-2}

\begin{itemize}
\item
  {H0: There is no association between the astrological star sign of a
  researcher and their success in science (who knew?)}
\item
  One twelfth for each sign. ie a researcher is as likely to have one
  star sign as any other.
\item
  {These are count data, there are at least five counts for every sign
  and the counts are independent - any individual researcher only
  contributes to one of the twelve counts.}
\item
  Note that we do not need to include the second \texttt{p=...} argument
  in this case since the default presumption, that all proportions are
  equal, is true here.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(stars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Chi-squared test for given probabilities

data:  stars
X-squared = 2.3, df = 11, p-value = 0.9971
\end{verbatim}

\section{Solution 2 (continued)}\label{solution-2-continued}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(stars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

    Chi-squared test for given probabilities

data:  stars
X-squared = 2.3, df = 11, p-value = 0.9971
\end{verbatim}

\begin{itemize}
\item
  {We see that the p-value is almost one so we emphatically do not
  reject the null hypothesis.}
\item
  We find no evidence that star sign affects success in science
  (X-sq=2.29, df = 11, p=0.997)
\end{itemize}

{Note the degrees of freedom that is reported: df = 11. The degrees of
freedom is the number of independent pieces of information. Here, given
that we know the total number of researchers, only eleven of the
individual counts are independent. Once they are known, the twelfth can
be calculated.}

\bookmarksetup{startatroot}

\chapter*{References}\label{references}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\end{CSLReferences}




\end{document}
